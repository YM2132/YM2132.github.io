<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yusuf Mohammad">

<title>The Path to StyleGan2 - Implementing the StyleGAN</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="StyleGAN_files/libs/clipboard/clipboard.min.js"></script>
<script src="StyleGAN_files/libs/quarto-html/quarto.js"></script>
<script src="StyleGAN_files/libs/quarto-html/popper.min.js"></script>
<script src="StyleGAN_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="StyleGAN_files/libs/quarto-html/anchor.min.js"></script>
<link href="StyleGAN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="StyleGAN_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="StyleGAN_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="StyleGAN_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="StyleGAN_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#stylegan---building-on-the-progressive-growing-gan" id="toc-stylegan---building-on-the-progressive-growing-gan" class="nav-link active" data-scroll-target="#stylegan---building-on-the-progressive-growing-gan">StyleGAN - Building on the Progressive Growing GAN</a></li>
  <li><a href="#the-path-to-implementation---a-roadmap" id="toc-the-path-to-implementation---a-roadmap" class="nav-link" data-scroll-target="#the-path-to-implementation---a-roadmap">The Path to Implementation - A Roadmap</a>
  <ul>
  <li><a href="#the-old-stuff" id="toc-the-old-stuff" class="nav-link" data-scroll-target="#the-old-stuff">The Old Stuff</a></li>
  <li><a href="#the-mapping-network" id="toc-the-mapping-network" class="nav-link" data-scroll-target="#the-mapping-network">The Mapping Network</a></li>
  <li><a href="#adaptive-instance-normalisation-adain" id="toc-adaptive-instance-normalisation-adain" class="nav-link" data-scroll-target="#adaptive-instance-normalisation-adain">Adaptive Instance Normalisation (AdaIN)</a>
  <ul class="collapse">
  <li><a href="#style-transfer---a-quick-detour" id="toc-style-transfer---a-quick-detour" class="nav-link" data-scroll-target="#style-transfer---a-quick-detour">Style Transfer - A Quick Detour</a></li>
  </ul></li>
  <li><a href="#random-noise---adding-randomness-to-the-g" id="toc-random-noise---adding-randomness-to-the-g" class="nav-link" data-scroll-target="#random-noise---adding-randomness-to-the-g">Random Noise - Adding Randomness to the G</a></li>
  <li><a href="#style-mixing" id="toc-style-mixing" class="nav-link" data-scroll-target="#style-mixing">Style Mixing</a></li>
  <li><a href="#learned-constant" id="toc-learned-constant" class="nav-link" data-scroll-target="#learned-constant">Learned Constant</a></li>
  </ul></li>
  <li><a href="#the-generator-model" id="toc-the-generator-model" class="nav-link" data-scroll-target="#the-generator-model">The Generator Model</a>
  <ul>
  <li><a href="#the-g-conv-block" id="toc-the-g-conv-block" class="nav-link" data-scroll-target="#the-g-conv-block">The G Conv Block</a></li>
  <li><a href="#the-g-model" id="toc-the-g-model" class="nav-link" data-scroll-target="#the-g-model">The G Model</a></li>
  <li><a href="#preparing-to-train-the-stylegan" id="toc-preparing-to-train-the-stylegan" class="nav-link" data-scroll-target="#preparing-to-train-the-stylegan">Preparing to Train the StyleGAN</a>
  <ul class="collapse">
  <li><a href="#frechet-inception-distance---fid" id="toc-frechet-inception-distance---fid" class="nav-link" data-scroll-target="#frechet-inception-distance---fid">Frechet-Inception Distance - FID</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#training-the-stylegan" id="toc-training-the-stylegan" class="nav-link" data-scroll-target="#training-the-stylegan">Training the StyleGAN</a>
  <ul>
  <li><a href="#the-training-loop---were-almost-there" id="toc-the-training-loop---were-almost-there" class="nav-link" data-scroll-target="#the-training-loop---were-almost-there">The Training Loop - We’re almost there!</a></li>
  <li><a href="#the-training-process" id="toc-the-training-process" class="nav-link" data-scroll-target="#the-training-process">The Training Process</a></li>
  <li><a href="#stylegan-images" id="toc-stylegan-images" class="nav-link" data-scroll-target="#stylegan-images">StyleGAN Images</a></li>
  </ul></li>
  </ul>
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="https://ym2132.github.io/"><i class="bi bi-link-45deg"></i>Yusuf's Deep Learning Blog</a></li><li><a href="https://github.com/YM2132?tab=repositories"><i class="bi bi-link-45deg"></i>Yusuf's GitHub</a></li><li><a href="https://ym2132.github.io/Progressive_GAN"><i class="bi bi-link-45deg"></i>Progressive Growing GAN Blog post</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://github.com/YM2132/YMPaperImplementations/blob/main/paper_implementations/python_implementations/StyleGAN"><i class="bi bi-file-code"></i>StyleGAN</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Path to StyleGan2 - Implementing the StyleGAN</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yusuf Mohammad </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<hr>
<p>This is the second post on the road to StyleGAN2. In this post we implement the StyleGAN and in the third and final post we will implement StyleGAN2.</p>
<p>You can find the <b>StyleGAN</b> paper <a href="https://arxiv.org/pdf/1812.04948">here</a>. Note, if I refer to the “the authors” I am referring to Karras et al, they are the authors of the StyleGAN paper.</p>
<p>This post will be a lot shorter than my last post, on the <a href="https://ym2132.github.io/Progressive_GAN">Progressive Growing GAN (PGGAN)</a>, because the StyleGAN reuses a lot of the techniques from the PGGAN. As such, I strongly suggest you read the PGGAN post if you haven’t before proceeding (so much is reused from the PGGAN, understanding it is a pre-requisite to understanding the StyleGAN).</p>
<p>We make use of the CelebA-HQ 256 dataset again, it can be found at: <a href="https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256">https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256</a></p>
<hr>
<p>Expand this block to show code for imports and some helper functions :)</p>
<div id="939ee513-ab6b-4c2b-9876-529b096a4c97" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Before we continue lets set our inputs and configure the device for our model code</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> ImageFolder</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> save_image</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms, utils</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchmetrics.image.fid <span class="im">import</span> FrechetInceptionDistance</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> sqrt</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># We can make use of a GPU if you have one on your computer. This works for Nvidia and M series GPU's</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.backends.mps.is_available():</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># These 2 lines assign some data on the memory of the device and output it. The output confirms</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if we have set the intended device</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.cuda.is_built():</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> (<span class="st">"cpu"</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># I also define a function we use to examine the outputs of the Generator</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_images(images, num_images<span class="op">=</span><span class="dv">16</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>)):</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure the input is on CPU</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> images.cpu().detach()</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize images from [-1, 1] to [0, 1]</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> (images <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clamp values to [0, 1] range</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.clamp(images, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make a grid of images</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> torchvision.utils.make_grid(images[:num_images], nrow<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to numpy and transpose</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> grid.numpy().transpose((<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the grid</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>figsize)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    plt.imshow(grid)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1.], device='cuda:0')</code></pre>
</div>
</div>
<section id="stylegan---building-on-the-progressive-growing-gan" class="level2">
<h2 class="anchored" data-anchor-id="stylegan---building-on-the-progressive-growing-gan">StyleGAN - Building on the Progressive Growing GAN</h2>
<p>The implementation of the StyleGAN makes a few major changes to the Generator (G) architecture, but the underlying structure follows the Progressive Growing GAN (PGGAN) paper. The Discriminator model remains unchanged from the PGGAN. Through modifying the G setup, StyleGAN achieves better image generation than PGGAN. Also, this paper covers some very interesting topics which shed light on the inner workings of GANs.</p>
<p>The trouble with with the PGGAN and other GANs is the lack of ways to modify the generator output. One of the key ideas of modifying the G is to expose new ways to control image generation. Previously, the only input to the model was the input latent vector<a href="#6"><sup>6</sup></a>, in the StyleGAN we switch this up. Rather than starting from a latent vector <span class="math inline">\(\textbf{z}\)</span>, we start from a learned constant. But, fret not we still have a place for <span class="math inline">\(\textbf{z}\)</span>, it is used in a mapping network (don’t worry we will explore all of this in depth later) to create an intermediate learned latent vector <span class="math inline">\(\textbf{w}\)</span>. <span class="math inline">\(\textbf{w}\)</span> is used in the Adapative Instance layers of the network and is one way to control generation in the StyleGAN. The second way comes through random noise injection, which takes place after each convolutional layer.</p>
<p>The “Style” part of StyleGAN refers to style transfer. The goal of style transfer is to render the same content of an image in different styles<a href="#1"><sup>1</sup></a>, take a look at Figure 1 for an illustration of how to think about this.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/8797df0f-0f4a-49fe-ba63-68e4c4f06ad0-1-755b68d4-3ee9-44c3-a5bf-ef9a3c66fee2.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1 - A Starry Night in different styles, the semantic content of the image is the same (they show the same thing) but the styles are clearly different</figcaption>
</figure>
</div>
<p>Style transfer is typically concerned with transferring the style of one image to another, with the style coming from an existing image. The authors choose to depart from this and instead of an image we use a seperate network to define the “styles”, in this sense they are not “styles” (hence the ““) as defined in the literature but they are used in the same manner which explains why the name is the same. The style’s are used to control the Adaptive Instance Normalisation (AdaIN).</p>
</section>
<section id="the-path-to-implementation---a-roadmap" class="level2">
<h2 class="anchored" data-anchor-id="the-path-to-implementation---a-roadmap">The Path to Implementation - A Roadmap</h2>
<p>In Figure 2 we see the architecture of the G model in the StyleGAN. The numbers denote the order in which I will cover each part (the boxes show the constituents of each part) of the network. Explained individually things can get a bit confusing, so keep this image in mind as you read on and the whole thing will make a lot more sense.</p>
<p>Here’s the order in which we will proceed:</p>
<pre><code>1 - The Mapping network
2 - The AdaIN layer
3 - Addition of random noise to images
4 - Style Mixing (not labelled here)
5 - Learned Constant (Const 4x4x512 in the image, ours will be 4x4x256)</code></pre>
<p>We will then wrap this all up in a neat package and implement the full G network.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/d41c861a-b82f-4921-b7c8-25c232a0ae67-1-ed1a63af-77df-4440-a57d-008d3fcd763d.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2 - A Roadmap</figcaption>
</figure>
</div>
<section id="the-old-stuff" class="level3">
<h3 class="anchored" data-anchor-id="the-old-stuff">The Old Stuff</h3>
<p>By old stuff I mean things we implemented in the PGGAN post but which we will reuse here. To name they are the Equal LR layers, Pixel Norm, MiniBatch standard deviation, WGAN-GP loss (this will be in the training loop), EMA and the entire Discriminator network. I will include the code here and refer you to the first post in this series for further details.</p>
<p>Expand the following code block to see the old stuff :)</p>
<div id="3a965ba4" class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PixelNorm(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">/</span> torch.sqrt(torch.mean(x <span class="op">**</span> <span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MiniBatchStdDev(nn.Module):</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, group_size<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.group_size <span class="op">=</span> group_size</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        N, C, H, W <span class="op">=</span> x.shape </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> <span class="bu">min</span>(<span class="va">self</span>.group_size, N) </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> x.view(G, <span class="op">-</span><span class="dv">1</span>, C, H, W)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y <span class="op">-</span> torch.mean(y, dim<span class="op">=</span><span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.mean(torch.square(y), dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.sqrt(y <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.mean(y, dim<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>], keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y.repeat(G, <span class="dv">1</span>, H, W)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([x,y], dim<span class="op">=</span><span class="dv">1</span>)    </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> EMA(model1, model2, decay<span class="op">=</span><span class="fl">0.999</span>):</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    par1 <span class="op">=</span> <span class="bu">dict</span>(model1.named_parameters())</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    par2 <span class="op">=</span> <span class="bu">dict</span>(model2.named_parameters())</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> par1.keys():</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        par1[k].data.mul_(decay).add_(par2[k].data, alpha<span class="op">=</span><span class="dv">1</span> <span class="op">-</span> decay)    </span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLR:</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name):</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_weight(<span class="va">self</span>, module):</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="bu">getattr</span>(module, <span class="va">self</span>.name <span class="op">+</span> <span class="st">'_orig'</span>) </span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        fan_in <span class="op">=</span> weight.data.size(<span class="dv">1</span>) <span class="op">*</span> weight.data[<span class="dv">0</span>][<span class="dv">0</span>].numel()</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> weight <span class="op">*</span> sqrt(<span class="dv">2</span> <span class="op">/</span> (fan_in))</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(module, name):</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        fn <span class="op">=</span> EqualLR(name)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="bu">getattr</span>(module, name)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> module._parameters[name]</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>        module.register_parameter(name <span class="op">+</span> <span class="st">'_orig'</span>, nn.Parameter(weight.data))</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        module.register_forward_pre_hook(fn)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> fn</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, module, <span class="bu">input</span>):</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="va">self</span>.compute_weight(module)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>        <span class="bu">setattr</span>(module, <span class="va">self</span>.name, weight)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> equal_lr(module, name<span class="op">=</span><span class="st">'weight'</span>):</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>    EqualLR.<span class="bu">apply</span>(module, name)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> module</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRConv2d(nn.Module):</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        conv <span class="op">=</span> nn.Conv2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        conv.weight.data.normal_()</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        conv.bias.data.zero_()</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> equal_lr(conv)</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv(<span class="bu">input</span>)</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRConvTranspose2d(nn.Module):</span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        conv <span class="op">=</span> nn.ConvTranspose2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>        conv.weight.data.normal_()</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        conv.bias.data.zero_()</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> equal_lr(conv)</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv(<span class="bu">input</span>)</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRLinear(nn.Module):</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_dim, out_dim):</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>        linear <span class="op">=</span> nn.Linear(in_dim, out_dim)</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>        linear.weight.data.normal_()</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>        linear.bias.data.zero_()</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> equal_lr(linear)</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(<span class="bu">input</span>)</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> D_ConvBlock(nn.Module):</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>        in_c,</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>        out_c,</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>        padding, </span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>,   </span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>        mbatch<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> []</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mbatch:</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>                MiniBatchStdDev(),</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>        layers_list.extend([</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, out_c<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blocks <span class="op">=</span> nn.ModuleList([</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">4</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">4</span>, out_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">2</span>, out_c, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>), </span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">+</span><span class="dv">1</span>, out_c, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">0</span>, mbatch<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.from_rgb <span class="op">=</span> nn.ModuleList([</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">1</span>),</span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.blocks)</span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> EqualLRLinear(out_c, <span class="dv">1</span>)</span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, layer_num, alpha):</span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(layer_num)):</span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> <span class="va">self</span>.num_layers <span class="op">-</span> i <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i<span class="op">+</span><span class="dv">1</span> <span class="op">==</span> layer_num:</span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> <span class="va">self</span>.from_rgb[idx](x)</span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.blocks[idx](out)</span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i<span class="op">+</span><span class="dv">1</span> <span class="op">==</span> layer_num <span class="kw">and</span> <span class="dv">0</span> <span class="op">&lt;=</span> alpha <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a>                    skip <span class="op">=</span> F.interpolate(x, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a>                    skip <span class="op">=</span> <span class="va">self</span>.from_rgb[idx <span class="op">+</span> <span class="dv">1</span>](skip)</span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> ((<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(out.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.linear(out)</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Discriminator().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="the-mapping-network" class="level3">
<h3 class="anchored" data-anchor-id="the-mapping-network">The Mapping Network</h3>
<p>From Figure 2 in the blue box (1) we see the Mapping network is a simple network consisting of only fully connected (linear) layers. It takes as input a latent vector <span class="math inline">\(\textbf{z}\)</span>, usually <span class="math inline">\(\textbf{z}\)</span> is fed directly to the G model however in StyleGAN it is not. Take a moment to look at Figure 2, you see G has no input instead it starts from a learned constant (we’ll come back to this). Anyways the output, of the mapping network, is a learned latent vector <span class="math inline">\(\textbf{w}\)</span>. The dimensions of both <span class="math inline">\(\textbf{z}\)</span> and <span class="math inline">\(\textbf{w}\)</span> are 256, the paper has them at 512, but our model has a smaller capacity as we only generate up to 256x256 images whereas the paper outputs 1024x1024 images (I did the same for my PGGAN implementation). Then we see that <span class="math inline">\(\textbf{w}\)</span> is used in the AdaIN layer, and it is the style part of our network.</p>
<p>I’m not sure exactly why this Mapping network is used, but here’s what I can decipher from the paper. The idea is that using a Mapping network allows <span class="math inline">\(\textbf{w}\)</span> to be disentangled, whereas <span class="math inline">\(\textbf{z}\)</span> is not. What does disentangled mean? To my understanding, the goal of disentanglement is a latent vector in which each linear subspace represents a different factor of variation<a href="#2"><sup>2</sup></a>. Now, <span class="math inline">\(\textbf{z}\)</span> does not have this property but <span class="math inline">\(\textbf{w}\)</span> does, this arises from the fact that <span class="math inline">\(\textbf{w}\)</span> is learnt thus giving it more freedom. Also, the setup of the GAN forces <span class="math inline">\(\textbf{w}\)</span> to become more disentangled through training. In theory it is easier for G to generate realistic images from a more disentangled representation, so training should push mapping network to creating a more disentangled <span class="math inline">\(\textbf{w}\)</span>. The paper does provide some metrics to measure the amount of disentanglement but today we’ll skip over it.</p>
<p>Now, then let’s get into implement the Mapping network!</p>
<div id="19fa8da7-e105-4950-a2da-f8ae33f1eae6" class="cell" data-scrolled="true" data-execution_count="11">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MappingNetwork(nn.Module):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We normalise the input with PixelNorm</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> PixelNorm()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;I set output to 256 to match the shortened G case</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># As we just want to pass the input through the whole network, I use a PyTorch Sequential</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># it allows us to pass our input through multiple layers with a single line in the forward method.</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            <span class="co"># I set the dimensionality of each layer to be the same. Perhaps you could change the hidden layer dimensions</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># and see what happens.</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            EqualLRLinear(<span class="dv">256</span>, <span class="dv">256</span>),</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalise input latent</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.norm(x)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using the Sequential pass the normalised input through the network</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layers(x)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Thats the mapping network done, it’s simple enough by itself. Time for the AdaIN!</p>
</section>
<section id="adaptive-instance-normalisation-adain" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-instance-normalisation-adain">Adaptive Instance Normalisation (AdaIN)</h3>
<p>The goal of style transfer is to find a way to transfer the style of an image to another without changing the content. A useful tool to achieve this is the Adaptive Instance Normalisation (AdaIN) layer<a href="#3"><sup>3</sup></a>. AdaIN is another of the major changes in the G model, replacing PixelNorm, it allows us to adjust the style of our generated images at different points in the model<a href="#4"><sup>4</sup></a>. You see in Figure 2, that the output of the mapping network is passed to all the AdaIN layers. But, the <span class="math inline">\(\textbf{w}\)</span> is first passed through a learned affine transform <span class="math inline">\(\textbf{A}\)</span>. This transform is what produces the style in our network for use in the AdaIN.</p>
<section id="style-transfer---a-quick-detour" class="level4">
<h4 class="anchored" data-anchor-id="style-transfer---a-quick-detour">Style Transfer - A Quick Detour</h4>
<p>Let us embark on a discussion of style transfer and the origins of AdaIN before we implement it. The style of an image can be found from it’s feature statistics, namely the mean and variance of an image. The idea is to use the mean and variance of the image whose style we want and make our other images match it. This can be done with different normalisation techniques<a href="#5"><sup>5</sup></a>, we call this Style Normalisation (from the paper I just linked to). Instance Normalisation can be used to perform style normalisation, which is normalising an image to have the style of another (making the mean and variance of that image match the style’s mean and variance). However, IN can only normalise images to one single style, whereas AdaIN can be adapted to many different styles through the extra input <span class="math inline">\(\textbf{y}\)</span> seen in Figure 3.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/21c749c5-efe4-478d-9523-84f53661d26e-1-fd62d944-61cd-4e21-a08d-b5ed2015a1f8.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3 - Instance Normalisation (top) and Adaptive Instance Normalisation (bottom)</figcaption>
</figure>
</div>
<p>Take a look at the formula for AdaIN vs IN in Figure 3. They are very similar, except AdaIN takes another input <span class="math inline">\(\textbf{y}\)</span>, this is the style. Consider IN, first the part in the brackets normalises the input <span class="math inline">\(\textbf{x}\)</span> and then it is adapted to have the feature statistics denoted by <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span>. Whereas, in AdaIN the normalised <span class="math inline">\(\textbf{x}\)</span> is adapted to have the feature statistics determined by the style <span class="math inline">\(\textbf{y}\)</span>. If you look closely at both formulas the operations outside the brakcets reverse the normalisation but with a new mean and std dev.</p>
<p>So what AdaIN does is very simple, it aligns the input <span class="math inline">\(\textbf{x}\)</span> to have the same mean and std dev of the style input. Typically, the style input is not a learnable parameter, but in the StyleGAN it is. Take a look at Figure 4 for the AdaIN we use (it’s almost identical, can you spot the difference?).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/01e8bd30-6406-4702-9330-7d74f3aeb923-1-cc0a72c8-84ff-4db7-82bb-22041841b737.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4 - The AdaIN used in the StyleGAN</figcaption>
</figure>
</div>
<p>The AdaIN in Figure 4 has the same input <span class="math inline">\(\textbf{y}\)</span>, but there are two aspects of it in the equation. <span class="math inline">\(\textbf{y}_s\)</span> is the style and <span class="math inline">\(\textbf{y}_b\)</span> is the bias. Both of these come from the learned affine transformation <span class="math inline">\(\textbf{A}\)</span> which is peformed on <span class="math inline">\(\textbf{w}\)</span> before it is passed to the AdaIN layers. Let’s discuss the goal of <span class="math inline">\(\textbf{A}\)</span> and the mapping network. They together provide a way to draw samples for each style from a learned distribution <span class="math inline">\(\textbf{W}\)</span>, we sample many different styles at each AdaIN in the network. The G uses these sampled styles to generate novel images. Furthermore it happens that (as stated by Karras) the styles are localises throughout the network, meaning at each point the style corresponds to something different in the images. The localisation occurs due to the formulation of AdaIN, let’s think about this before moving on. The middle part of Figure 4, normalises the input x the effect of this is setting the mean to 0 and the std dev to 1 and thereafter the <span class="math inline">\(\textbf{y}_s\)</span> and <span class="math inline">\(\textbf{y}_b\)</span> are applied, this is the root of localisation. By normalising the input image first we essentially reset the statistical properties, removing the influence of previous AdaIN operations and only the current style effects are applied. In other words, each AdaIN only controls one convolution operation before being overwritten by the next AdaIN.</p>
<p>Now what exactly is a learned affine transformation? Well, in a neural network setting it often refers to a linear forward pass (essentially we multiply our input by a weight and add a bias, to make it a learned operation but we keep the dimensionality the same), so we implement it as a pass through a linear layer.</p>
<p>Now you know how AdaIN works, let’s implement it!</p>
<div id="7b4623ea-ba6c-4fea-ac91-8c7882fb8e6d" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We define AdaIN as a PyTorch module</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AdaIN(nn.Module):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># As input we take the number of dimensions we have in our latent space, the number  and the current number of dimensions</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the current number will change based on the layer. Remember as we grow our G we decrease the number of channels with it starting</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># at 256 and ending at 64</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_dim, current_c):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Our map layer is a simple Linear layer, we make use of the EqLR linear layer we implemented in the previous post</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.map_layer <span class="op">=</span> EqualLRLinear(latent_dim, current_c<span class="op">*</span><span class="dv">2</span>)  <span class="co"># Style is 2x current dim, this is stated in the paper</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Look ahead for why it is 2x current dim.</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># IN constitutes the middle part of Figure 4 (without the y's), the default for InstanceNorm2d is affine=False (gamma and beta</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># are not used when affine=False)</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.IN <span class="op">=</span> nn.InstanceNorm2d(current_c)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># As input to our forward pass we have w - the output of the mapping network </span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and the image (the object being passed through the network)</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, w, image):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># To get out style we pass w through the affine transformation</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        style <span class="op">=</span> <span class="va">self</span>.map_layer(w)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We need to create y_style and y_bias from the style output. To do this we use the chunk method from PyTorch</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># chunk splits the tensor in 2 down the middle, so we will end up with y_s and y_b having half the number of channels that style </span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;has, this is why we do current_c*2 in the map_layer. </span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        y_s, y_b <span class="op">=</span> style.chunk(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape y_s and y_b to match image's dimensions, currently the dims of y_s and y_b are (N, C) and image is (N, C, H, W)</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># after the unsqueezes the dims of y_s and y_b will be (N, C, 1, 1)</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        y_s <span class="op">=</span> y_s.unsqueeze(<span class="dv">2</span>).unsqueeze(<span class="dv">3</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        y_b <span class="op">=</span> y_b.unsqueeze(<span class="dv">2</span>).unsqueeze(<span class="dv">3</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implement the full formula</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (y_s <span class="op">*</span> <span class="va">self</span>.IN(image)) <span class="op">+</span> y_b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>Expand the following code block to get some insight into the forward method of AdaIN</p>
<div id="3947bfcb-8291-44bc-b170-bd67ad9c0102" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">256</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>map_layer <span class="op">=</span> nn.Linear(<span class="dv">256</span>, <span class="dv">512</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>style <span class="op">=</span> map_layer(w)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>y_s, y_b <span class="op">=</span> style.chunk(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_s.shape, y_b.shape)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y_s <span class="op">=</span> y_s.unsqueeze(<span class="dv">2</span>).unsqueeze(<span class="dv">3</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>y_b <span class="op">=</span> y_b.unsqueeze(<span class="dv">2</span>).unsqueeze(<span class="dv">3</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_s.shape, y_b.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 256]) torch.Size([1, 256])
torch.Size([1, 256, 1, 1]) torch.Size([1, 256, 1, 1])</code></pre>
</div>
</div>
<p>The use of InstancNorm2d had me stumped for a while, I wanted to prove by setting affine=False it’s not a learned operation. Expand the code block below to see how we can use PyTorch to check if we have correctly turned off the learning.</p>
<div id="be109c66" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We create a random input with 4 channels</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">10</span>) </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define two different InstanceNorm2d operation. One with learning on and the other off</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>in_affine_on <span class="op">=</span> nn.InstanceNorm2d(<span class="dv">4</span>, affine<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>in_affine_off <span class="op">=</span> nn.InstanceNorm2d(<span class="dv">4</span>, affine<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"InstanceNorm2d with affine=True:"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the params</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> in_affine_on.named_parameters():</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: shape </span><span class="sc">{</span>param<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, requires_grad </span><span class="sc">{</span>param<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">InstanceNorm2d with affine=False:"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> in_affine_off.named_parameters():</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: shape </span><span class="sc">{</span>param<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, requires_grad </span><span class="sc">{</span>param<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># You see the above code prints nothing for in_affine_off let's explor it more here</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># We see that there are 0 params, which means nothing to learn and hence learned is off correctly</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Number of parameters (affine=True): </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> in_affine_on.parameters())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of parameters (affine=False): </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> in_affine_off.parameters())<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>InstanceNorm2d with affine=True:
weight: shape torch.Size([4]), requires_grad True
bias: shape torch.Size([4]), requires_grad True

InstanceNorm2d with affine=False:

Number of parameters (affine=True): 8
Number of parameters (affine=False): 0</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="random-noise---adding-randomness-to-the-g" class="level3">
<h3 class="anchored" data-anchor-id="random-noise---adding-randomness-to-the-g">Random Noise - Adding Randomness to the G</h3>
<p>A picture of a human has many random elements, e.g.&nbsp;the placement of freckles, hair, stubble among others. The important thing is that the exact placement of these doesn’t matter to the pereception of the image so long as they are distributed correctly (for example not abnormal patches in the hair) and we need a way for our model to accomodate generation of such stochastic features.</p>
<p>In a traditional G, such stochastic variation is achieved by the model learning a way to generate pseudo-random numbers from just the input latent vector. This scheme is quite difficult to get right, as seen by repeated patterns in other GAN architectures. The StyleGAN skips this by inserting random noise after each convolutional layer. This technique is very interesting as it only seems to affect the stochastic aspects of the images and leaves the high level aspects of the image remain unchanged. Also, the effects are localised throughout the network, i.e.&nbsp;different noise layers affect subsets of the image uniquely, the authors state this is because at any point in the G there is pressure to generate new things and the easiest way to generate randomess is to take advantage of the newly added noise. Each layer has a new set of noise, so there is no pressure to reuse old noise (due to normalisation).</p>
<p>Lastly, referring back to Figure 2 we see the noise output passes through an operation <span class="math inline">\(\textbf{B}\)</span>. <span class="math inline">\(\textbf{B}\)</span> is a learned per-channel scaling factor for the noise input, it will ensure the number of channels matches the number of channels at the current layer. Other than that, I’m not sure why it is a learned operation.</p>
<p>Now let’s implement the noise layer!</p>
<div id="1fcf3503-048a-49b5-b497-58c94684d4f7" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We make use of PyTorch modules again, it's a very useful class and we make use of it a lot.</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NoiseLayer(nn.Module):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;The only input is the number of channels we current have, we need this to ensure our weight parameter matches number of channels</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;in current layer</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This weight is for the "learned" aspect of the scaling</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weight <span class="op">=</span> nn.Parameter(torch.zeros(<span class="dv">1</span>, channels, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, gen_image, noise<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If noise is not initialised for this layer</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> noise <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;We want to match the dims of current model stage</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>            N, _, H, W <span class="op">=</span> gen_image.shape</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># generate the noise</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>            noise <span class="op">=</span> torch.randn(N, <span class="dv">1</span>, H, W, device<span class="op">=</span>gen_image.device)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The noise is added with a summation</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> gen_image <span class="op">+</span> (noise <span class="op">*</span> <span class="va">self</span>.weight)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="style-mixing" class="level3">
<h3 class="anchored" data-anchor-id="style-mixing">Style Mixing</h3>
<p>The last part of the G we will discuss is style mixing, also known as mixing regularisation<a href="#7"><sup>7</sup></a>. To enact this in our G, a given percentage of images are generated with two latent vectors (the percentage for us is 90%). The way it works is that we creating 2 <span class="math inline">\(\textbf{w}\)</span>’s by making two calls to the mapping network and then we choose a point in the network randomly to switch the <span class="math inline">\(\textbf{w}\)</span>’s. So, at a random point we switch <span class="math inline">\(\textbf{w}_1\)</span> with <span class="math inline">\(\textbf{w}_2\)</span> what this means is before the crossover the model uses <span class="math inline">\(\textbf{w}_1\)</span> and after it uses <span class="math inline">\(\textbf{w}_2\)</span>, hence the name style mixing. The effect of this is to prevent the network from assuming adjacent styles are correlated. Refer to Figure 5 to understand what is mean by adjacent style, basically it is style used in the AdaIN layers before and after the current layer. Without this regularisation technique the model may assume that adjacent styles are correlated, i.e.&nbsp;when one style changes so does another, as they are drawn from the same latent vector and by mixing styles we force the generator to handle cases where adjacent styles are different.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/346a05e8-caf6-4ed0-8a44-2efaee078571-1-b3f9885b-5155-40f6-88d4-445d810ae59c.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5 - These are adjacent styles occur, so by adjacent we mean the style that comes before or after the current style</figcaption>
</figure>
</div>
<p>I will implement style mixing within the G model, we’ll implement that right after we discuss the learned constant.</p>
</section>
<section id="learned-constant" class="level3">
<h3 class="anchored" data-anchor-id="learned-constant">Learned Constant</h3>
<p>In this model, we do not provide input directly to the model at the first layer. Instead our model starts from a learned constant. Essentially it will create the input itself, but once it is learned it stays the same for all inputs and at inference time it will be constant (you see what I did there…).</p>
<p>Why they chose to do this, I’m a unsure of but it is very interesting. Rather than providing explicit input at the first layer we essentially make the model learn where to start from</p>
<section id="on-a-fully-trained-network-show-what-the-learned-constant-looks-like" class="level5">
<h5 class="anchored" data-anchor-id="on-a-fully-trained-network-show-what-the-learned-constant-looks-like">On a fully trained network show what the learned constant looks like?</h5>
<div id="9285a677-271e-4502-9323-af81b51383f4" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LearnedConstant(nn.Module):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># in_c is the number of channels we start with</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_c):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We create a PyTorch parameter this is trainable. It has batch size 1</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The LearnedConstant is initialised to 1 as set out in the paper.</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.constant <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">1</span>, in_c, <span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;When we init the learned constant we pass in the batch size</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, batch_size):</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># It is expanded the match the batch_size currently in network, the rest of dims stay the same</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.constant.expand(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we have all the tools to implement our G model. So without further ado let’s get to it!</p>
</section>
</section>
</section>
<section id="the-generator-model" class="level2">
<h2 class="anchored" data-anchor-id="the-generator-model">The Generator Model</h2>
<p>We are finally here, the epitomy of the StyleGAN paper and this blog post. The G model is the key in the StyleGAN and we are about to embark on a journey to combine the pieces and make and awesome G model!!!</p>
<p>So here’s whats gonna happen, I will split the implementation into two parts. First comes the G_ConvBlock, the building block of our G and then the G model code.</p>
<section id="the-g-conv-block" class="level3">
<h3 class="anchored" data-anchor-id="the-g-conv-block">The G Conv Block</h3>
<p>If you’ve read the PGGAN post, you’ll recognise this following code box and also the small changes present. If you haven’t read the post, once again I highly recommend you do to build the StyleGAN I think it’s mandatory to implement the PGGAN too. The underlying architecture comes from the PGGAN, so to understand that is to understand the StyleGAN.</p>
<div id="ea756ff5-b58a-4951-9fd7-012a5282a5ca" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> G_ConvBlock(nn.Module):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        in_c, </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        out_c, </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        padding,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        upsample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> []</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Both ksize2 and padding2 will be used even if they are not set,</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if they are not set by parameters we just set them to ksize1 and padding</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If we upsample is True, we need to ensure we upsample the image. The StyleGAN uses bilinear upsampling</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># upsample=True is the default case</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> upsample:</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>                nn.Upsample(scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>),</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>                EqualLRConv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>                NoiseLayer(out_c),</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>                AdaIN(<span class="dv">256</span>, out_c),</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># upsample=False is only set for the first layer and at the first layer we must initialise the learned constant</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first block only has one convolution operation</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.learned_constant <span class="op">=</span> LearnedConstant(in_c)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>                NoiseLayer(in_c),</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>                AdaIN(<span class="dv">256</span>, in_c),</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The following addition to layers_list is always added</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># observe that the latent_dim size to AdaIN is always 256.</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        layers_list.extend([</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>            NoiseLayer(out_c),</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>            AdaIN(<span class="dv">256</span>, out_c),</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This is used to determine in the forward pass if we are at the first layer or not</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.upsample <span class="op">=</span> upsample</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, w, x<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># From the __init__ method, if we are the first layer we must run the forward pass of the learned_constant</span></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># w.size(0) is the batch_size</span></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.upsample:</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.learned_constant(w.size(<span class="dv">0</span>))</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;MAY BE ABLE TO GET RID OF THIS CAUSE LEARNED CONSTANT ISNT IN SELF.LAYERS</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, LearnedConstant):</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer()</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We need to distuingush if we are at an AdaIN layer as it expects a w input. The w is provided the the G_ConvBlock call</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(layer, AdaIN):</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                <span class="co">#&nbsp;When calling AdaIN we need to call mapping network</span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(w, x)</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x)</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-g-model" class="level3">
<h3 class="anchored" data-anchor-id="the-g-model">The G Model</h3>
<p>Next comes the full G model. Once again it’s similar to the PGGAN G model with some minor changes. A noticeable difference is the inclusion of style mixing, don’t worry though the comments will walk you through what is going on.</p>
<div id="a2865f77-fb0f-40a3-842b-3945caec757a" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_c<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We initialise the MappingNetwork withing the __init__ to "link" them. The MappingNetwork must be trained and is done so</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># w.r.t to the Generator loss. To achieve updates w.r.t to the G loss they need to be linked and by calling MappingNetwork here,</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># when we update the G model the gradients will flow back to the MappingNetwork too.</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.g_mapping <span class="op">=</span> MappingNetwork()</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We define a total of 7 G_ConvBlocks. The number of in channels and out channels follow the progressive growing regime from PGGAN</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Once again check out my PGGAN blog for a more in depth explanation. But in short, we start with 256 channels and end with 64</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The first layer has upsample=False so that we make the call to the learned_constant.</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_4x4 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>, upsample<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_8x8 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_16x16 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_32x32 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_64x64 <span class="op">=</span> G_ConvBlock(in_c, in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_128x128 <span class="op">=</span> G_ConvBlock(in_c<span class="op">//</span><span class="dv">2</span>, in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_256x256 <span class="op">=</span> G_ConvBlock(in_c<span class="op">//</span><span class="dv">4</span>, in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The output of the generator is always converted to an RGB image, an RGB image has 3 channels (red, green, blue)</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_4 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_8 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_16 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_32 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_64 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_128 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_256 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The output activation function ensures our outputs have value range [-1,1]</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> nn.Tanh()</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Notice that our forward pass is missing an "x" which is typical in PyTorch models, this is because of the learned_constant</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;and our model not having an input layer. Rather we pass in our latent vector z and also the current layer number and alpha value.</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, z, layer_num, alpha):   </span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first call to g_mapping</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> <span class="va">self</span>.g_mapping(z)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The following if statement encapsulates Style Mixing.</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We generate a random number in between 0-1 and if it is below 0.9 we enable style mixing. </span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;the 0.9 ensures that we enable style mixing for 90% of all batches.</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mixing is applied to 90% of the batches, from Table 2 in the StyleGAN paper</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.rand(<span class="dv">1</span>).item() <span class="op">&lt;</span> <span class="fl">0.9</span>:</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We sample a second latent vector, randn_like ensures the dims match the first latent vector</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>            z2 <span class="op">=</span> torch.randn_like(z)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate a second intermediate latent space</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>            w2 <span class="op">=</span> <span class="va">self</span>.g_mapping(z2)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;Need to choose a random crossover point</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>            crossover_point <span class="op">=</span> random.randint(<span class="dv">1</span>, layer_num)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>            crossover_point <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First check if style mixing is active for the current forward pass, this is done by checking if crossover_point is something other than None</span></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if it is None the first part of the if statement is False</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Then if style mixing is active we need to ensure we've reached the crossover point</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">1</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>        out_4 <span class="op">=</span> <span class="va">self</span>.block_4x4(w)  <span class="co">#&nbsp;First block has no input x</span></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_4(out_4)</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">2</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>        out_8 <span class="op">=</span> <span class="va">self</span>.block_8x8(w, out_4)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_4(out_4)</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_8(out_8)</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">3</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>        out_16 <span class="op">=</span> <span class="va">self</span>.block_16x16(w, out_8)</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_8(out_8)</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_16(out_16)</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">4</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>        out_32 <span class="op">=</span> <span class="va">self</span>.block_32x32(w, out_16)</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">4</span>:</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_16(out_16)</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_32(out_32)</span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">5</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>        out_64 <span class="op">=</span> <span class="va">self</span>.block_64x64(w, out_32)</span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">5</span>:</span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_32(out_32)</span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_64(out_64)</span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">6</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a>        out_128 <span class="op">=</span> <span class="va">self</span>.block_128x128(w, out_64)</span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">6</span>:</span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_64(out_64)</span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_128(out_128)</span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> crossover_point <span class="kw">and</span> <span class="dv">7</span> <span class="op">&gt;=</span> crossover_point:</span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a>            w <span class="op">=</span> w2</span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a>        out_256 <span class="op">=</span> <span class="va">self</span>.block_256x256(w, out_128)</span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">7</span>:</span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_128(out_128)</span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb14-131"><a href="#cb14-131" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_256(out_256)</span>
<span id="cb14-132"><a href="#cb14-132" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Generator().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bb72ccc5" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;</span><span class="al">TESTING</span><span class="co"> G</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>g_in <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>g_out <span class="op">=</span> g(g_in, alpha<span class="op">=</span><span class="fl">0.5</span>, layer_num<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>show_images(g_out), g_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There we have it the StyleGAN G model, now let’s train it!</p>
</section>
<section id="preparing-to-train-the-stylegan" class="level3">
<h3 class="anchored" data-anchor-id="preparing-to-train-the-stylegan">Preparing to Train the StyleGAN</h3>
<p>There a few things we should cover before we implement the training loop. Once again a lot of the details follow the PGGAN training setup but with a few changes, also I don’t follow the paper to the T here and I advise you not to either. They had trained on 8 V100 GPUs for a week, I have a single 3090 and for whatever card you have you may need to adapt the training scheme to make it run in a reasonable time and run with regards to your memory constraints.</p>
<p>Firstly, let’s implement the helper functions we use throughout the training loop. We have a get_dataloader, which will return a dataloader with different batch sizes (more to come). get_batch_size which is used in conjunction with the dataloader, we make use of different batch sizes based on the resolution<a href="#8"><sup>8</sup></a>. Next we have get_total_iters, we also train each layer for a different number of iterations this comes from the fact that the lower resolution layers converge quicker and as such we can save time by training them for less time. The different iteration training based on resolution was something I added, it saves us time and energy usage (a.k.a I have to spend less on my electricity bill). We also have get_params_with_lr, in the paper it is stated that the mapping network has a LR which is reduced by two orders of magnitude compared to the lr of the rest of the network. Given that we init the mapping network in G the mapping network params are in the G network and can be accessed based on their naming convention.</p>
<p>I include the code and comments for all these utilities in one code block below.</p>
<div id="9c13d822" class="cell" data-scrolled="true" data-execution_count="64">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloader(image_size, batch_size<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Just some basic transforms, image_size holds the resolution of the current layer</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># so we create a new dataloader after stabilising each layer</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((image_size, image_size)),  <span class="co"># Resize images to the required size</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># I assume your CelebA HQ 256 directory is in the same one as this notebook, feel free to change it</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ImageFolder(root<span class="op">=</span><span class="st">'./celeba_hq_256'</span>, transform<span class="op">=</span>transform)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataloader</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple mapping function, it doesn't really need to be a function but encapsulating it in one makes it </span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># clear to see what is happening. The batch sizes I pick are determined by me, </span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># feel free to experiment and change them</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_batch_size(resolution):</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    batch_sizes <span class="op">=</span> {</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="dv">4</span>: <span class="dv">128</span>,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        <span class="dv">8</span>: <span class="dv">128</span>,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        <span class="dv">16</span>: <span class="dv">128</span>,</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        <span class="dv">32</span>: <span class="dv">64</span>,</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        <span class="dv">64</span>: <span class="dv">32</span>,</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span class="dv">128</span>: <span class="dv">16</span>,</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        <span class="dv">256</span>: <span class="dv">8</span>,</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch_sizes.get(resolution) </span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Similar story here as for get_batch_size</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_total_iters(resolution):</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    total_iters <span class="op">=</span> {</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        <span class="dv">4</span>: <span class="dv">50000</span>,</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        <span class="dv">8</span>: <span class="dv">80000</span>,</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>        <span class="dv">16</span>: <span class="dv">100000</span>,</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        <span class="dv">32</span>: <span class="dv">150000</span>,</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        <span class="dv">64</span>: <span class="dv">150000</span>,</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        <span class="dv">128</span>: <span class="dv">200000</span>,</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        <span class="dv">256</span>: <span class="dv">225000</span>,</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_iters.get(resolution)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;To get the params for the mapping network we look for parameters with "mapping" in the name</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_params_with_lr(model):</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    mapping_params <span class="op">=</span> []</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    other_params <span class="op">=</span> []</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'mapping'</span> <span class="kw">in</span> name:  <span class="co"># Adjust this condition based on your actual naming convention</span></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>            mapping_params.append(param)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>            other_params.append(param)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mapping_params, other_params</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="co"># To illustrate how this works look at this</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> g.named_parameters():</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(name)</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;The naming convetion of PyTorch has the module name at the start. This is what we take advantage of</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>g_mapping.layers.0.linear.bias
g_mapping.layers.0.linear.weight_orig
g_mapping.layers.2.linear.bias
g_mapping.layers.2.linear.weight_orig
g_mapping.layers.4.linear.bias
g_mapping.layers.4.linear.weight_orig
g_mapping.layers.6.linear.bias
g_mapping.layers.6.linear.weight_orig
g_mapping.layers.8.linear.bias
g_mapping.layers.8.linear.weight_orig
g_mapping.layers.10.linear.bias
g_mapping.layers.10.linear.weight_orig
g_mapping.layers.12.linear.bias
g_mapping.layers.12.linear.weight_orig
g_mapping.layers.14.linear.bias
g_mapping.layers.14.linear.weight_orig
block_4x4.learned_constant.constant
block_4x4.layers.0.weight
block_4x4.layers.1.map_layer.linear.bias
block_4x4.layers.1.map_layer.linear.weight_orig
block_4x4.layers.3.conv.bias
block_4x4.layers.3.conv.weight_orig
block_4x4.layers.4.weight
block_4x4.layers.5.map_layer.linear.bias
block_4x4.layers.5.map_layer.linear.weight_orig
block_8x8.layers.1.conv.bias
block_8x8.layers.1.conv.weight_orig
block_8x8.layers.2.weight
block_8x8.layers.3.map_layer.linear.bias
block_8x8.layers.3.map_layer.linear.weight_orig
block_8x8.layers.5.conv.bias
block_8x8.layers.5.conv.weight_orig
block_8x8.layers.6.weight
block_8x8.layers.7.map_layer.linear.bias
block_8x8.layers.7.map_layer.linear.weight_orig
block_16x16.layers.1.conv.bias
block_16x16.layers.1.conv.weight_orig
block_16x16.layers.2.weight
block_16x16.layers.3.map_layer.linear.bias
block_16x16.layers.3.map_layer.linear.weight_orig
block_16x16.layers.5.conv.bias
block_16x16.layers.5.conv.weight_orig
block_16x16.layers.6.weight
block_16x16.layers.7.map_layer.linear.bias
block_16x16.layers.7.map_layer.linear.weight_orig
block_32x32.layers.1.conv.bias
block_32x32.layers.1.conv.weight_orig
block_32x32.layers.2.weight
block_32x32.layers.3.map_layer.linear.bias
block_32x32.layers.3.map_layer.linear.weight_orig
block_32x32.layers.5.conv.bias
block_32x32.layers.5.conv.weight_orig
block_32x32.layers.6.weight
block_32x32.layers.7.map_layer.linear.bias
block_32x32.layers.7.map_layer.linear.weight_orig
block_64x64.layers.1.conv.bias
block_64x64.layers.1.conv.weight_orig
block_64x64.layers.2.weight
block_64x64.layers.3.map_layer.linear.bias
block_64x64.layers.3.map_layer.linear.weight_orig
block_64x64.layers.5.conv.bias
block_64x64.layers.5.conv.weight_orig
block_64x64.layers.6.weight
block_64x64.layers.7.map_layer.linear.bias
block_64x64.layers.7.map_layer.linear.weight_orig
block_128x128.layers.1.conv.bias
block_128x128.layers.1.conv.weight_orig
block_128x128.layers.2.weight
block_128x128.layers.3.map_layer.linear.bias
block_128x128.layers.3.map_layer.linear.weight_orig
block_128x128.layers.5.conv.bias
block_128x128.layers.5.conv.weight_orig
block_128x128.layers.6.weight
block_128x128.layers.7.map_layer.linear.bias
block_128x128.layers.7.map_layer.linear.weight_orig
block_256x256.layers.1.conv.bias
block_256x256.layers.1.conv.weight_orig
block_256x256.layers.2.weight
block_256x256.layers.3.map_layer.linear.bias
block_256x256.layers.3.map_layer.linear.weight_orig
block_256x256.layers.5.conv.bias
block_256x256.layers.5.conv.weight_orig
block_256x256.layers.6.weight
block_256x256.layers.7.map_layer.linear.bias
block_256x256.layers.7.map_layer.linear.weight_orig
to_rgb_4.conv.bias
to_rgb_4.conv.weight_orig
to_rgb_8.conv.bias
to_rgb_8.conv.weight_orig
to_rgb_16.conv.bias
to_rgb_16.conv.weight_orig
to_rgb_32.conv.bias
to_rgb_32.conv.weight_orig
to_rgb_64.conv.bias
to_rgb_64.conv.weight_orig
to_rgb_128.conv.bias
to_rgb_128.conv.weight_orig
to_rgb_256.conv.bias
to_rgb_256.conv.weight_orig</code></pre>
</div>
</div>
<section id="frechet-inception-distance---fid" class="level4">
<h4 class="anchored" data-anchor-id="frechet-inception-distance---fid">Frechet-Inception Distance - FID</h4>
<p>Metrics are important, they help us reason about our work objectively. In the PGGAN post, to assess the quality of our images we simply looked at the photos and used our intuition, this isn’t a good practice as we (as humans) have biases and are usually not the best judges of quality. Think about what good generated images would look like and how would we assess it? We want our generated images to have variation (no mode collapse please), they should be high resolution and they should follow how the real images look (i.e.&nbsp;they should look real). These aspects are hard to formalise, but it can be achieved by the Frechet-Inception Distance.</p>
<p>In the StyleGAN paper, the authors use Frechet-Inception Distance (FID)<a href="#9"><sup>9</sup></a> as the metric to assess image quality. FID is quite cool, it’s goal is to compare the distribution of the generated images against the distribution of the real (ground truth) images. It does so using the Inception V3 image classification model, which is pretrained on the ImageNet dataset, namely we pass the real images and the generated images through the network and compute the mean and std-dev of the last layer prior to output of the Inception V3 model. The two sets of statistics are then compared against each other and we get an FID score, the lower the score the better the generated images are. It can detect mode collapse as a result of the std-dev comparison, if mode collapses std-dev will be very low and not close to real images std-dev.</p>
<p>FID does have some disadvantages, firstly the score is affected by the number of samples passed through. 10000 real and fake images is usually a good starting point, however I just the whole CelebA-HQ dataset which is 30000 images. I then also generated 30000 fake images and pass them to the FID function.</p>
<p>Let’s implement the helper function to calculate FID for our G model.</p>
<div id="f9d72220" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now sample 30k fake and add them to fid</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resize(images):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resize to 299x299, the inception v3 model expects 299,299 images so we just resize our images to</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># this size</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((<span class="dv">299</span>, <span class="dv">299</span>)),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> transform(images)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We make use of the FID class provided by the torchmetrics library provided by PyTorch Lightning</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># This class works by "adding" fake and real images to the model</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;So I create two functions, one for adding fake images and one for real images</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_fake_images(g_running, num_images, batch_size, latent_dim, device, layer_num, alpha<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;The function takes in g_running and all params needed to generate images</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we use g_running in this function as it is the model we use to output our fake images</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    g_running.<span class="bu">eval</span>()</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set torch.no_grad to turn off gradients, it makes the code run faster and use less memory as gradients</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;aren't tracked</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate 30000 images to pass to the FID model, we pass them as we generate them to save</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># images</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">0</span>, num_images, batch_size), desc<span class="op">=</span><span class="st">"Generating images"</span>):</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> torch.randn(batch_size, latent_dim, device<span class="op">=</span>device)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>            batch_images <span class="op">=</span> g_running(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># resize images</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            resize_batch <span class="op">=</span> resize(batch_images)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Inception v3 requires pixel ranges to be [0,255] currently it's [-1,1], </span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># this line handles the conversion</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>            resize_batch <span class="op">=</span> ((resize_batch <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> <span class="fl">127.5</span>).clamp(<span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Inception v3 also expects input data type to be uint8, this can be handled with a simple cast</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>            resize_batch <span class="op">=</span> resize_batch.to(torch.uint8)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update FID</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>            fid.update(resize_batch, real<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Clear GPU cache, to save memory</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>            torch.cuda.empty_cache()</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;The second function just takes in the data_loader as a parm</span></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_real_imgs(data_loader):</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we pass all batches to the FID model i.e. 30k images</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> tqdm(data_loader, desc<span class="op">=</span><span class="st">"Processing real images"</span>):</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>        imgs, _ <span class="op">=</span> batch</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Resize, convert to [0,255] range and cast to uint8 as before</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        imgs <span class="op">=</span> resize(imgs)</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        imgs <span class="op">=</span> imgs.to(device)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>        imgs <span class="op">=</span> ((imgs <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> <span class="fl">127.5</span>).clamp(<span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        imgs <span class="op">=</span> imgs.to(torch.uint8)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>        fid.update(imgs, real<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Final function which combines both of the image adding functions</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_and_save_fid(layer_num, iteration, data_loader, g_running, num_fake_images, batch_size, latent_dim, device, fid_file, alpha<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;We reset the FID score statistics for recalculation</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>    fid.reset()</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the real and fake images</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    add_fake_images(g_running, num_fake_images, batch_size, latent_dim, device, layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>    add_real_imgs(data_loader)</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute FID score and output it</span></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>    fid_score <span class="op">=</span> fid.compute()</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"FID score for layer </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">, iteration </span><span class="sc">{</span>iteration<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>fid_score<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;We also save the scores to a file</span></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(fid_file, <span class="st">'a'</span>) <span class="im">as</span> f:</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>        f.write(<span class="ss">f"Layer </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">, Iteration </span><span class="sc">{</span>iteration<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>fid_score<span class="sc">.</span>item()<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So there we have all the helper functions we will be using to train our StyleGAN.</p>
</section>
</section>
</section>
<section id="training-the-stylegan" class="level2">
<h2 class="anchored" data-anchor-id="training-the-stylegan">Training the StyleGAN</h2>
<p>Quickly, before we set off if you have read the Goodfellow GAN or PGGAN blog this part of the blog will look a little different. I made some discoveries while training this model, firstly Jupyter notebooks are not a good medium (in my experience at least) for large training runs. My kernel died more times than I would like while training the StyleGAN often costing hours of progress, energy and time, even with the checkpoints. I love notebooks, but I think for this sort of stuff they are not optimised and going forwards I think I will stick with them for prototyping (the feedback from a notebook is amazing) and then make use of actual python files for the training loops (or any other long running code). To this end, I will provide a link to the python files for training (check out the sidebar on the right) and the output’s here will look different as I have to load the images from disk rather than them being outputted straight to the notebook as before.</p>
<p>Now that that’s out of the way, let’s take a look at the training loop! (Given the use of .py file for training the loop in that file may look slightly different, but is functionally the same)</p>
<section id="the-training-loop---were-almost-there" class="level4">
<h4 class="anchored" data-anchor-id="the-training-loop---were-almost-there">The Training Loop - We’re almost there!</h4>
<p>So we’re here, the culmination of all our struggles now it’s time to see what they get us. Let’s get an overview of the training loop, refer to code comments for further details. Firstly, we generate our checkpoint and sample directories, I also create an “fid.txt” file to keep track of FID scores). Next, we intialise our D, G, G_running and fid models. Setup our optimisers, accounting for the learning rate adjusment required for the mapping network. Then there’s some boring stuff and then we start training. The training scheme is the same as the first post, two for loops one for introducing the network and the second for stabilisation. This training loop may take a while to run, in the paper the authors stated the FID kept decreasing when using this model compared to PGGAN so to get it to converge we need to have a longer training loop.</p>
<div id="2d1198de" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create new checkpoint dir with timestamp</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>timestamp <span class="op">=</span> datetime.now().strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">_%H%M%S"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>run_dir <span class="op">=</span> os.path.join(<span class="st">'./checkpoints'</span>, <span class="ss">f'run_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>checkpoint_dir <span class="op">=</span> os.path.join(run_dir, <span class="ss">f"checkpoint_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>sample_dir <span class="op">=</span> os.path.join(run_dir, <span class="ss">f"sample_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Create a file to log FID scores</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>fid_file <span class="op">=</span> os.path.join(run_dir, <span class="st">'fid.txt'</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>os.makedirs(checkpoint_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>os.makedirs(sample_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Init models</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Generator().to(device)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Discriminator().to(device)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>g_running <span class="op">=</span> Generator().to(device)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove gradients from g_running as they're not needed</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>g_running.train(<span class="va">False</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Init FID model, feature=2048 means which layer to use for FID calculation. The number represents the number of</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="co"># features, 2048 corresponds to the last layer prior to output as we discussed. You can use layers before this one.</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;such as 64, 192, 768 but I found these report lower FID I guess it's because they aren't as good. Correct me on that</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co"># if I'm wrong</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>fid <span class="op">=</span> FrechetInceptionDistance(feature<span class="op">=</span><span class="dv">2048</span>).to(device)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Get all the params of G model, specifically we care about the mapping_params.</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>mapping_params, other_params <span class="op">=</span> get_params_with_lr(g)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co"># learning rate is set to 0.001 for all network except mapping network which is set to 0.001 * 0.01</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="co"># The optimisers are the same as in PGGAN in all regards except mapping network (which wasn't in PGGAN at all</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co"># anyways)</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.001</span> <span class="co"># Try 0.003? Or reduce LR as progreesing. 0.005 for layers 1-3 then 0.003</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>g_optimizer <span class="op">=</span> torch.optim.Adam([</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'params'</span>: mapping_params, <span class="st">'lr'</span>: lr <span class="op">*</span> <span class="fl">0.01</span>},  <span class="co"># 0.01 * LR for mapping network</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'params'</span>: other_params, <span class="st">'lr'</span>: lr}  <span class="co"># Regular LR for other parts</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>], betas<span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">0.99</span>))</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>d_optimizer <span class="op">=</span> torch.optim.Adam(d.parameters(), lr<span class="op">=</span>lr, betas<span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">0.99</span>))</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="co"># The following stuff is for checkpoint. These are very handy as training can fail and it saves us alot</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="co"># time to just run from checkpoint instead of the whole thing again.</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>start_layer <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>start_iter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if resuming from a checkpoint</span></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>resume_checkpoint <span class="op">=</span> <span class="va">False</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="co"># resume_checkpoint = If you have a checkpoint replace this with the path of checkpoint file</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> resume_checkpoint:</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.isfile(resume_checkpoint):</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If checkpoint exists we load everything needed to resume training</span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Note we save checkpoints only after completely stabilising a layer</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"=&gt; loading checkpoint '</span><span class="sc">{</span>resume_checkpoint<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        checkpoint <span class="op">=</span> torch.load(resume_checkpoint, weights_only<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        start_layer <span class="op">=</span> checkpoint[<span class="st">'layer_num'</span>] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        start_iter <span class="op">=</span> checkpoint[<span class="st">'iteration'</span>] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>        g.load_state_dict(checkpoint[<span class="st">'g_state_dict'</span>])</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>        d.load_state_dict(checkpoint[<span class="st">'d_state_dict'</span>])</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>        g_running.load_state_dict(checkpoint[<span class="st">'g_running_state_dict'</span>])</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>        g_optimizer.load_state_dict(checkpoint[<span class="st">'g_optimizer_state_dict'</span>])</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>        d_optimizer.load_state_dict(checkpoint[<span class="st">'d_optimizer_state_dict'</span>])</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"=&gt; loaded checkpoint '</span><span class="sc">{</span>resume_checkpoint<span class="sc">}</span><span class="ss">' (layer </span><span class="sc">{</span>start_layer<span class="sc">}</span><span class="ss">, iteration </span><span class="sc">{</span>start_iter<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"=&gt; no checkpoint found at '</span><span class="sc">{</span>resume_checkpoint<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Starting training from the beginning"</span>)</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Init EMA </span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>EMA(g_running, g, <span class="dv">0</span>)</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a><span class="co"># List of image sizes</span></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>]</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="co"># We evaluate FID every 10k iterations</span></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>num_iters_for_eval <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We want to gen 30k fake images for FID calculation to match 30k real images</span></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>num_fake_images <span class="op">=</span> <span class="dv">30000</span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">256</span>  <span class="co"># Adjust based on your model's input size</span></span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Start_layer to 8 we start by introducing the current resolution layer</span></span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer_num <span class="kw">in</span> <span class="bu">range</span>(start_layer, <span class="dv">8</span>):</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get current resolution</span></span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a>    resolution <span class="op">=</span> img_size[layer_num<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get batch size, total iters for current layer and the data loader for this layer</span></span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> get_batch_size(resolution)</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>    total_iters <span class="op">=</span> get_total_iters(resolution)</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> get_dataloader(resolution, batch_size)</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Init a progress bar</span></span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Training resolution: </span><span class="sc">{</span>resolution<span class="sc">}</span><span class="ss">x</span><span class="sc">{</span>resolution<span class="sc">}</span><span class="ss">, Batch size: </span><span class="sc">{</span>batch_size<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a>    pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(total_iters))</span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Begin introducing layer phase</span></span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> pbar:</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a>        d.zero_grad()</span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> (<span class="pp">OSError</span>, <span class="pp">StopIteration</span>):</span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If we reach the end of the dataset, we reintialise the iterable</span></span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a>            <span class="co"># basically starting again</span></span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a>            dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Train D</span></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a>        real_size <span class="op">=</span> real_imgs.size(<span class="dv">0</span>)</span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> real_imgs.to(device)</span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> label.to(device)</span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> d(real_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The line below implements a small weight penalty</span></span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>        <span class="co"># It ensures the D loss isnt too far away from 0 preventing extreme outputs </span></span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> real_preds.mean() <span class="op">-</span> <span class="fl">0.001</span> <span class="op">*</span> (real_preds<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample input for G</span></span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-121"><a href="#cb19-121" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs.detach(), layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-122"><a href="#cb19-122" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> gen_preds.mean() </span>
<span id="cb19-123"><a href="#cb19-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-124"><a href="#cb19-124" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient Penalty - GP</span></span>
<span id="cb19-125"><a href="#cb19-125" aria-hidden="true" tabindex="-1"></a>        eps <span class="op">=</span> torch.rand((real_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb19-126"><a href="#cb19-126" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())</span>
<span id="cb19-127"><a href="#cb19-127" aria-hidden="true" tabindex="-1"></a>        x_hat.requires_grad_(<span class="va">True</span>)</span>
<span id="cb19-128"><a href="#cb19-128" aria-hidden="true" tabindex="-1"></a>        pred_x_hat <span class="op">=</span> d(x_hat, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-129"><a href="#cb19-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-130"><a href="#cb19-130" aria-hidden="true" tabindex="-1"></a>        WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()</span>
<span id="cb19-131"><a href="#cb19-131" aria-hidden="true" tabindex="-1"></a>        grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb19-132"><a href="#cb19-132" aria-hidden="true" tabindex="-1"></a>            outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb19-133"><a href="#cb19-133" aria-hidden="true" tabindex="-1"></a>            grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb19-134"><a href="#cb19-134" aria-hidden="true" tabindex="-1"></a>            create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb19-135"><a href="#cb19-135" aria-hidden="true" tabindex="-1"></a>        )[<span class="dv">0</span>]</span>
<span id="cb19-136"><a href="#cb19-136" aria-hidden="true" tabindex="-1"></a>        GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean() </span>
<span id="cb19-137"><a href="#cb19-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-138"><a href="#cb19-138" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb19-139"><a href="#cb19-139" aria-hidden="true" tabindex="-1"></a>        d_loss.backward()</span>
<span id="cb19-140"><a href="#cb19-140" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb19-141"><a href="#cb19-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-142"><a href="#cb19-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now lets train the Generator</span></span>
<span id="cb19-143"><a href="#cb19-143" aria-hidden="true" tabindex="-1"></a>        g.zero_grad()</span>
<span id="cb19-144"><a href="#cb19-144" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-145"><a href="#cb19-145" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-146"><a href="#cb19-146" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-147"><a href="#cb19-147" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()</span>
<span id="cb19-148"><a href="#cb19-148" aria-hidden="true" tabindex="-1"></a>        g_loss.backward()</span>
<span id="cb19-149"><a href="#cb19-149" aria-hidden="true" tabindex="-1"></a>        g_optimizer.step()</span>
<span id="cb19-150"><a href="#cb19-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-151"><a href="#cb19-151" aria-hidden="true" tabindex="-1"></a>        EMA(g_running, g)</span>
<span id="cb19-152"><a href="#cb19-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-153"><a href="#cb19-153" aria-hidden="true" tabindex="-1"></a>        inc <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">/</span> (<span class="bu">len</span>(pbar)<span class="op">-</span>i)</span>
<span id="cb19-154"><a href="#cb19-154" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">+=</span> inc   </span>
<span id="cb19-155"><a href="#cb19-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-156"><a href="#cb19-156" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> num_iters_for_eval <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-157"><a href="#cb19-157" aria-hidden="true" tabindex="-1"></a>            sample_z <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-158"><a href="#cb19-158" aria-hidden="true" tabindex="-1"></a>            sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-159"><a href="#cb19-159" aria-hidden="true" tabindex="-1"></a>            save_image(sample_imgs_EMA, <span class="ss">f'</span><span class="sc">{</span>sample_dir<span class="sc">}</span><span class="ss">/sample_intro_layer_</span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">_iter_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">.png'</span>, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-160"><a href="#cb19-160" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Introducing - G_running images images after iter: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> | alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-161"><a href="#cb19-161" aria-hidden="true" tabindex="-1"></a>            show_images(sample_imgs_EMA)</span>
<span id="cb19-162"><a href="#cb19-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-163"><a href="#cb19-163" aria-hidden="true" tabindex="-1"></a>            calculate_and_save_fid(layer_num, i, data_loader, g_running, num_fake_images, batch_size, latent_dim, device, fid_file, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-164"><a href="#cb19-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-165"><a href="#cb19-165" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-166"><a href="#cb19-166" aria-hidden="true" tabindex="-1"></a>        sample_z <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-167"><a href="#cb19-167" aria-hidden="true" tabindex="-1"></a>        sample_imgs <span class="op">=</span> g(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-168"><a href="#cb19-168" aria-hidden="true" tabindex="-1"></a>        sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-169"><a href="#cb19-169" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Images after introducing layer: </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss"> | alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-170"><a href="#cb19-170" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G images'</span>)</span>
<span id="cb19-171"><a href="#cb19-171" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs)</span>
<span id="cb19-172"><a href="#cb19-172" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G_running images'</span>)</span>
<span id="cb19-173"><a href="#cb19-173" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs_EMA)</span>
<span id="cb19-174"><a href="#cb19-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-175"><a href="#cb19-175" aria-hidden="true" tabindex="-1"></a>        calculate_and_save_fid(layer_num, <span class="st">'final intro'</span>, data_loader, g_running, num_fake_images, batch_size, latent_dim, device, fid_file, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-176"><a href="#cb19-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-177"><a href="#cb19-177" aria-hidden="true" tabindex="-1"></a>    stabilise_pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(total_iters))</span>
<span id="cb19-178"><a href="#cb19-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> stabilise_pbar:</span>
<span id="cb19-179"><a href="#cb19-179" aria-hidden="true" tabindex="-1"></a>        d.zero_grad()</span>
<span id="cb19-180"><a href="#cb19-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-181"><a href="#cb19-181" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb19-182"><a href="#cb19-182" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb19-183"><a href="#cb19-183" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> (<span class="pp">OSError</span>, <span class="pp">StopIteration</span>):</span>
<span id="cb19-184"><a href="#cb19-184" aria-hidden="true" tabindex="-1"></a>            dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb19-185"><a href="#cb19-185" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb19-186"><a href="#cb19-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-187"><a href="#cb19-187" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Train D</span></span>
<span id="cb19-188"><a href="#cb19-188" aria-hidden="true" tabindex="-1"></a>        real_size <span class="op">=</span> real_imgs.size(<span class="dv">0</span>)</span>
<span id="cb19-189"><a href="#cb19-189" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> real_imgs.to(device)</span>
<span id="cb19-190"><a href="#cb19-190" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> label.to(device)</span>
<span id="cb19-191"><a href="#cb19-191" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> d(real_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-192"><a href="#cb19-192" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> real_preds.mean() <span class="op">-</span> <span class="fl">0.001</span> <span class="op">*</span> (real_preds<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb19-193"><a href="#cb19-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-194"><a href="#cb19-194" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample input for G</span></span>
<span id="cb19-195"><a href="#cb19-195" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-196"><a href="#cb19-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-197"><a href="#cb19-197" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-198"><a href="#cb19-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-199"><a href="#cb19-199" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs.detach(), layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-200"><a href="#cb19-200" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> gen_preds.mean()</span>
<span id="cb19-201"><a href="#cb19-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-202"><a href="#cb19-202" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient Penalty - GP</span></span>
<span id="cb19-203"><a href="#cb19-203" aria-hidden="true" tabindex="-1"></a>        eps <span class="op">=</span> torch.rand((real_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb19-204"><a href="#cb19-204" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())</span>
<span id="cb19-205"><a href="#cb19-205" aria-hidden="true" tabindex="-1"></a>        x_hat.requires_grad_(<span class="va">True</span>)</span>
<span id="cb19-206"><a href="#cb19-206" aria-hidden="true" tabindex="-1"></a>        pred_x_hat <span class="op">=</span> d(x_hat, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-207"><a href="#cb19-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-208"><a href="#cb19-208" aria-hidden="true" tabindex="-1"></a>        WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()</span>
<span id="cb19-209"><a href="#cb19-209" aria-hidden="true" tabindex="-1"></a>        grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb19-210"><a href="#cb19-210" aria-hidden="true" tabindex="-1"></a>            outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb19-211"><a href="#cb19-211" aria-hidden="true" tabindex="-1"></a>            grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb19-212"><a href="#cb19-212" aria-hidden="true" tabindex="-1"></a>            create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb19-213"><a href="#cb19-213" aria-hidden="true" tabindex="-1"></a>        )[<span class="dv">0</span>]</span>
<span id="cb19-214"><a href="#cb19-214" aria-hidden="true" tabindex="-1"></a>        GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean() </span>
<span id="cb19-215"><a href="#cb19-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-216"><a href="#cb19-216" aria-hidden="true" tabindex="-1"></a>        <span class="co"># WGAN_GP_loss = d_loss</span></span>
<span id="cb19-217"><a href="#cb19-217" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb19-218"><a href="#cb19-218" aria-hidden="true" tabindex="-1"></a>        d_loss.backward()</span>
<span id="cb19-219"><a href="#cb19-219" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb19-220"><a href="#cb19-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-221"><a href="#cb19-221" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now lets train the Generator</span></span>
<span id="cb19-222"><a href="#cb19-222" aria-hidden="true" tabindex="-1"></a>        g.zero_grad()</span>
<span id="cb19-223"><a href="#cb19-223" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-224"><a href="#cb19-224" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-225"><a href="#cb19-225" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-226"><a href="#cb19-226" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()</span>
<span id="cb19-227"><a href="#cb19-227" aria-hidden="true" tabindex="-1"></a>        g_loss.backward()</span>
<span id="cb19-228"><a href="#cb19-228" aria-hidden="true" tabindex="-1"></a>        g_optimizer.step()</span>
<span id="cb19-229"><a href="#cb19-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-230"><a href="#cb19-230" aria-hidden="true" tabindex="-1"></a>        EMA(g_running, g)</span>
<span id="cb19-231"><a href="#cb19-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-232"><a href="#cb19-232" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> num_iters_for_eval <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-233"><a href="#cb19-233" aria-hidden="true" tabindex="-1"></a>            sample_z <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-234"><a href="#cb19-234" aria-hidden="true" tabindex="-1"></a>            sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-235"><a href="#cb19-235" aria-hidden="true" tabindex="-1"></a>            save_image(sample_imgs_EMA, <span class="ss">f'</span><span class="sc">{</span>sample_dir<span class="sc">}</span><span class="ss">/sample_stabilising_layer_</span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">_iter_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">.png'</span>, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-236"><a href="#cb19-236" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Stabilising - G_running images images after iter: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> | alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-237"><a href="#cb19-237" aria-hidden="true" tabindex="-1"></a>            show_images(sample_imgs_EMA)</span>
<span id="cb19-238"><a href="#cb19-238" aria-hidden="true" tabindex="-1"></a>            calculate_and_save_fid(layer_num, i, data_loader, g_running, num_fake_images, batch_size, latent_dim, device, fid_file, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-239"><a href="#cb19-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-240"><a href="#cb19-240" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-241"><a href="#cb19-241" aria-hidden="true" tabindex="-1"></a>        sample_z <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">256</span>, device<span class="op">=</span>device)</span>
<span id="cb19-242"><a href="#cb19-242" aria-hidden="true" tabindex="-1"></a>        sample_imgs <span class="op">=</span> g(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-243"><a href="#cb19-243" aria-hidden="true" tabindex="-1"></a>        sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-244"><a href="#cb19-244" aria-hidden="true" tabindex="-1"></a>        save_image(sample_imgs_EMA, <span class="ss">f'</span><span class="sc">{</span>sample_dir<span class="sc">}</span><span class="ss">/sample_layer_</span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">_completed.png'</span>, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-245"><a href="#cb19-245" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Images after stabilising layer: </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss"> | alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-246"><a href="#cb19-246" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G images'</span>)</span>
<span id="cb19-247"><a href="#cb19-247" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs)</span>
<span id="cb19-248"><a href="#cb19-248" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G_running images'</span>)</span>
<span id="cb19-249"><a href="#cb19-249" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs_EMA)</span>
<span id="cb19-250"><a href="#cb19-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-251"><a href="#cb19-251" aria-hidden="true" tabindex="-1"></a>        calculate_and_save_fid(layer_num, <span class="st">'final_stable'</span>, data_loader, g_running, num_fake_images, batch_size, latent_dim, device, fid_file, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-252"><a href="#cb19-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-253"><a href="#cb19-253" aria-hidden="true" tabindex="-1"></a>    torch.save({</span>
<span id="cb19-254"><a href="#cb19-254" aria-hidden="true" tabindex="-1"></a>        <span class="st">'g_state_dict'</span>: g.state_dict(),</span>
<span id="cb19-255"><a href="#cb19-255" aria-hidden="true" tabindex="-1"></a>        <span class="st">'g_running_state_dict'</span>: g_running.state_dict(),</span>
<span id="cb19-256"><a href="#cb19-256" aria-hidden="true" tabindex="-1"></a>        <span class="st">'d_state_dict'</span>: d.state_dict(),</span>
<span id="cb19-257"><a href="#cb19-257" aria-hidden="true" tabindex="-1"></a>        <span class="st">'g_optimizer_state_dict'</span>: g_optimizer.state_dict(),</span>
<span id="cb19-258"><a href="#cb19-258" aria-hidden="true" tabindex="-1"></a>        <span class="st">'d_optimizer_state_dict'</span>: d_optimizer.state_dict(),</span>
<span id="cb19-259"><a href="#cb19-259" aria-hidden="true" tabindex="-1"></a>        <span class="st">'layer_num'</span>: layer_num,</span>
<span id="cb19-260"><a href="#cb19-260" aria-hidden="true" tabindex="-1"></a>        <span class="st">'iteration'</span>: i</span>
<span id="cb19-261"><a href="#cb19-261" aria-hidden="true" tabindex="-1"></a>    }, <span class="ss">f'</span><span class="sc">{</span>checkpoint_dir<span class="sc">}</span><span class="ss">/completed_checkpoint_g_and_EMA_layer_</span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">.pth'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-training-process" class="level4">
<h4 class="anchored" data-anchor-id="the-training-process">The Training Process</h4>
<div id="72e7cdfc-fd16-4719-b64e-931f8ebe374b" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_data(csv_filename):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> {}</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(csv_filename, <span class="st">'r'</span>) <span class="im">as</span> csvfile:</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        reader <span class="op">=</span> csv.reader(csvfile)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">next</span>(reader)  <span class="co"># Skip header</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> row <span class="kw">in</span> reader:</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>            layer, iteration, fid <span class="op">=</span> row</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> layer <span class="kw">not</span> <span class="kw">in</span> data:</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                data[layer] <span class="op">=</span> {<span class="st">'iterations'</span>: [], <span class="st">'fids'</span>: []}</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>            iteration <span class="op">=</span> <span class="bu">int</span>(iteration)  <span class="co"># All iterations are now numeric</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>            data[layer][<span class="st">'iterations'</span>].append(iteration)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>            data[layer][<span class="st">'fids'</span>].append(<span class="bu">float</span>(fid))</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_plots(processed_data):</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    num_layers <span class="op">=</span> <span class="bu">len</span>(processed_data)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> (num_layers <span class="op">+</span> <span class="dv">1</span>) <span class="op">//</span> <span class="dv">2</span>  <span class="co"># Calculate number of rows (2 plots per row)</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(rows, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span> <span class="op">*</span> rows))</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (layer, layer_data) <span class="kw">in</span> <span class="bu">enumerate</span>(processed_data.items()):</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> idx <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        col <span class="op">=</span> idx <span class="op">%</span> <span class="dv">2</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[row, col] <span class="cf">if</span> rows <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> axes[col]</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        ax.plot(layer_data[<span class="st">'iterations'</span>], layer_data[<span class="st">'fids'</span>], marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">'Iterations'</span>)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">'FID Score (log scale)'</span>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f'Layer </span><span class="sc">{</span>layer<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        ax.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        ax.grid(<span class="va">True</span>)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set x-axis to log scale</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        ax.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add text annotations for final points</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        last_x <span class="op">=</span> layer_data[<span class="st">'iterations'</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>        last_y <span class="op">=</span> layer_data[<span class="st">'fids'</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>        ax.annotate(<span class="ss">f'Final: </span><span class="sc">{</span>last_y<span class="sc">:.2f}</span><span class="ss">'</span>, (last_x, last_y), </span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>                    textcoords<span class="op">=</span><span class="st">"offset points"</span>, xytext<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">10</span>), ha<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set y-axis limits to start from a non-zero value</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        ax.set_ylim(bottom<span class="op">=</span><span class="bu">max</span>(<span class="fl">0.1</span>, <span class="bu">min</span>(layer_data[<span class="st">'fids'</span>])<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove any unused subplots</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_layers <span class="op">%</span> <span class="dv">2</span> <span class="op">!=</span> <span class="dv">0</span> <span class="kw">and</span> rows <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>        fig.delaxes(axes[rows<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Process the data</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>processed_data <span class="op">=</span> process_data(<span class="st">'./processed_fid_scores.csv'</span>)</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plots</span></span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>create_plots(processed_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There we have it, the trained StyleGAN! A few points to note, examine the FID scores and note down any patterns and then read on.</p>
<p>Firstly, for layer 1 the FID is usually lowest in the early iterations and then increases. I think this is due to the model overfitting and for some reason not having a previous layer to introduce and stabilise causes this issue as you see it less in the further layers. Then again, in the later layers as alpha grows you see the FID decrease until about the halfway point after which at some point it increases and usually has a large jump at the end of the introduction phase of a new layer, this is what necessitates the stabilisation phase. It’s cool to see this play out in practise. Also, observe how the instability increases the more layers we add and in turn increase the resolution</p>
<p>A <b>BIG</b> disclaimer, my FID for layer 7 is nowhere near where the paper gets to. Honestly, I have no idea why and I’ve retrained this model many times. It takes about 7 days to train on my 3090, the authors trained it for a week on 8 V100 GPU’s, I think this is why - they had much more power and trained the model for a lot longer than I can. Reach out to me if you have more idea’s, I had tried to decrease the FID as much as possible but it just won’t budge.</p>
</section>
<section id="stylegan-images" class="level4">
<h4 class="anchored" data-anchor-id="stylegan-images">StyleGAN Images</h4>
<p>Lastly, lets take a look at the images we generated. This isn’t a handpicked sample, at the end of each layer’s training I generate 16 images and this is what I will show here.</p>
<div id="b33a3703-ccab-4437-91a9-a7f89d0b44f1" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code-fold:true</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>img_dir <span class="op">=</span> <span class="st">'./python_implementations/StyleGAN/checkpoints/final_styleGAN_run/sample_20240915_115437'</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">15</span>))  <span class="co"># Adjust the figure size as needed</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">8</span>):</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    image_path <span class="op">=</span> glob.glob(<span class="ss">f"</span><span class="sc">{</span>img_dir<span class="sc">}</span><span class="ss">/sample_layer_</span><span class="sc">{</span>layer<span class="sc">}</span><span class="ss">_completed.png"</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_path:</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, layer)  <span class="co"># 3x3 grid of subplots</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> plt.imread(image_path[<span class="dv">0</span>])</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        plt.imshow(img)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f"Layer </span><span class="sc">{</span>layer<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)  <span class="co"># Turn off axis labels</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"No image found for Layer </span><span class="sc">{</span>layer<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="StyleGAN_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There we have it! We’ve trained our own StyleGAN and we march forwards to StyleGAN 2! The images arent the best and nowhere near what was reported in the paper, so is the consquence of being GPU poor. Nonetheless, well done! I hope you had fun and look out for the next one :)</p>
<hr>
<p><a id="1" style="text-decoration: none; color: inherit;" href=""><sup>1</sup></a> <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf</a></p>
<p><a id="2" style="text-decoration: none; color: inherit;" href=""><sup>2</sup></a> A linear subspace means some spaces of the vector <span class="math inline">\(\textbf{w}\)</span> and the factors of variation are the different aspects of a face. E.g. hair colour, skin colour, nose shape, nose position, eyelid shape placement of ears etc (this is not concrete it is just an explanation). So what does it mean, I take it as different areas of the vector control different areas of the generated images, for example dimensions 1-24 of <span class="math inline">\(\textbf{w}\)</span> could correspond to face placement i.e.&nbsp;subsets of the vector directly control different aspects of the images generation. If I am wrong here please let me know @ <a href="mailto:y%75sufmohamma%64@l%69ve.com">yusufmohammad@live.com</a></p>
<p><a id="3" style="text-decoration: none; color: inherit;" href=""><sup>3</sup></a> <a href="https://arxiv.org/pdf/1703.06868">https://arxiv.org/pdf/1703.06868</a></p>
<p><a id="4" style="text-decoration: none; color: inherit;" href=""><sup>4</sup></a> Bear with me here, this is quite confusing at first but I will explain it as we go along.</p>
<p><a id="5" style="text-decoration: none; color: inherit;" href=""><sup>5</sup></a> <a href="https://arxiv.org/pdf/1703.06868">https://arxiv.org/pdf/1703.06868</a></p>
<p><a id="6" style="text-decoration: none; color: inherit;" href=""><sup>6</sup></a> A “latent vector” just means a hidden vector. I.e. something which we cannot modify or observe. A latent vector acts as a lower dimensional code (lower dimensional compared to the output), which the GAN can use to encode into an image. This is what the GAN is learning to do.</p>
<p><a id="7" style="text-decoration: none; color: inherit;" href=""><sup>7</sup></a> Regularisation is a mathematical technique to make model “simpler”. I think it follows the principle of parsimony where simpler things are preferred as they are more likely to be true. It also prevents overfitting.</p>
<p><a id="8" style="text-decoration: none; color: inherit;" href=""><sup>8</sup></a> When using this function you may need to reduce the batch sizes based on the memory of your GPU. When running the training loop if you face a memory error of max capacity used then reduce the batch sizes by a half and continue to do so until it works.</p>
<p><a id="9" style="text-decoration: none; color: inherit;" href=""><sup>9</sup></a> The paper which introduced the FID score is <a href="https://arxiv.org/pdf/1706.08500">https://arxiv.org/pdf/1706.08500</a>. Note that FID is still the standard metric used to assess generated image quality, showing it’s importance and usefulness.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>