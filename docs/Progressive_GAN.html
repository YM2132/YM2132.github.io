<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yusuf Mohammad">

<title>The Path to StyleGan2 - Progressive Growing GAN</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="Progressive_GAN_files/libs/clipboard/clipboard.min.js"></script>
<script src="Progressive_GAN_files/libs/quarto-html/quarto.js"></script>
<script src="Progressive_GAN_files/libs/quarto-html/popper.min.js"></script>
<script src="Progressive_GAN_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Progressive_GAN_files/libs/quarto-html/anchor.min.js"></script>
<link href="Progressive_GAN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Progressive_GAN_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Progressive_GAN_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Progressive_GAN_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Progressive_GAN_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="https://ym2132.github.io/"><i class="bi bi-link-45deg"></i>Yusuf's Deep Learning Blog</a></li><li><a href="https://github.com/YM2132?tab=repositories"><i class="bi bi-link-45deg"></i>Yusuf's GitHub</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="www"><i class="bi bi-file-code"></i>Progressive_GAN.py</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Path to StyleGan2 - Progressive Growing GAN</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yusuf Mohammad </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<hr>
<p>This post is the first in a three part series, which will see us implement the StyleGAN2 architecure at its finale. The Progressive Growing GAN architecture is the foundation of the StyleGAN models, so we start our journey here. You can find the source paper for this post <a href="https://arxiv.org/pdf/1710.10196">here</a>.</p>
<hr>
<h2 class="anchored">
The Traditional GAN and its Issues
</h2>
<p>The problem with the traditional Goodfellow Generative Adversarial Network, is that it isn’t good at generating high resolution images<a href="#1"><sup>1</sup></a>.</p>
<p>The GAN<a href="#2"><sup>2</sup></a> consists of two models, a Generator and a Discriminator. They are pitted against each other in a game, whereby the generator (G) takes random noise and transforms it into images and the discriminator (D) checks whether an image is from the generator or the training set of images. The distribution of the generated images should ideally be the same as that of the training images, but such a task is impossible to define by hand. The assessment of the D model provides a gradient which can be used to train both the D and G models. Further details can be gained from my blog post on the <a href="https://ym2132.github.io/GenerativeAdversarialNetworks_Goodfellow">GAN</a>.</p>
<p>This scheme presents a few issues, lets discuss some of them. Firstly, the way we assess the performance of the GAN is to check the distance between the training distribution and the generated distribution. However, if these aren’t close (i.e.&nbsp;the generated images look nothing like training images and are too easy to tell apart) the gradients can point to random directions. Another issue is the difficulty they face when generating higher resolution images, this comes from the fact that as resolution increases its much easier to tell the generated images apart from the training images.</p>
<p>This is where the Progressive Growing GAN (PGGAN) makes its key contribution. Through progressively increasing the resolution throughout the model layers, the PGGAN can generate high quality images which look good.</p>
<p>In terms of metrics, the paper uses a variety of different metrics to test the variance of the generated images (low variance means all generated images will look roughly similar which we don’t want). But, for simplicity I will not cover these and we will just assess images by looking at them.</p>
<hr>
<p>A final caveat, the paper used 1024x1024 images and the model learns to generate images of that size. I will use 256x256 size images in the training set and our model will generate images of that size too, this is to reduce training time and memory usage.</p>
<hr>
<p>Expand this block to show code for imports and some helper functions!</p>
<div id="0bc20150" class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Before we continue lets set our inputs and configure the device for our model code</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> ImageFolder</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> save_image</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms, utils</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> sqrt</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># We can make use of a GPU if you have one on your computer. This works for Nvidia and M series GPU's</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.backends.mps.is_available():</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># These 2 lines assign some data on the memory of the device and output it. The output confirms</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if we have set the intended device</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.cuda.is_built():</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> (<span class="st">"cpu"</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.ones(<span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (x)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># I also define a function we use to examine the outputs of the Generator</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_images(images, num_images<span class="op">=</span><span class="dv">16</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>)):</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure the input is on CPU</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> images.cpu().detach()</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize images from [-1, 1] to [0, 1]</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> (images <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clamp values to [0, 1] range</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.clamp(images, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make a grid of images</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> torchvision.utils.make_grid(images[:num_images], nrow<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to numpy and transpose</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> grid.numpy().transpose((<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the grid</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>figsize)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    plt.imshow(grid)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1.], device='cuda:0')</code></pre>
</div>
</div>
<h2 class="anchored">
The Progressive Growing GAN
</h2>
<p>The key idea is that we can start with low resolution images and grow them by increasing resolution between each layer, we’ll cover the mechanics soon. By starting off with low resolution images we allow the network to learn the overall structure of the images and defer the learning of finer details to later stages, this makes the task much simpler than trying to learn both aspects at once.</p>
<p>Let’s examine why low resolution images allow the network to learn the main structure of the images. Take Figure 1, a full size 256x256 image and next to it the same image downsized to 4x4 pixels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./figures/image_comparison.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1 - Stringer</figcaption>
</figure>
</div>
<p>The 4x4 image contains the complete structural information of the 256x256 image, despite containing 4096 times less information than it. In this example we see, the middle 2x2 area contains the structure of the face, the bottom row has the shoulders and the bearded chin in the middle, the top row has the top of the head and the hair. This happens because images are made up of areas of similar colours, i.e.&nbsp;nearby pixels share similar colours<a href="#3"><sup>3</sup></a>. This phenomenon of natural images is what allows this architecture to work so well, to drive the point home lets look, in Figure 2, at the full run of images from 8x8 through to 128x128. We see the image structure doesn’t change much between each upsizing, this is what we take advantage of in the PGGAN.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./figures/image_size_comparison.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2</figcaption>
</figure>
</div>
<h2 class="anchored">
The Path to Implementation
</h2>
<p>There are a few crucial ideas which we need to understand to implement the PGGAN, I will name them here and explain them as we go along. We need to understand the growing scheme and the actual structure of the model itself, minibatch standard deviation (MB StdDev), equalised learning rate (Eq LR), pixel normalisation (PN) and the WGAN-GP loss function.</p>
<p>The implementation of these things was not immediately clear to me, to combat this we will take a slight detour for now. The paper itself presents multiple ways to implement the PGGAN, one of which is named the Gulrajani case<a href="#4"><sup>4</sup></a>. In the Gulrajani case we can skip the implementation of the progressive growing, MB StdDev , Eq LR and PN. Doing so not only makes the task simpler at first but will show us how these other aspects increase the quality of the model.</p>
<hr>
<p><b>Note 1</b> the paper works up to generating 1024x1024 images, for time and compute’s sake I will only go up to 256x256. The technique doesn’t change if you want toincrease the model capacity to generate the 1024x1024 images quite simply by following the existing structure.</p>
<p><b>Note 2</b> Due to the way the Gulrajani case is setup, namely the batch size needs to be alot bigger (the paper states 64, I use 32 for memory constraints) thus using more memory, so I only generate up to 64x64 images for this case. After we cover this I will implement the full model which will generate 256x256 images.</p>
<p>I admit this may be a bit confusing, but to summarise the plan:</p>
<ul>
<li>
First implement the <b>Gulrajani case</b>, which is the model without any extra bells and whistles. It will generate 64x64 images.
</li>
<li>
Secondly, implement what I call <b>the full case</b>, which is the model with all the extras. It will generate 256x256 images.
</li>
</ul>
<hr>
<p>So, having said that lets get to it and examine the Generator (G) architecture. In Figure 3 we see the G used by the paper to generate 1024 images, our implementation uses a truncated version of this but the structure is the same. Also, the number of feature maps we have at each layer differs, this is because we dont start with a (512, 1, 1) shape latent vector. Rather, we start with (128, 1, 1) in the Gulrajani case.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/ca38df5f-1-image-2.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3 - G Architecture</figcaption>
</figure>
</div>
Now, the Gulrajani case has some slight differences to the scheme in Figure 3 and the full case. Here I list out the differences, we will explore their implications after implementing the Gulrajani case:
<ul>
<li>
Minibatch size of 32 (paper states 64 but it uses too much memory)
</li>
<li>
LeakyReLU is replaced with standard ReLU.
</li>
<li>
PN is replaced with batch normalisation
</li>
<li>
Disable: progressive growing, Mb StdDev and Eq LR
</li>
<li>
The adam optimiser hypermaraters are <span class="math inline">\(\alpha\)</span>=0.0001, <span class="math inline">\(\beta=0.9\)</span>
</li>
<li>
The model is initialised using He’s initialiser.
</li>
<li>
Lastly, in the Gulrajani case the D model is supposed to be updated 5 times for every 1 G update. I scrap this for a 1:1 update ratio. This is for time purposes and I observed better looking photos this way<sup><a href="#5">5</a></sup>.
</li>
</ul>
<p>Now lets see how we build out the Gulrajani G network!</p>
<h2 class="anchored">
The Gulrajani Generator (G) Network
</h2>
<p>There are two parts to this, the actual model definiton and the class which creates the blocks.</p>
<p>Let’s look at the model definition first and foremost.</p>
<div id="6a8cc6b6" class="cell" data-scrolled="true" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gulrajani_Generator(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_c<span class="op">=</span><span class="dv">128</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;in_c: In channels, this is the number of channels in the latent vector input</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We use it to calculate the number of channels in any given layer</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_c <span class="op">=</span> in_c</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For the first block I include the parameter names, they will be exlcuded from subsequent block definitions</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first 4x4 block differs in that ksize1 != ksize2, this is to transform the shape of our input from </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (batch_size, 128, 1, 1) to (batch_size, 128, 4, 4). I.e. this tranform gives us 4x4 images</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_4x4 <span class="op">=</span> G_ConvBlock(</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            in_c<span class="op">=</span>in_c, </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            out_c<span class="op">=</span>in_c, </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            ksize1<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            padding<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            ksize2<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            padding2<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            upsample<span class="op">=</span><span class="va">False</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># As before this block outputs 128 feature maps</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first 4 blocks output 128 feature maps, this follows the scheme of the paper</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The fifth layer is the first layer to halve the number of feature maps, we follow the same scheme</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># with a smaller amout of feature maps</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_8x8 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_16x16 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_32x32 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_64x64 <span class="op">=</span> G_ConvBlock(in_c, in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The to_rgb layer outputs 3 feature maps, i.e. RGB.</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># It has an in_c the same as the out_c of the last (64x64) block</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb <span class="op">=</span> nn.Conv2d(in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We use tanh for the output activation, this bounds our pixels values between [-1,1]</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> nn.Tanh()</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># To observe the upsampling in effect, uncomment the print statements and run the example output ahead</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and see what happens! TIP: comment the print statements again before running the training loop ;)</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The forward method simply passes x through the layers of our model</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(x.shape)</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        out_4 <span class="op">=</span> <span class="va">self</span>.block_4x4(x)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_4.shape)</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        out_8 <span class="op">=</span> <span class="va">self</span>.block_8x8(out_4)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_8.shape)</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        out_16 <span class="op">=</span> <span class="va">self</span>.block_16x16(out_8) </span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_16.shape)</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>        out_32 <span class="op">=</span> <span class="va">self</span>.block_32x32(out_16)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_32.shape)</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>        out_64 <span class="op">=</span> <span class="va">self</span>.block_64x64(out_32)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_64.shape)</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.to_rgb(out_64)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(out_64.shape)</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now lets look at the code for the G_ConvBlock itself. The reason for the seperation here is mainly to make our code cleaner, by defining the G_ConvBlock class we can save a lot of repeated code<a href="#6"><sup>6</sup></a>.</p>
<div id="37a3b1f1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> G_ConvBlock(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        in_c, </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        out_c, </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        padding,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        upsample<span class="op">=</span><span class="va">True</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> []</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ksize2 and padding2 are used regardless of whether or not they are defined,</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;so if they aren't we set them to ksize1 and padding.</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If upsample True, we add the upsample layer before the</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># next set of convolutional blocks</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> upsample:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Upscale, we use the nearest neighbour upsampling technique</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                nn.Upsample(scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'nearest'</span>),</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The layers of the block are the same, regardless of if we use upsample or not</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        layers_list.extend([</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(out_c),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(out_c),</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We convert out layers_list to a PyTorch Modulelist, this allows us to iterate on the layersb</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Having defined our G model, lets run a sample input through the model. Before doing so let’s implement a function to intialise the weights of our model. Remember the model needs to be intialised with He’s intialisation scheme.</p>
<div id="dbc4c662" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize with He's initializer</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_weights(m):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        nn.init.kaiming_normal_(m.weight, mode<span class="op">=</span><span class="st">'fan_in'</span>, nonlinearity<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> m.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>            nn.init.constant_(m.bias, <span class="dv">0</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You see nn.LayerNorm here, this will come in handy in the D model</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(m, (nn.BatchNorm2d, nn.LayerNorm)):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(m.weight, <span class="dv">1</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(m.bias, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="43a503ea" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Gulrajani_Generator().to(device)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the weights intialisation to the model</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">apply</span>(init_weights)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;</span><span class="al">TESTING</span><span class="co"> G</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>g_in <span class="op">=</span> torch.randn((<span class="dv">1</span>, <span class="dv">128</span>, <span class="dv">1</span>, <span class="dv">1</span>), device<span class="op">=</span>device)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>g_out <span class="op">=</span> g(g_in)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>show_images(g_out), g_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Great, we now have our Gulrajani Generator implemented! And it’s capable out outputting 64x64. You can experiment with higher resolutions too!</p>
<p>Let’s move on to the Discriminator.</p>
<h2 class="anchored">
The Gulrajani Discriminator (D) Network
</h2>
<p>Looking at Figure 4, we see the architecture for the full case of the D network. Similar to the G network, we will truncate it to match our case here. Note, it’s structure is very similar to the G network, just in reverse (in that the first input has the same pixels as the output of the G network).</p>
<p>The goal of the D network is to classify whether any given image is from the training set or the G model. As such, by examining the output shapes we see it eventually becomes a 1x1x1 shape, this is the final classification of the network.</p>
<p>So in a line, the D model takes our generated image or a training image as input and outputs a classification of whether it is generated or not. This classification is then used to build our loss functions and update both networks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/c8655667-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4 - D Architecture</figcaption>
</figure>
</div>
<p>Now, let’s build out the Gulrajani D network. Before we start, as before, I list out the specific differences in the Gulrajani D case:</p>
<ul>
<li>
Minibatch size of 32 (paper states 64 but it uses too much memory). Same as the G network.
</li>
<li>
Disable: progressive growing, Mb StdDev and Eq LR. MbStdDev being disabled is noteworthy, in Figure 4 you can see it as a layer before the finals blocks, as such our final blocks have one less feature map than in that image.
</li>
<li>
The adam parameters are the same as for the G model
</li>
<li>
The model is initialised using He’s initialiser too.
</li>
<li>
We add layer normalisation after each conv 3x3 and 4x4 layer.
</li>
</ul>
<p>Having said this, lets get right to the D model code!</p>
<div id="c5c16347" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gulrajani_Discriminator(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, out_c<span class="op">=</span><span class="dv">128</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Notice the D model is essentially the G in reverse</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># with an added linear layer</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first block takes in 64 channels, this is the output</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from "from_rgb"</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_64x64 <span class="op">=</span> D_ConvBlock(out_c<span class="op">//</span><span class="dv">2</span>, out_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_32x32 <span class="op">=</span> D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_16x16 <span class="op">=</span> D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_8x8 <span class="op">=</span> D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Our last block differs slightly. The goal is to output</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;128x1x1 feature maps ready to be passed through the linear layer</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;A note on padding, if padding=0 we do not preserve the dimension through the layer,</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;whereas padding=1 preserves the dimension</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_4x4 <span class="op">=</span> D_ConvBlock(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            in_c<span class="op">=</span>out_c, </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            out_c<span class="op">=</span>out_c, </span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>            ksize1<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            padding<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>            ksize2<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>            padding2<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.from_rgb <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(out_c, <span class="dv">1</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.from_rgb(x)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The interpolation has a scale_factor=0.5, this is halving</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the size of the image each time.</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.block_64x64(out)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.block_32x32(out)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.block_16x16(out)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.block_8x8(out)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.block_4x4(out)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;This layer flattens the output of block_4x4, we need to do this as a linear layer</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># expects its input to have only 1 dimension</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(out.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.linear(out)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before covering the D_ConvBlock, notice the D model is a reverse of the G model. This fact is especially important when we implement progressive growing so keep it in the back of your mind!</p>
<p>Now, lets discuss the D_ConvBlock.</p>
<div id="ef263245" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> D_ConvBlock(nn.Module):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This block is pretty much the same as the G_ConvBlock, with one small difference</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;See if you can spot the difference and think about why we use this scheme, read ahead for my explanantion</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        in_c,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        out_c,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        padding, </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>,   </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> [</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, layer <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.layers):</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, nn.Conv2d):  <span class="co"># After each Conv2d layer</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> F.layer_norm(x, [x.size(<span class="dv">1</span>), x.size(<span class="dv">2</span>), x.size(<span class="dv">3</span>)])</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(x.shape)</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="97715d32" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Gulrajani_Discriminator().to(device)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># As before we init the model using he's init scheme</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>d.<span class="bu">apply</span>(init_weights)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>d_in <span class="op">=</span> torch.randn((<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">64</span>, <span class="dv">64</span>), device<span class="op">=</span>device)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>d_out <span class="op">=</span> d(d_in)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>d_out, d_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(tensor([[0.6182]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),
 torch.Size([1, 1]))</code></pre>
</div>
</div>
<p>Did you spot the difference? More importantly did you figure out why we have this difference?</p>
<p>If you got it well done! If not let me explain, take a look at our forward pass. The Gulrajani D employs layer normalisation after each convolutional block, but the PyTorch layer_norm has as its parameters the dimensions of the input alongside the input itself. To allow for generality we need to dynamically call layer_norm, to ensure it only comes after conv layers we create a layer list and iterate through it. Our instance check ensures the current layer that x has gone through is in fact a conv layer and if so we pass the output through the layer_norm before the LeakyReLU.</p>
<p>So, now we have our Gulrajani G and D setup. Now it’s time to generate some images!</p>
<h2 class="anchored">
The Training Loop
</h2>
<p>Now we have almost everything we need to get started on training. Note I say almost, as we don’t even have our dataset yet! The dataset we will be using is a smaller version of the CelebA-HQ Face dataset. The original dataset uses 30000 1024x1024 images, however due to its size (80gb on disk) we use a smaller image size. Our dataset is 30000 256x256 images and is alot easier to handle.</p>
<p>The dataset can be found at: <a href="https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256">https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256</a></p>
<div id="aa28d6cb" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lets set up our data transforms, we don't do anything special here</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We just resize our images to 64x64 and normalise them</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data loader</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">64</span>, <span class="dv">64</span>)),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: You may need to change the path on your machine</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> datasets.ImageFolder(<span class="st">'./celeba_hq_256'</span>, transform<span class="op">=</span>transform)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The params, pin_memory speeds up the transfer of data from RAM to GPU VRAM</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># and num_workers assigns multiple workers to load data once again speeding up the process</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, pin_memory<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have the dataset, we can intialise our Adam optimisers and define the training loop<a href="#7"><sup>7</sup></a>. The loop we define here is pretty standard, however things will get interesting soon when we implement the full case ;)</p>
<p>For training the PGGAN, whether its the full case or the Gulrajani case, we must use the WGAN-GP (Wasserstein GAN - Gradient Penalty) loss function. The reasoning comes from the instability of GAN training, with traditional loss functions training is too diffucult. The WGAN-GP loss greatly increases the stability of the training scheme. Let’s quickly cover how it works and it’s implementation before we develop the full training loop.</p>
<section id="wasserstein-gan---gradient-penalty-wgan-gp4" class="level3">
<h3 class="anchored" data-anchor-id="wasserstein-gan---gradient-penalty-wgan-gp4">Wasserstein GAN - Gradient Penalty (WGAN-GP)<a href="#4"><sup>4</sup></a></h3>
<p>Long story short, using the WGAN-GP loss improves the training scheme of our GAN and thus improves the quality of the output.</p>
<p>Now for long story long, lets discuss how the WGAN-GP loss improves training. Training GANs is inherently difficult due to the setup of the game between the D and G model, at any point in training if the D model becomes too good it will easily tell apart the G samples from real samples. This causes vanishing gradients and the information from D becomes less meaningful, causing a breakdown in the training regime.</p>
<section id="wgan" class="level4">
<h4 class="anchored" data-anchor-id="wgan">WGAN</h4>
<p>So, in comes the Wasserstein GAN (WGAN - this came before WGAN-GP) whose major contribution was to provide a loss function which improved the stability of GAN training and helped to alleviate mode collapse issues<a href="#8"><sup>8</sup></a> (mode collapse is issues such as GANs outputting 1 image for all input or images of one colour, so essentially an issue which causes training to fail). How does the WGAN do this (I will do my best to give a quick overview of this<a href="#9"><sup>9</sup></a>), well in the traditional GAN setting as the D gets better the loss function becomes saturated and leaves us with those pesky vanishing gradients. The saturation occurs due to the loss functions trying to solve the Jenson-Shannon divergence which is not differentiable everywhere, simply put at some points the gradients provide no information for updating the models. To overcome this it was held that G and D updates need be carefully controlled, such that this behaviour isn’t reached, but it is very difficult to do this in practise and there is little common consensus on how to do it well.</p>
<p>Now, the WGAN uses a Wasserstein distance which is differentiable everywhere meaning the gradients will always be meaningful. This allows us to train the D model to optimality without worrying about vanishing gradients and preventing mode collapse. Further, this means we do not have to balance the training of G and D so carefully, as with WGAN the better the D model the more meaningful our gradients are for updating the models.</p>
<p>So, it sounds like WGAN should work pretty well. Why doesnt it? Let’s discuss some it’s issues, which will lead us nicely to the WGAN-GP and how it solves these issues. The WGAN requires that the D model satisfies a 1-Lipschitz constraint<a href="#10"><sup>10</sup></a>, this constrain is enforced by clipping the weights of D. Now, here’s where the issue arises, I quote from the WGAN paper<a href="#8"><sup>8</sup></a> “Weight clipping is a clearly terrible way to enforce a Lipschitz constraint”. Weight clipping leads to unintended consequences, we will discuss the two covered in the PGGAN paper. First, the weight clipping causes the D model to learn very simple functions thus leaving room for improvement given the potential complexity. Second, the weight clipping results in exploding or vanishing gradients, which are exactly what we want to avoid, take. a look at figure 5. The blue line in Figure 5 is WGAN with Gradient Penalty, the solution to these issues.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/eafbb8ce-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5</figcaption>
</figure>
</div>
</section>
<section id="wgan-gp" class="level4">
<h4 class="anchored" data-anchor-id="wgan-gp">WGAN-GP</h4>
<p>Having explored WGAN and it’s issues, lets shift our attention to WGAN-GP and explore how it improves upon WGAN. The key issues is WGAN arrise from enforcing the 1-Lipschitz contstraint through weight clipping, WGAN-GP uses a gradient penalty instead (hence the name). Namely, the 1-Lipschitz constrain is imposed via a penalty on the gradient norm of D. Take a look at Figure 6, this is the formula for our loss function. The “Original critic loss” is the WGAN aspect. <span class="math inline">\(\lambda=10\)</span> is the standard setup. Now, we can look at Algorithm 1 which implements this function and build it out in Python too! (P.S I know Figure 6 may look a little scary, but we will relate the elements of Figure 6 to Algorithm 1 and the Python implementation).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/1ab15083-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6 - WGAN-GP Formula</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/c877878c-1-image-2.png" class="img-fluid figure-img"></p>
<figcaption>Algorithm 1 - We follow this to implement WGAN-GP</figcaption>
</figure>
</div>
<p>First off, if you take the formula in Figure 6 you see the original critic loss corresponds to the red box in Algo 1 and the gradient penalty corresponds to the purple box. So the WGAN aspect is just the D predictions on <span class="math inline">\(\tilde{x}\)</span>, namely the generated images, minus the predictions on <span class="math inline">\(x\)</span>, namely the real images. Thus the seemingly scary critic loss is quite simple once broken down!</p>
<p>Now, for the rest of the algorithm I will refer to the following block with the python implementation of the WGAN-GP loss.</p>
<div id="52e32265" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co"> 1 - This block will contain some variable which dont exist yet</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;imagine they do, their names should inform you of the content, this</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># is just for illustrative purposes</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co"> 2 - Anytime I refer to a line number I am referring to the line</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># number in Algorithm 1. E.g. Line 1 = while theta has not converged do</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># We start at line 4, in which we just load our real imgs, create our noise tensor</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># and sample epsilon from a uniform distribution</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>real_imgs, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader)) </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.randn((batch_size, latent_dim, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>eps <span class="op">=</span> torch. rand((batch_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))  <span class="co">#&nbsp;in the paper eps is a single number, however for us we need multiple due to batch_size &gt; 1</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Line 5 see's us create our generated images</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>gen_imgs <span class="op">=</span> g(z)  <span class="co"># Assume g is our generator network, we replace x_tilde with gen_imgs</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Lets create our fake and real predictions, these come in handy later</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>real_preds <span class="op">=</span> d(real_imgs)  <span class="co"># Assume d is the discriminator network</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>gen_preds <span class="op">=</span> d(gen_imgs)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Line 6 - we create x_hat</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># .detach() moves our images from GPU to CPU (RAM) memory</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())  <span class="co"># x_hat is a combination of real and fake imgs</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>x_hat.requires_grad_(<span class="va">True</span>)  <span class="co"># A PyTorch idiosyncracy to enable backprop on x_hat</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>pred_x_hat <span class="op">=</span> d(x_hat)  <span class="co">#&nbsp;We use pred_x_hat in calculating the gradient penalty</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Now line 7 is the crux and as such I will split it up into a few different sections</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()  <span class="co"># This is the first part of line 7, D(gen_imgs) - D(real_imgs). As we have a batch size &gt; 1 we must use the mean here</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;To calculate the gradient penalty (second part of line 7) we need to take the gradients of D(x_hat)</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>)[<span class="dv">0</span>]  <span class="co"># The grads here represent how the model reacts to an image which is not either real nor fake</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co"># it is in the mid point, and as such it allows us to explore the behaviour of d across the input space</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;rather than just when images are real or fake. This allows us to enforce the Lipschitzs constraint by calculating</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co"># the norm of these grads and penalizing it if it is not rougly 1.</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean()  <span class="co">#&nbsp;Now we have our gradient penalty. Once again we use mean due to batch_size</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="co"># WGAN_GP_loss = d_loss</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="co"># The above trains the D model, now lets look at the G model</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="co"># The g update is alot simpler, Look at line's 11 and 12</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.randn((batch_size, latent_dim, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>gen_imgs <span class="op">=</span> g(z)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>gen_preds <span class="op">=</span> d(gen_imgs)  <span class="co">#&nbsp;This corresponds to D(G(z))</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()  <span class="co"># Remember mean as we have batch_size &gt; 1</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a><span class="co"># And thats it!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Well done, you’ve implemented a custom loss function! Now that thats out of the way let’s put it use and train our Gulrajani PGGAN.</p>
<hr>
<p><b>NOTE</b> I train the model here for 10000 iterations (10000 * 32 = 32000 so it’s essentially one epoch of the training data). This is a very small amount, and I recommend you train the model for much more iterations (100000 is a good balance of time and output). I used a smaller number to save time and to ensure this post doesn’t physically get too long.</p>
<p>So, please <b>increase the end_iter</b> before running the following code.</p>
<p>Lastly, you may observe some weird patterns in the Gulrajani case. This is normal and is why this case isn’t the end of our story. More on this after we train the model.</p>
<hr>
<div id="bcbb5f07" class="cell" data-scrolled="true" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;In this training loop we will save checkpoints of the model so let's setup a new directory for the checkpoint to be save to.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note this code will create the checkpoint dirs in your current working directory (i.e. whichever directory this file is in)</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>timestamp <span class="op">=</span> datetime.now().strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">_%H%M"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>checkpoint_dir <span class="op">=</span> os.path.join(os.getcwd(), <span class="ss">f"checkpoint_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>os.makedirs(checkpoint_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Lets re-init our models just to ensure there is no carry over from before</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Gulrajani_Discriminator().to(device)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Gulrajani_Generator().to(device)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>d.<span class="bu">apply</span>(init_weights)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">apply</span>(init_weights)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Lets init our optimisers</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>beta1, beta2 <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.9</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizers - Note they are both the same</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>g_optimizer <span class="op">=</span> torch.optim.Adam(g.parameters(), lr<span class="op">=</span>lr, betas<span class="op">=</span>(beta1, beta2))</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>d_optimizer <span class="op">=</span> torch.optim.Adam(d.parameters(), lr<span class="op">=</span>lr, betas<span class="op">=</span>(beta1, beta2))</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># We will keep track of d_loss and g_loss to examine later</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>g_losses <span class="op">=</span> []</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>d_losses <span class="op">=</span> []</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co"># We will use a progress bar to keep track of our training run here</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;In order to do this we need a start and an end value</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co"># I deviate from the "epoch" terminology, because in the paper </span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co"># iterations are used to count how much the model is trained rather than epochs.</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="co"># The use of iterations highlights the importance of number of images shown, and it also gives finer grained control.</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>start_iter, end_iter <span class="op">=</span> <span class="dv">0</span>, <span class="dv">10000</span>  <span class="co">#&nbsp;Feel free to increase the end_iter and experiment with your results</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Now lets create a handy progress bar using the tqdm library</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>progress_bar <span class="op">=</span> tqdm(<span class="bu">range</span>(start_iter, end_iter))</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We can use the progress bar to keep track of the number of iterations</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> progress_bar:</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First off we train the discriminator</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A python convention is to use "_" for things we want to throw away or wont use</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;Here _ stores the label which we don't care about as we know implicitly that all real_images have label 1</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    d.zero_grad()</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    real_imgs, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    real_imgs <span class="op">=</span> real_imgs.to(device)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>    real_preds <span class="op">=</span> d(real_imgs)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;Gen fake images</span></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.randn((batch_size, latent_dim, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    gen_imgs <span class="op">=</span> g(z)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    gen_preds <span class="op">=</span> d(gen_imgs.detach())</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gradient Penalty - GP</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    eps <span class="op">=</span> torch.rand((batch_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>    x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>    x_hat.requires_grad_(<span class="va">True</span>)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>    pred_x_hat <span class="op">=</span> d(x_hat)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>        outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>        grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>        create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    )[<span class="dv">0</span>]</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean() </span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># WGAN_GP_loss = d_loss</span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>    d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>    d_loss.backward()</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>    d_optimizer.step()</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>    d_losses.append(d_loss.detach())</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now lets train the Generator</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    g.zero_grad()</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.randn((batch_size, latent_dim, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>    gen_imgs <span class="op">=</span> g(z)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    gen_preds <span class="op">=</span> d(gen_imgs)</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>    g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>    g_loss.backward()</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>    g_optimizer.step()</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>    g_losses.append(g_loss.detach())</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now lets setup some testing stuff to keep us informed on how the model is doing.</span></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This consists of outputting sample images from the G model at regular intervals(I choose every 500 iterations)</span></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;and saving some model checkpoint throughout training (I save a checkpoint every 10000 iterations).</span></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We also want to update our status bar with some useful info, such as the current loss values. We do </span></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># this every 100 iterations</span></span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>        progress_bar.set_description(<span class="ss">f"D: </span><span class="sc">{</span>d_loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">, G: </span><span class="sc">{</span>g_loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i<span class="op">+</span><span class="dv">1</span>) <span class="op">%</span> <span class="dv">500</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Lets show some samples</span></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We gen 8 sample images</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>            sample_z <span class="op">=</span> torch.randn(<span class="dv">8</span>, latent_dim, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>            sample_imgs <span class="op">=</span> g(sample_z)</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>            show_images(sample_imgs)</span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i<span class="op">+</span><span class="dv">1</span>) <span class="op">%</span> <span class="dv">10000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>        torch.save({</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>            <span class="st">'g_state_dict'</span>: g.state_dict(),</span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>            <span class="st">'d_state_dict'</span>: d.state_dict(),</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>            <span class="st">'g_optimizer_state_dict'</span>: g_optimizer.state_dict(),</span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>            <span class="st">'d_optimizer_state_dict'</span>: d_optimizer.state_dict(),</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>            <span class="st">'iteration'</span>: i</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>        }, <span class="ss">f'</span><span class="sc">{</span>checkpoint_dir<span class="sc">}</span><span class="ss">/checkpoint_iter_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">.pth'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -4.0252, G: 8.4129:   5%|▍         | 499/10000 [02:43&lt;51:19,  3.09it/s]   </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: 4.1170, G: 2.2822:  10%|▉         | 999/10000 [05:28&lt;49:09,  3.05it/s]    </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -14.0048, G: 13.8735:  15%|█▍        | 1499/10000 [08:14&lt;47:06,  3.01it/s] </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -28.7303, G: 20.2716:  20%|█▉        | 1999/10000 [10:59&lt;43:42,  3.05it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -13.0796, G: 23.0539:  25%|██▍       | 2499/10000 [13:43&lt;40:38,  3.08it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -33.7290, G: 26.4978:  30%|██▉       | 2999/10000 [16:29&lt;38:02,  3.07it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-12.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -44.3616, G: 29.3735:  35%|███▍      | 3499/10000 [19:15&lt;36:40,  2.95it/s]  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-14.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -42.4620, G: 31.0859:  40%|███▉      | 3999/10000 [22:01&lt;32:38,  3.06it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-16.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -37.8902, G: 30.8805:  45%|████▍     | 4495/10000 [24:45&lt;35:25,  2.59it/s]Traceback (most recent call last):
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/shutil.py", line 738, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/shutil.py", line 736, in rmtree
    os.rmdir(path, dir_fd=dir_fd)
OSError: [Errno 39] Directory not empty: '/tmp/pymp-i1zs7tv1'
D: -51.7479, G: 33.8998:  45%|████▍     | 4499/10000 [24:46&lt;32:11,  2.85it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-18.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -60.7261, G: 38.2137:  50%|████▉     | 4999/10000 [27:32&lt;27:50,  2.99it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-20.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -44.3616, G: 8.7010:  55%|█████▍    | 5499/10000 [30:17&lt;24:33,  3.05it/s] </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-22.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -43.4830, G: 28.5494:  57%|█████▋    | 5663/10000 [31:10&lt;24:20,  2.97it/s]Traceback (most recent call last):
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/shutil.py", line 738, in rmtree
    onerror(os.rmdir, path, sys.exc_info())
  File "/home/yusuf/anaconda3/envs/gpu_use/lib/python3.11/shutil.py", line 736, in rmtree
    os.rmdir(path, dir_fd=dir_fd)
OSError: [Errno 39] Directory not empty: '/tmp/pymp-y1hw6u2c'
D: -31.9647, G: 38.9928:  60%|█████▉    | 5999/10000 [33:02&lt;21:44,  3.07it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-24.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -69.3636, G: 46.4498:  65%|██████▍   | 6499/10000 [35:46&lt;19:18,  3.02it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-26.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -45.6132, G: 42.0237:  70%|██████▉   | 6999/10000 [38:32&lt;16:16,  3.07it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-28.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -30.6929, G: 32.8052:  75%|███████▍  | 7499/10000 [41:17&lt;13:32,  3.08it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-30.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -33.7616, G: 49.7827:  80%|███████▉  | 7999/10000 [44:03&lt;13:27,  2.48it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-32.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: 15.4376, G: -27.7988:  85%|████████▍ | 8499/10000 [46:48&lt;08:06,  3.09it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-34.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -61.9004, G: 8.2054:  90%|████████▉ | 8999/10000 [49:34&lt;05:25,  3.07it/s] </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-36.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -8.8729, G: 32.2779:  95%|█████████▍| 9499/10000 [52:18&lt;02:43,  3.07it/s]  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-38.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -100.8944, G: 60.1621: 100%|█████████▉| 9999/10000 [55:03&lt;00:00,  3.08it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-12-output-40.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>D: -100.8944, G: 60.1621: 100%|██████████| 10000/10000 [55:03&lt;00:00,  3.03it/s]</code></pre>
</div>
</div>
</section>
<section id="the-gulrajani-case---postmortem" class="level4">
<h4 class="anchored" data-anchor-id="the-gulrajani-case---postmortem">The Gulrajani Case - Postmortem</h4>
<p>The images above may differ from your own, but it’s clear to see our network is generating something which look like faces (with very clear issues). The model seems to struggle on generating backgrounds and facial features all look messed up, but they look like faces! But, upon closer examination we see something is going wrong, take a look at the G and D loss values and the actual images themselves.</p>
<p>The actual loss values of G and D vary massively, this is not what we want to see. This highlights the inherant unstability of GANs and despite our WGAN-GP we still see this behaviour in the Gulrajani case. This instability can be tamed by Eqaulised Learning Rate and Pixel Normalisation. We will cover both of these and apply them to the full case and observe the impact.</p>
</section>
</section>
<section id="cover-why-neg-values-and-what-it-means" class="level1">
<h1>COVER WHY NEG VALUES AND WHAT IT MEANS</h1>
<p>MAKE PLOT OF G AND D AND WRITE ABOUT IT</p>
<p>Next, when I say look at the images I don’t mean the glaring issues of mismatch facial features and such but rather the lack of diversity in the generated images. Often times in the samples shown, mutliple images seem to look pretty similar with minor differences. Why could this be happening? A well known issue with GANs is failure to capture the all the variation in the dataset, in the PGGAN paper this is solved by the Minibatch Standard Deviation layer.</p>
<div id="c4a98260" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming d_losses and g_losses are lists of GPU tensors</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>d_losses_cpu <span class="op">=</span> [loss.cpu().detach().numpy() <span class="cf">for</span> loss <span class="kw">in</span> d_losses]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>g_losses_cpu <span class="op">=</span> [loss.cpu().detach().numpy() <span class="cf">for</span> loss <span class="kw">in</span> g_losses]</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>plt.plot(d_losses_cpu, label<span class="op">=</span><span class="st">'Discriminator Loss'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>plt.plot(g_losses_cpu, label<span class="op">=</span><span class="st">'Generator Loss'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iterations'</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Generator and Discriminator Loss Over Time'</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Above you see a plot of the G and D loss over the iterations, it’s clear there’s a huge issue here. This shows clearly how difficult it is to train GANs. As the model get’s larger it appears the stability of the training process decreases, as is the difficulty of generating high resolution images. My intuitions tells me that this is what the full case will solve, by learning the lower level representations</p>
<h1>
The Full Case Progressive GAN!!!
</h1>
<p>Finally, we are ready to implement the full PGGAN. All that came before was leading us to this. A short roadmap in the order we will cover things: PixelNorm, MiniBatchStdDev, Equalised Learning Rate (EqLR) layers, then the new ConvBlocks (they are slightly different but not by much), the new G and D networks setups (these have a stark difference with the implementation of progressive growing, mainly in the forward methods) and finally the training loop.</p>
<p>Note, we will see the Progressive Growing aspect in the model definitions.</p>
<p>Without further ado, lets get to it!</p>
<section id="pixelwise-normalisation-pn" class="level3">
<h3 class="anchored" data-anchor-id="pixelwise-normalisation-pn">PixelWise Normalisation (PN)</h3>
<p>Typically GANs use batch normalisation (BN) in the G and D to help stabilise traiing, however WGAN-GP fares poorly with BN in the D so our model does not use any normalisation in the D model<a href="#11"><sup>11</sup></a>. In the PGGAN we ditch BN in favour of PN and apply it to the layers in the G. The formula for for PN is given in Figure 7. This formula is a variant of Local Response Normlization from the ImageNet paper by Krizhevsky et al.&nbsp;In this formula:</p>
<p><span class="math inline">\(\epsilon=10^{-8}\)</span></p>
<p><span class="math inline">\(N=\text{number of feature maps}\)</span></p>
<p><span class="math inline">\(a_{x,y}=\text{The input}\)</span></p>
<p><span class="math inline">\(b_{x,y}=\text{The output, i.e. the normalised input}\)</span></p>
<p>Let’s implement it!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/f2925211-1-image-3.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7 - Pixel Normalisation Forumal</figcaption>
</figure>
</div>
<div id="b355d1cc" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># I choose to implement this as a PyTorch module</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># In PyTorch you have a lot of freedom to create modules for many tasks</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PixelNorm(nn.Module):</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You see it's a relatively straightforward implementation</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the term inside the sqrt is a summation over all feature maps</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;divided by all feature maps, a.k.a taking the mean!</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">/</span> torch.sqrt(torch.mean(x <span class="op">**</span> <span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>                                  <span class="op">+</span> <span class="fl">1e-8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="minibatch-standard-devation---mbstddev" class="level3">
<h3 class="anchored" data-anchor-id="minibatch-standard-devation---mbstddev">Minibatch Standard Devation - MbStdDev</h3>
<p>GANs can tend to capture only small parts of the variation of the training data, we saw this firsthand in the Gulrajani case where our outputs were often very similar. One of the reasons something this can happen is that the G learns to produce a limited set of outputs (reaches a local minima in the gradient space) and then the D model gets good at classifying these as real and treats everything else as generated pushing the G further. To solve this, the PGGAN paper introduces MbStdDev. The formulation is as follows:</p>
<pre><code>1 - Compute standard deviation for each feature map, in each spatial location (i.e. height and width) over the batch
2 - Average the output of 1 over all feature maps and spatial locations to get a single value
3 - Then create another feature map with this single value repeated throughout it, this is then concatenated to the original feature maps.</code></pre>
<p>The idea behind this is that it allows the D model to consider the whole batch at the same time rather, by providing information on the variance of the batch of generated samples the D can punish batches with low std dev. The training data will likely have a high std dev, due to the difference in real images, this is why the D model will punish low std dev inputs. Note, this depends alot upon the real images if they were to have a low std dev too I’m not sure how effective this technique would be. In any case, the goal is to provide D with information on std dev of entire batches and get the G to generate images with similar std dev to the real images.</p>
<p>Now let’s implement it!</p>
<hr>
<p>Note, for the implementation of this I refer to the paper authors github repo for the code. They apply some tricks, which aren’t discussed in the paper which stumped me until I looked at their code. For what it’s worth, this is a common thing when implementing papers and you often need to think a little out of the box when translating the paper to code to get it to work<a href="#12"><sup>12</sup></a>.</p>
<hr>
<div id="cdc9c554" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Once again we implement Md StdDev as a PyTorch module</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MiniBatchStdDev(nn.Module):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, group_size<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Group size is from the github repo I linked to</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># It isn't discussed at all in the paper AFAIK</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.group_size <span class="op">=</span> group_size</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>        N, C, H, W <span class="op">=</span> x.shape  <span class="co">#&nbsp;N = num feature maps, C = num channels, H = height, W = width</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> <span class="bu">min</span>(<span class="va">self</span>.group_size, N)  <span class="co">#&nbsp;the minibatch must be divisible by group_size</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Here we split up X into groups</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;This line may be a little weird, expand the next code box to explore this line!</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> x.view(G, <span class="op">-</span><span class="dv">1</span>, C, H, W)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The 3 following lines see us implement number 1 from the list above.</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y <span class="op">-</span> torch.mean(y, dim<span class="op">=</span><span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.mean(torch.square(y), dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.sqrt(y <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This is number 2</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> torch.mean(y, dim<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>], keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Finally this is number 3</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y.repeat(G, <span class="dv">1</span>, H, W)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;We return the input x with an additional feature map</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([x,y], dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Expand this code block to explore</p>
<div id="205c2537" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In line 15 we have y = x.view(G, -1, C, H, W)</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Let's explore what this code</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn((<span class="dv">32</span>, <span class="dv">128</span>, <span class="dv">32</span>, <span class="dv">32</span>))  <span class="co">#&nbsp;Assume b is our tensor in the D network</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># in the view 4 corresponds to the group size, -1 in a dims mean PyTorch will calculate it for us</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;128 is the number of channels and the last 2 are height and width</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> b.view(<span class="dv">4</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">128</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># So let's take a look at how the .view changes b</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.shape, c.shape)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We see the C, H and W columns don't change</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The change come's from the N column. We have split out our 32 feature maps</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># into 4 groups of 8. I may be wrong here but I think this allows us to better</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co"># capture the variation in subsets of the images. Honestly, I'm not</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co"># sure why this is done so feel free to email me and we can discuss further</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([32, 128, 32, 32]) torch.Size([4, 8, 128, 32, 32])</code></pre>
</div>
</div>
</section>
<section id="equalised-learning-rate---eqlr" class="level3">
<h3 class="anchored">Equalised Learning Rate - EqLR</h3>
<p>Now time for the big one, Eq LR is what stumped me for the longest time on this implementation. I must give credit to <a href="https://github.com/odegeasslbc/Progressive-GAN-pytorch/blob/master/progan_modules.py">https://github.com/odegeasslbc/Progressive-GAN-pytorch/blob/master/progan_modules.py</a>, who’s implementation I made use of. The PyTorch wizadry to make this work is a bit beyond me at the moment, so I will use their implementation and do my best to explain it<a href="#13"><sup>13</sup></a>.</p>
<p>The name was slightly misleading to me, as the technique refers to scaling of the weights of the layers at runtime rather than acting on the learning rate itself.</p>
<p>The paper states that the weights are scaled to <span class="math inline">\(\hat{w}_i=\frac{w_i}{c}\)</span> where <span class="math inline">\(w_i=\text{weights}\)</span> and <span class="math inline">\(c\)</span> is the per-layer normalisation constant from He’s intialiser. But in the code they provide (and my implementation) the weights are scaled by <span class="math inline">\(w_i=w_i * \frac{\sqrt{2}}{c}\)</span>. # Why is it 2/c who knows really?</p>
<p>He’s intialiser is a common weight initialisation method for all form of neural networks (we used it previosuly to init our Gulrajani case).</p>
<p>Eq LR is a method of normalisation, employed in both the G and D models. Normalisation is necessary in the PGGAN to constrain the signal magnitdues, i.e.&nbsp;to ensure we dont see exploding or vanishing gradients. Eq LR, comes in to use due to a particular of the optimisers used in neural network trainig (Adam, RMSProp etc). These optimisers normalise a gradient update by its estimated std dev, so the update is independent of the scale of the parameter. # Show this in action maybe? So if some parameters have a larger dynamic range than others they will take longer to adjust, Eq LR ensures this doesn’t happen as it makes the dynamic range and learning speed of all weights the same. A dynamic range is the range of values that the weights can take, by constraining them we ensure this range isn’t too large or too small<a href="#14"><sup>14</sup></a>.</p>
<p>Let’s implement it shall we.</p>
<div id="836f56bd" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is the key class</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;It applies EqLR not just at intialisation but dynamically throughout training</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This is done through a forward pre-hook, which essentially is a function</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;which runs before the forward method</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLR:</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;We init the EqualLR class with the name of the weight parameter</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name):</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_weight(<span class="va">self</span>, module):</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;getattr = get attribute, in weight we stored the original</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># in the apply method</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="bu">getattr</span>(module, <span class="va">self</span>.name <span class="op">+</span> <span class="st">'_orig'</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;weight.data.size(1) is the number of channels (for a conv layer)</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;or the number of input features (for a linear layer)</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># weight.data[0][0].numel() for a linear layer is 1 and for a conv layer</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># it is the kernel size*kernel_size.  </span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        fan_in <span class="op">=</span> weight.data.size(<span class="dv">1</span>) <span class="op">*</span> weight.data[<span class="dv">0</span>][<span class="dv">0</span>].numel()</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> weight <span class="op">*</span> sqrt(<span class="dv">2</span> <span class="op">/</span> (fan_in))</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(module, name):</span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We create an instance of EqualLR </span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>        fn <span class="op">=</span> EqualLR(name)</span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The original weight is retrived from the layer</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="bu">getattr</span>(module, name)</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The weight is deleted from the layer</span></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> module._parameters[name]</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;We register a new parameter with the name _orig</span></span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># saving the original parameters</span></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a>        module.register_parameter(name <span class="op">+</span> <span class="st">'_orig'</span>, nn.Parameter(weight.data))</span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We call the pre-hook, which runs before the forward pass</span></span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a>        module.register_forward_pre_hook(fn)</span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> fn</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, module, <span class="bu">input</span>):</span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We call compute weight before the forward pass</span></span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When registering the pre_hook this __call__ is what will be called</span></span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="va">self</span>.compute_weight(module)</span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">setattr</span>(module, <span class="va">self</span>.name, weight)</span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> equal_lr(module, name<span class="op">=</span><span class="st">'weight'</span>):</span>
<span id="cb41-47"><a href="#cb41-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is just a simple function to apply the EqualLR regime</span></span>
<span id="cb41-48"><a href="#cb41-48" aria-hidden="true" tabindex="-1"></a>    EqualLR.<span class="bu">apply</span>(module, name)</span>
<span id="cb41-49"><a href="#cb41-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-50"><a href="#cb41-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> module</span>
<span id="cb41-51"><a href="#cb41-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-52"><a href="#cb41-52" aria-hidden="true" tabindex="-1"></a><span class="co"># We redefine the layers simply, initialising the weight with a normal </span></span>
<span id="cb41-53"><a href="#cb41-53" aria-hidden="true" tabindex="-1"></a><span class="co"># distribution and the biases as 0. </span></span>
<span id="cb41-54"><a href="#cb41-54" aria-hidden="true" tabindex="-1"></a><span class="co"># By using  *args and **kwargs we allow for full flexibility in these layers</span></span>
<span id="cb41-55"><a href="#cb41-55" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;and we can pass the usual arguments we would to the regular PyTorch versions.</span></span>
<span id="cb41-56"><a href="#cb41-56" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRConv2d(nn.Module):</span>
<span id="cb41-57"><a href="#cb41-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb41-58"><a href="#cb41-58" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb41-59"><a href="#cb41-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-60"><a href="#cb41-60" aria-hidden="true" tabindex="-1"></a>        conv <span class="op">=</span> nn.Conv2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb41-61"><a href="#cb41-61" aria-hidden="true" tabindex="-1"></a>        conv.weight.data.normal_()</span>
<span id="cb41-62"><a href="#cb41-62" aria-hidden="true" tabindex="-1"></a>        conv.bias.data.zero_()</span>
<span id="cb41-63"><a href="#cb41-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-64"><a href="#cb41-64" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> equal_lr(conv)</span>
<span id="cb41-65"><a href="#cb41-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-66"><a href="#cb41-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb41-67"><a href="#cb41-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv(<span class="bu">input</span>)</span>
<span id="cb41-68"><a href="#cb41-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-69"><a href="#cb41-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-70"><a href="#cb41-70" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRConvTranspose2d(nn.Module):</span>
<span id="cb41-71"><a href="#cb41-71" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb41-72"><a href="#cb41-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb41-73"><a href="#cb41-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-74"><a href="#cb41-74" aria-hidden="true" tabindex="-1"></a>        conv <span class="op">=</span> nn.ConvTranspose2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb41-75"><a href="#cb41-75" aria-hidden="true" tabindex="-1"></a>        conv.weight.data.normal_()</span>
<span id="cb41-76"><a href="#cb41-76" aria-hidden="true" tabindex="-1"></a>        conv.bias.data.zero_()</span>
<span id="cb41-77"><a href="#cb41-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-78"><a href="#cb41-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> equal_lr(conv)</span>
<span id="cb41-79"><a href="#cb41-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-80"><a href="#cb41-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb41-81"><a href="#cb41-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv(<span class="bu">input</span>)</span>
<span id="cb41-82"><a href="#cb41-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-83"><a href="#cb41-83" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EqualLRLinear(nn.Module):</span>
<span id="cb41-84"><a href="#cb41-84" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_dim, out_dim):</span>
<span id="cb41-85"><a href="#cb41-85" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb41-86"><a href="#cb41-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-87"><a href="#cb41-87" aria-hidden="true" tabindex="-1"></a>        linear <span class="op">=</span> nn.Linear(in_dim, out_dim)</span>
<span id="cb41-88"><a href="#cb41-88" aria-hidden="true" tabindex="-1"></a>        linear.weight.data.normal_()</span>
<span id="cb41-89"><a href="#cb41-89" aria-hidden="true" tabindex="-1"></a>        linear.bias.data.zero_()</span>
<span id="cb41-90"><a href="#cb41-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-91"><a href="#cb41-91" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> equal_lr(linear)</span>
<span id="cb41-92"><a href="#cb41-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-93"><a href="#cb41-93" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb41-94"><a href="#cb41-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(<span class="bu">input</span>)</span>
<span id="cb41-95"><a href="#cb41-95" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3489221a" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Do I keep this???</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>layer <span class="op">=</span> EqualLRConv2d(<span class="dv">3</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">256</span>, <span class="dv">256</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> layer(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, with those tools ready to use we can begin building the final block. It’s time to build the models themselves and implement the full progressive growing.</p>
<hr>
<p>Before moving on a word to the wise, the code for EqualLR is not straightforward. If you do not understand it (as I didn’t) then don’t be afraid to move on and come back to it :)</p>
<hr>
<h2 class="anchored" data-anchor-id="equalised-learning-rate---eqlr">
The Full Case G and D Networks
</h2>
<hr>
<p>From here on out the <b>Full Case G and D networks will be referred to as just G and D</b> respectively</p>
<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/8227b1c5-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7 - To save you scrolling, let’s put the full model architectures here</figcaption>
</figure>
</div>
<p>In Figure 7 you see the full architecture of the G and D models. The ones shown generate 1024x1024 images, as above for compute and time constrains, here we will use 256x256 images instead. Note, it is more than the 64x64 we generated in the Guljarani case, this is due to the progressive growing and it increasing our training efficiency. So then, our G model will start off with a latent of shape (batch_size, 256, 1, 1) and output of size (batch_size, 3, 256, 256) and the D model will take input of size (batch_size, 3, 256, 256) and output of size (1).</p>
<p>Our model’s follow the same pattern as above. For example, in our G we will see the first 4 layers will keep the number of channels the same and it is only subsequently that we will begin our halving of the channels. Similarily, in our D model we have the same number of channels in the last 4 layers, and they get progressively smaller as you move back to the first layer. This layout follows the paper, just with less channels and layers overall (feel free to experiment with different schemes here, e.g.&nbsp;progressively growing channels by 4x each time instead of 2x).</p>
<p>As before, I’ll cover the networks themselves first and then the convolutional blocks that make them up.</p>
<h4 class="anchored">
The Full Case G
</h4>
<p>Let’s jump right into the code, then we can explore what exactly is going on!</p>
<div id="c1cd30f4" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Credit to: https://github.com/odegeasslbc/Progressive-GAN-pytorch/blob/master/progan_modules.py</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_c<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The init method of G resembles the Gulrajani</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The major difference is the addition of multiple to_rgb layers</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This is to facilitate the growing</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_c <span class="op">=</span> in_c</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.input_layer = nn.Sequential(</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    EqualLRConvTranspose2d(in_c, in_c, 4, 1, 0),</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    PixelNorm(),</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    nn.LeakyReLU(0.2))</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_4x4 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>, upsample<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">#self.block_4x4 = G_ConvBlock(in_c, in_c, 3, 1, use_fc=True)</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_8x8 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_16x16 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_32x32 <span class="op">=</span> G_ConvBlock(in_c, in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_64x64 <span class="op">=</span> G_ConvBlock(in_c, in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_128x128 <span class="op">=</span> G_ConvBlock(in_c<span class="op">//</span><span class="dv">2</span>, in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block_256x256 <span class="op">=</span> G_ConvBlock(in_c<span class="op">//</span><span class="dv">4</span>, in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># no LeakyReLU on the to_RGBs</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_4 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_8 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_16 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_32 <span class="op">=</span> EqualLRConv2d(in_c, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_64 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_128 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.to_rgb_256 <span class="op">=</span> EqualLRConv2d(in_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> nn.Tanh()</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, layer_num, alpha):  </span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Our forward method now takes some new parameters</span></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;layer_num corresponds to the current layer we are on</span></span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;alpha is the value of the parameter alpha used in the introduction of </span></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># new layers to the network</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">#out_4 = self.input_layer(x.view(-1, self.in_c, 1, 1))</span></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The first layer is simple, we just pass it through the 4x4 block </span></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and if we are currently on layer_1 we pass it through to_rgb and call it a day</span></span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>        out_4 <span class="op">=</span> <span class="va">self</span>.block_4x4(x)</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_4(out_4)</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The second layer and onwards are where things heat u</span></span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Being the second layer we have a previous layer available and it must be used in our progressive growing</span></span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;We pass the out_4 through out_8 </span></span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a>        out_8 <span class="op">=</span> <span class="va">self</span>.block_8x8(out_4)</span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># if we are currently introducing layer 2 we must implement out formula from below</span></span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;skip corresponds to skip in the formula, as seen in Figure 8 we operate on the outputs</span></span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;passed through to_rgb layers</span></span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_4(out_4)</span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># skip is currently 4x4 images, for the formula to work dimensions must match</span></span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># so we upsample skip to beome 8x8 images, matching the dimensions of out_8 </span></span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;We also pass out_8 through to_rgb</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_8(out_8)</span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;Here is our formula, note here I use one out</span></span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;"out = " this one is the out and "* out" is the out_new</span></span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Our outputs are passed through a tanh, this is to put the values in the range [-1,1]</span></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;This scheme continues for all subsequent layers</span></span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a>        out_16 <span class="op">=</span> <span class="va">self</span>.block_16x16(out_8)</span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_8(out_8)</span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_16(out_16)</span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a>        out_32 <span class="op">=</span> <span class="va">self</span>.block_32x32(out_16)</span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">4</span>:</span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_16(out_16)</span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_32(out_32)</span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a>        out_64 <span class="op">=</span> <span class="va">self</span>.block_64x64(out_32)</span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">5</span>:</span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_32(out_32)</span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_64(out_64)</span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a>        out_128 <span class="op">=</span> <span class="va">self</span>.block_128x128(out_64)</span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">6</span>:</span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_64(out_64)</span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_128(out_128)</span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-111"><a href="#cb43-111" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a>        out_256 <span class="op">=</span> <span class="va">self</span>.block_256x256(out_128)</span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> layer_num <span class="op">==</span> <span class="dv">7</span>:</span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> <span class="va">self</span>.to_rgb_128(out_128)</span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a>            skip <span class="op">=</span> F.interpolate(skip, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.to_rgb_256(out_256)</span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb43-122"><a href="#cb43-122" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.tanh(out)</span>
<span id="cb43-123"><a href="#cb43-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> out</span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Generator().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s explore the two methods in the G model. The init method, is pretty similar to the Gulrajani G except from the multiple declrations of to_rgb. Note how each of these corresponds to the blocks (e.g.&nbsp;to_rgb_4 goes with block_4x4, the in_c matches between both of them), we use each of these in their respective progressive growing layer.</p>
<p>We should probably discuss the progressive growing scheme. Take a look at Figure 8.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/9d1c8e82-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 8 - How the progressive growing works</figcaption>
</figure>
</div>
<p>Figure 8 shows both the G and D progressive growing scheme, let’s focus on G for now (the idea is the same but the implementation differs, the G case is simpler). (a) represents the base case, we have a layer (16x16 in this case, but it doesn’t matter the idea is the same for all layers) which is passed through a to_rgb layer. This is how training proceeds when we are not growing. (b) shows the progressive growing, we add the next 32x32 layer (doubling image resolution) however it is faded in slowly so as not to disrupt previous layers too much. This fading is handled by the <span class="math inline">\(\alpha\)</span> parameter. <span class="math inline">\(\alpha\)</span> grows linearly from 0 -&gt; 1, it acts as a weight which increases the input from the new layer slowly and reduces the input from the 16x16 (previous layer). The input from the previous layer is included as a residual connection (a residual connection is one where the output from an old layer is passed to the output of a subsequent layer, this differs where usually output from previous layers is just passed forward as an input to the next layer).</p>
<p>We can construct a equation (1) to show this behaviour nicely:</p>
<p><span class="math display">\[\text{out} = ((1-\alpha) * \text{skip}) + (\alpha * \text{outnew})\tag{1}\]</span></p>
<p>In this case out is the final output, outnew is the output of the new layer and skip is the output of the previous layer. We see then that as <span class="math inline">\(\alpha\)</span> grows it will increase the impact of the new layer and decrease the impact of the previous layer. This is progressive growing!</p>
<p>Let us examine the G_ConvBlock for the full case. The structure G_ConvBlock for the full case matches the Gulrajani case, but the actual layers used are different. We use EqLR Conv layers, PixelNorm instead of BatchNorm and LeakyReLU instead of ReLU.</p>
<p>We’ve already discussed the EqLR layers and PixelNorm but why use LeakyReLU over ReLU? The Rectified Linear Unit (ReLU) sets all inputs below 0 to 0. One of the issues of ReLU, is the dying ReLU problem which is when some paramaters always output 0 due to the formulation of the ReLU (observe Figure 9). LeakyReLU applies a constant to the negative values of it’s inputs, so unlike ReLU it does not output 0 for negative values, this is an attempt to allow those paramaters to learn rather than shutting them down<a href="#15"><sup>15</sup></a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/9cc46f11-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 9 - Graphs for ReLU and LeakyReLU</figcaption>
</figure>
</div>
<div id="0a97744b" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> G_ConvBlock(nn.Module):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>        in_c, </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        out_c, </span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>        padding,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        upsample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> []</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If upsample True, we add the upsample layer before the</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># next set of convolutional blocks</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> upsample:</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Upscale, we use the nearest neighbour upsampling technique</span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>                nn.Upsample(scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'nearest'</span>),</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The layers of the block are the same, regardless of if we use upsample or not</span></span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>        layers_list.extend([</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>            PixelNorm(),</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>            PixelNorm(),</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we have implemented our G with EqLR, PixelNorm and Progressive growing, let’s test it out!</p>
<div id="04e3052e" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;</span><span class="al">TESTING</span><span class="co"> G</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>g_in <span class="op">=</span> torch.randn((<span class="dv">1</span>, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>), device<span class="op">=</span>device)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Change layer_num and see what happens</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>g_out <span class="op">=</span> g(g_in, alpha<span class="op">=</span><span class="fl">0.5</span>, layer_num<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>show_images(g_out), g_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<h4 class="anchored">
The Full Case D
</h4>
<p>Now its time for the D model. It’s seeminly quite similar to the G model but there are a few major differences in it’s setup. Let’s explore them!</p>
<p>To better understand how our D is setup, take a look at Figure 10.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/3f7595b0-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Figure 10 - How the models grow</figcaption>
</figure>
</div>
<p>The <b>key</b> thing to note here is the <b>direction of growth</b>. The G model grows from top down to bottom as in, 4x4 -&gt; 8x8 -&gt; 16x16 -&gt; 32x32 -&gt; … -&gt; 256x256 (it’s 1024x1024 in Figure 10 but we stop at 256). Then the output of the G model is fed into the D model, so by necessity the D model grows from bottom up to top as in 256x256 -&gt; 128x128 -&gt; … -&gt; 32x32 -&gt; 16x16 -&gt; 8x8 -&gt; 4x4. This is what causes the implementation of the G and D models to differ. I had missed this key difference when I first tried to implement the model but studying Figure 10 highlighted the correct pattern.</p>
<div id="5477f167" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, out_c<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># So in that light, we init a ModuleList with the first</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;convblock having expecting the same number of channels as </span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;the last G output. The first from_rgb will provide us with</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 64 channels.</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Also, the last block in this ModuleList will be where we start</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from. I include some numbers on the right to show the order</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;of growth in the D model (these are index numbers, this makes it easier</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># to understand the forward pass)</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blocks <span class="op">=</span> nn.ModuleList([</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">4</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 6 we finish here            </span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">4</span>, out_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 5</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">//</span><span class="dv">2</span>, out_c, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 4</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 3</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 2</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c, out_c, <span class="dv">3</span>, <span class="dv">1</span>),  <span class="co"># 1</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>            D_ConvBlock(out_c<span class="op">+</span><span class="dv">1</span>, out_c, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">0</span>, mbatch<span class="op">=</span><span class="va">True</span>),  <span class="co">#&nbsp;0 we start here</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from_rgb takes the RGB image outputted by the G and outputs the</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of channels needed for each layer</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.from_rgb <span class="op">=</span> nn.ModuleList([</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c<span class="op">//</span><span class="dv">2</span>, <span class="dv">1</span>),</span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(<span class="dv">3</span>, out_c, <span class="dv">1</span>),</span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The number of layers is needed to implement the growing and skip formula.</span></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.blocks)</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The final layer, this is always the final layer it takes the output</span></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and converts it to a prediction</span></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> EqualLRLinear(out_c, <span class="dv">1</span>)</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, layer_num, alpha):</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;I use a different method of selecting layers here</span></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We know at any given point what number of layers we will use</span></span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># so we index over that number</span></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(layer_num)):</span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;idx will give us the index into self.blocks, e.g. if we are </span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># at layer 4 idx starts at 7 - 3 - 1 = 3, then 4, 5, and ends at 6</span></span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> <span class="va">self</span>.num_layers <span class="op">-</span> i <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># i is an index which start at 0 and the count layer_num starts at 1 hence the +1</span></span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># since i is inverted i+1 == layer_num means we are at the start of our forward loop</span></span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>            <span class="co"># and as such we need to convert x from RGB. </span></span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i<span class="op">+</span><span class="dv">1</span> <span class="op">==</span> layer_num:</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> <span class="va">self</span>.from_rgb[idx](x)</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We always just pass through the blocks, this starts at the top level block</span></span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;for the current number of layers. E.g. at layer_num=4 we start at index 3 of self.blocks</span></span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.blocks[idx](out)</span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;i &gt; 0 means we are not on the last block and for all but the last block</span></span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;we must half the resolution</span></span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Half the resolution of the image</span></span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> F.interpolate(out, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a>                <span class="co">#&nbsp;as before i+1 == layer_num means we are the start of the forward pass</span></span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a>                <span class="co"># and 0 &lt;= alpha &lt; 1 means we are introducing a new layer</span></span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i<span class="op">+</span><span class="dv">1</span> <span class="op">==</span> layer_num <span class="kw">and</span> <span class="dv">0</span> <span class="op">&lt;=</span> alpha <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># If you refer back to Figure 8 and observe how the growing works for</span></span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#&nbsp;the D model, the skip connection involves the input x</span></span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a>                    skip <span class="op">=</span> F.interpolate(x, scale_factor<span class="op">=</span><span class="fl">0.5</span>, mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a>                    skip <span class="op">=</span> <span class="va">self</span>.from_rgb[idx <span class="op">+</span> <span class="dv">1</span>](skip)</span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> ((<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> skip) <span class="op">+</span> (alpha <span class="op">*</span> out)</span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We flatten the output to be passed through the linear layer</span></span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(out.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.linear(out)</span>
<span id="cb46-75"><a href="#cb46-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb46-76"><a href="#cb46-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Discriminator().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So, thats our D model code. Once again the init method differs slightly from the Gulrajani case, we make use of Modulelists and create multiple from_rgb’s thats it really. The forward method, however is vastly different. As discussed above, the model begins from the bottom and grows bottom up we intialise our model layers as such. Refer to the comments in the forward pass and I explain the full implementation and all the weird indexing going on here :)</p>
<p>A quick explainer on the alpha and progressrive growing for the D model. Whereas with the G model it works on the output of layers, in the D model it works on the input to layers. Look at Figure 8, if we are at the 32x32 layer the next layer below is the 16x16 layer, the 32x32 layer being the newly introduced layer. So the alpha fading provides the original input to the previous layer and the new one.</p>
<p>Moving on, let’s look at the D_ConvBlock. It is exactly the same as the Gulrajani block, except we include the MiniBatch Standard deviation layer. This addition adds an extra feature map to our final block, hence the out_c+1 in the last conv block above.</p>
<div id="36fa7d5c" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> D_ConvBlock(nn.Module):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        in_c,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        out_c,</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        ksize1, </span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>        padding, </span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>        ksize2<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>        padding2<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>        stride<span class="op">=</span><span class="va">None</span>,   </span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>        mbatch<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        layers_list <span class="op">=</span> []</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ksize2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>            ksize2 <span class="op">=</span> ksize1</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> padding2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>            padding2 <span class="op">=</span> padding</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mbatch:</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>            layers_list.extend([</span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>                MiniBatchStdDev(),</span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>        layers_list.extend([</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(in_c, out_c, ksize1, padding<span class="op">=</span>padding),</span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>            EqualLRConv2d(out_c, out_c, ksize2, padding<span class="op">=</span>padding2),</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers_list)</span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Awesome! We’ve now implemented the Full case G and D, only thing remains to train our full Progressive GAN model!!!</p>
<p>(Just after testing the D model)</p>
<div id="a8776422" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note, if you change the layer_num here you will need to change the </span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;dims in the d_in, the number of pixels in must match the layer_num</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g. at layer_num = 5 you need 64x64 images. I leave the rest to you to play with ;)</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>d_in <span class="op">=</span> torch.randn((<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">256</span>, <span class="dv">256</span>), device<span class="op">=</span>device)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>d_out <span class="op">=</span> d(d_in, alpha<span class="op">=</span><span class="fl">0.5</span>, layer_num<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>d_out, d_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(tensor([[-0.1543]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),
 torch.Size([1, 1]))</code></pre>
</div>
</div>
<h2 class="anchored">
Training the Progressive GAN
</h2>
<p>We are finally at the end of our journey, I appreciate this is a long post but we’re almost there!</p>
<p>The training loop is quite perculiar for this model, but we’ll go through it together. There is one last piece of the puzzle we must put in place before the training loop. In the paper, it is stated that an Exponential Moving Average (EMA) is used for the weights when we show the generated images. That is it is only used at inference time (when we want to generate an image) rather than for the training process. The idea being that by using an EMA we stabilise the weights by using the entire set of weights over the training process<a href="#16"><sup>16</sup></a>, to illustrate it’s effectiveness in our training loop when we sample images we will show both the ones with EMA and without.</p>
<div id="6c8e6d80" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We init a function to calculate the EMA for our parameters.</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;This is implemented using two model, one the training G and the other</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># a G we do not train but only use to hold the weights after perfoming the EMA</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> EMA(model1, model2, decay<span class="op">=</span><span class="fl">0.999</span>):</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    par1 <span class="op">=</span> <span class="bu">dict</span>(model1.named_parameters())</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    par2 <span class="op">=</span> <span class="bu">dict</span>(model2.named_parameters())</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> par1.keys():</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>        par1[k].data.mul_(decay).add_(<span class="dv">1</span> <span class="op">-</span> decay, par2[k].data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cb7be2f6" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First off let's load our data again</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;The scheme is a little different as due to progressive growing</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Our real images will need to be resized depending upon which layer</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;we're currently at</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloader(image_size, batch_size<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((image_size, image_size)),  <span class="co"># Resize images to the required size</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ImageFolder(root<span class="op">=</span><span class="st">'./celeba_hq_256'</span>, transform<span class="op">=</span>transform)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataloader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The training proces for the PGGAN has two phases, it is related to the growing and the <span class="math inline">\(\alpha\)</span>. So in the first phase we introduce the new layer and <span class="math inline">\(\alpha\)</span> grows from 0-1, increasing linearly after each iteration. Then in the second phase when <span class="math inline">\(\alpha=1\)</span>, we continue training the network with the output being fully from the new layer. Recall, equation (1) for the effect <span class="math inline">\(\alpha\)</span> has on the layers when <span class="math inline">\(\alpha=1\)</span> the effect of the skip connection is 0. The purpose of this scheme is to stabilise the network after having added a new layer. This continues until the model is fully trained.</p>
<p>To realise this two phase process, I just run the training loop twice per layer training. Also, having covered the Gulrajani case you will see the training loop is almost identical. The differences come from introducing layer_nums, alpha and the two loops to introduce and stabilise the new layers. As such, I reduce the exposition here and advise you to refer to the Gulrajani case.</p>
<div id="0f626ea6" class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Generator().to(device)  <span class="co">#&nbsp;The G we train</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> Discriminator().to(device)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>g_running <span class="op">=</span> Generator().to(device)  <span class="co">#&nbsp;The G we maintain for creating samples</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>g_running.train(<span class="va">False</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;The LR is quite high but this is specified in the paper</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;A high LR has the benefit of allowing us to explore more of the gradient space</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>g_optimizer <span class="op">=</span> torch.optim.Adam(g.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>, betas<span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">0.99</span>))</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>d_optimizer <span class="op">=</span> torch.optim.Adam(d.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>, betas<span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">0.99</span>))</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>EMA(g_running, g, <span class="dv">0</span>)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;We use this list to create a dataloader with the correct resolution for imgs</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>]</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>layer_num <span class="op">=</span> <span class="dv">1</span>  <span class="co">#&nbsp;We start at layer 1</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>start_iter <span class="op">=</span> <span class="dv">0</span>  <span class="co">#&nbsp;We start at iteration 0, of course, we use iterations in this training loop not epochs</span></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;The total number of iterations each phase of training will run for</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>total_iters <span class="op">=</span> <span class="dv">50000</span>  <span class="co">#&nbsp;The paper states 800k per phase but I go for 50k</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co"># I think 800k is excessive, but feel free to increase the number of training iterations and see how it goes!</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize lists to store loss values for statistics</span></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>g_losses <span class="op">=</span> []</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>d_losses <span class="op">=</span> []</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;range 1-7, for 7 layers we will introduce</span></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer_num <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">8</span>):</span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="dv">0</span>  <span class="co">#&nbsp;Set alpha to 0 before we introduce each new layer</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a>    resolution <span class="op">=</span> img_size[layer_num<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> get_dataloader(resolution)</span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Training resolution: </span><span class="sc">{</span>resolution<span class="sc">}</span><span class="ss">x</span><span class="sc">{</span>resolution<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>    pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(total_iters))</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> pbar:</span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a>        d.zero_grad()</span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> (<span class="pp">OSError</span>, <span class="pp">StopIteration</span>):</span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>            <span class="co">#&nbsp;If we reach the end of the dataset, we reintialise the iterable</span></span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># basically starting again</span></span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a>            dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Train D</span></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;real_size keeps track of the batch_size </span></span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a>        real_size <span class="op">=</span> real_imgs.size(<span class="dv">0</span>)</span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> real_imgs.to(device)</span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> label.to(device)</span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> d(real_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The line below implements a small weight penalty</span></span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;It is stated in the paper and it's reason is to prevent the </span></span>
<span id="cb52-58"><a href="#cb52-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># D loss being too far away from 0 preventing extreme outputs </span></span>
<span id="cb52-59"><a href="#cb52-59" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> real_preds.mean() <span class="op">-</span> <span class="fl">0.001</span> <span class="op">*</span> (real_preds<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb52-60"><a href="#cb52-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-61"><a href="#cb52-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample input for G</span></span>
<span id="cb52-62"><a href="#cb52-62" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-63"><a href="#cb52-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-64"><a href="#cb52-64" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-65"><a href="#cb52-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-66"><a href="#cb52-66" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs.detach(), layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-67"><a href="#cb52-67" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> gen_preds.mean()  <span class="co"># Make gen_preds a signle value</span></span>
<span id="cb52-68"><a href="#cb52-68" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-69"><a href="#cb52-69" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient Penalty - GP</span></span>
<span id="cb52-70"><a href="#cb52-70" aria-hidden="true" tabindex="-1"></a>        eps <span class="op">=</span> torch.rand((real_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb52-71"><a href="#cb52-71" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())</span>
<span id="cb52-72"><a href="#cb52-72" aria-hidden="true" tabindex="-1"></a>        x_hat.requires_grad_(<span class="va">True</span>)</span>
<span id="cb52-73"><a href="#cb52-73" aria-hidden="true" tabindex="-1"></a>        pred_x_hat <span class="op">=</span> d(x_hat, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-74"><a href="#cb52-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-75"><a href="#cb52-75" aria-hidden="true" tabindex="-1"></a>        WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()</span>
<span id="cb52-76"><a href="#cb52-76" aria-hidden="true" tabindex="-1"></a>        grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb52-77"><a href="#cb52-77" aria-hidden="true" tabindex="-1"></a>            outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb52-78"><a href="#cb52-78" aria-hidden="true" tabindex="-1"></a>            grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb52-79"><a href="#cb52-79" aria-hidden="true" tabindex="-1"></a>            create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb52-80"><a href="#cb52-80" aria-hidden="true" tabindex="-1"></a>        )[<span class="dv">0</span>]</span>
<span id="cb52-81"><a href="#cb52-81" aria-hidden="true" tabindex="-1"></a>        GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean() </span>
<span id="cb52-82"><a href="#cb52-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-83"><a href="#cb52-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># WGAN_GP_loss = d_loss</span></span>
<span id="cb52-84"><a href="#cb52-84" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb52-85"><a href="#cb52-85" aria-hidden="true" tabindex="-1"></a>        d_loss.backward()</span>
<span id="cb52-86"><a href="#cb52-86" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb52-87"><a href="#cb52-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-88"><a href="#cb52-88" aria-hidden="true" tabindex="-1"></a>        d_losses.append(d_loss.detach())</span>
<span id="cb52-89"><a href="#cb52-89" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-90"><a href="#cb52-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now lets train the Generator</span></span>
<span id="cb52-91"><a href="#cb52-91" aria-hidden="true" tabindex="-1"></a>        g.zero_grad()</span>
<span id="cb52-92"><a href="#cb52-92" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-93"><a href="#cb52-93" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-94"><a href="#cb52-94" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-95"><a href="#cb52-95" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()</span>
<span id="cb52-96"><a href="#cb52-96" aria-hidden="true" tabindex="-1"></a>        g_loss.backward()</span>
<span id="cb52-97"><a href="#cb52-97" aria-hidden="true" tabindex="-1"></a>        g_optimizer.step()</span>
<span id="cb52-98"><a href="#cb52-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-99"><a href="#cb52-99" aria-hidden="true" tabindex="-1"></a>        g_losses.append(g_loss.detach())</span>
<span id="cb52-100"><a href="#cb52-100" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-101"><a href="#cb52-101" aria-hidden="true" tabindex="-1"></a>        EMA(g_running, g)</span>
<span id="cb52-102"><a href="#cb52-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-103"><a href="#cb52-103" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">+=</span> <span class="dv">1</span> <span class="op">/</span> <span class="bu">len</span>(pbar)</span>
<span id="cb52-104"><a href="#cb52-104" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> <span class="bu">round</span>(alpha, <span class="dv">2</span>)</span>
<span id="cb52-105"><a href="#cb52-105" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-106"><a href="#cb52-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># I will show images both after we have introduced the new layer</span></span>
<span id="cb52-107"><a href="#cb52-107" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;and after we have stabilised it</span></span>
<span id="cb52-108"><a href="#cb52-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb52-109"><a href="#cb52-109" aria-hidden="true" tabindex="-1"></a>        sample_z <span class="op">=</span> torch.randn(<span class="dv">8</span>, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-110"><a href="#cb52-110" aria-hidden="true" tabindex="-1"></a>        sample_imgs <span class="op">=</span> g(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-111"><a href="#cb52-111" aria-hidden="true" tabindex="-1"></a>        sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-112"><a href="#cb52-112" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Images after introducing layer: </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb52-113"><a href="#cb52-113" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G images'</span>)</span>
<span id="cb52-114"><a href="#cb52-114" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs)</span>
<span id="cb52-115"><a href="#cb52-115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G_running images'</span>)</span>
<span id="cb52-116"><a href="#cb52-116" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs_EMA)</span>
<span id="cb52-117"><a href="#cb52-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-118"><a href="#cb52-118" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-119"><a href="#cb52-119" aria-hidden="true" tabindex="-1"></a>    stabilise_pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(total_iters))</span>
<span id="cb52-120"><a href="#cb52-120" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;To stabilise we just run the whole thing again, I do it this</span></span>
<span id="cb52-121"><a href="#cb52-121" aria-hidden="true" tabindex="-1"></a>    <span class="co">#&nbsp;way for simplicity</span></span>
<span id="cb52-122"><a href="#cb52-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> stabilise_pbar:</span>
<span id="cb52-123"><a href="#cb52-123" aria-hidden="true" tabindex="-1"></a>        d.zero_grad()</span>
<span id="cb52-124"><a href="#cb52-124" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-125"><a href="#cb52-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb52-126"><a href="#cb52-126" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb52-127"><a href="#cb52-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> (<span class="pp">OSError</span>, <span class="pp">StopIteration</span>):</span>
<span id="cb52-128"><a href="#cb52-128" aria-hidden="true" tabindex="-1"></a>            dataset <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb52-129"><a href="#cb52-129" aria-hidden="true" tabindex="-1"></a>            real_imgs, label <span class="op">=</span> <span class="bu">next</span>(dataset)</span>
<span id="cb52-130"><a href="#cb52-130" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-131"><a href="#cb52-131" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;Train D</span></span>
<span id="cb52-132"><a href="#cb52-132" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;real_size keeps track of the batch_size </span></span>
<span id="cb52-133"><a href="#cb52-133" aria-hidden="true" tabindex="-1"></a>        real_size <span class="op">=</span> real_imgs.size(<span class="dv">0</span>)</span>
<span id="cb52-134"><a href="#cb52-134" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> real_imgs.to(device)</span>
<span id="cb52-135"><a href="#cb52-135" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> label.to(device)</span>
<span id="cb52-136"><a href="#cb52-136" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> d(real_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-137"><a href="#cb52-137" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;The line below implements a small weight penalty</span></span>
<span id="cb52-138"><a href="#cb52-138" aria-hidden="true" tabindex="-1"></a>        <span class="co">#&nbsp;It is stated in the paper and it's reason is to prevent the </span></span>
<span id="cb52-139"><a href="#cb52-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># D loss being too far away from 0 preventing extreme outputs </span></span>
<span id="cb52-140"><a href="#cb52-140" aria-hidden="true" tabindex="-1"></a>        real_preds <span class="op">=</span> real_preds.mean() <span class="op">-</span> <span class="fl">0.001</span> <span class="op">*</span> (real_preds<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb52-141"><a href="#cb52-141" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-142"><a href="#cb52-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample input for G</span></span>
<span id="cb52-143"><a href="#cb52-143" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-144"><a href="#cb52-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-145"><a href="#cb52-145" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-146"><a href="#cb52-146" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-147"><a href="#cb52-147" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs.detach(), layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-148"><a href="#cb52-148" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> gen_preds.mean()  <span class="co"># Make gen_preds a signle value</span></span>
<span id="cb52-149"><a href="#cb52-149" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-150"><a href="#cb52-150" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient Penalty - GP</span></span>
<span id="cb52-151"><a href="#cb52-151" aria-hidden="true" tabindex="-1"></a>        eps <span class="op">=</span> torch.rand((real_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)).to(device)</span>
<span id="cb52-152"><a href="#cb52-152" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> (eps <span class="op">*</span> real_imgs) <span class="op">+</span> ((<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> gen_imgs.detach())</span>
<span id="cb52-153"><a href="#cb52-153" aria-hidden="true" tabindex="-1"></a>        x_hat.requires_grad_(<span class="va">True</span>)</span>
<span id="cb52-154"><a href="#cb52-154" aria-hidden="true" tabindex="-1"></a>        pred_x_hat <span class="op">=</span> d(x_hat, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-155"><a href="#cb52-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-156"><a href="#cb52-156" aria-hidden="true" tabindex="-1"></a>        WGAN <span class="op">=</span> gen_preds.mean() <span class="op">-</span> real_preds.mean()</span>
<span id="cb52-157"><a href="#cb52-157" aria-hidden="true" tabindex="-1"></a>        grads <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb52-158"><a href="#cb52-158" aria-hidden="true" tabindex="-1"></a>            outputs<span class="op">=</span>pred_x_hat, inputs<span class="op">=</span>x_hat,</span>
<span id="cb52-159"><a href="#cb52-159" aria-hidden="true" tabindex="-1"></a>            grad_outputs<span class="op">=</span>torch.ones_like(pred_x_hat),</span>
<span id="cb52-160"><a href="#cb52-160" aria-hidden="true" tabindex="-1"></a>            create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb52-161"><a href="#cb52-161" aria-hidden="true" tabindex="-1"></a>        )[<span class="dv">0</span>]</span>
<span id="cb52-162"><a href="#cb52-162" aria-hidden="true" tabindex="-1"></a>        GP <span class="op">=</span> ((grads.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean() </span>
<span id="cb52-163"><a href="#cb52-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-164"><a href="#cb52-164" aria-hidden="true" tabindex="-1"></a>        <span class="co"># WGAN_GP_loss = d_loss</span></span>
<span id="cb52-165"><a href="#cb52-165" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> WGAN <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> GP</span>
<span id="cb52-166"><a href="#cb52-166" aria-hidden="true" tabindex="-1"></a>        d_loss.backward()</span>
<span id="cb52-167"><a href="#cb52-167" aria-hidden="true" tabindex="-1"></a>        d_optimizer.step()</span>
<span id="cb52-168"><a href="#cb52-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-169"><a href="#cb52-169" aria-hidden="true" tabindex="-1"></a>        d_losses.append(d_loss.detach())</span>
<span id="cb52-170"><a href="#cb52-170" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-171"><a href="#cb52-171" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now lets train the Generator</span></span>
<span id="cb52-172"><a href="#cb52-172" aria-hidden="true" tabindex="-1"></a>        g.zero_grad()</span>
<span id="cb52-173"><a href="#cb52-173" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.randn(real_size, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-174"><a href="#cb52-174" aria-hidden="true" tabindex="-1"></a>        gen_imgs <span class="op">=</span> g(z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-175"><a href="#cb52-175" aria-hidden="true" tabindex="-1"></a>        gen_preds <span class="op">=</span> d(gen_imgs, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-176"><a href="#cb52-176" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> <span class="op">-</span>gen_preds.mean()</span>
<span id="cb52-177"><a href="#cb52-177" aria-hidden="true" tabindex="-1"></a>        g_loss.backward()</span>
<span id="cb52-178"><a href="#cb52-178" aria-hidden="true" tabindex="-1"></a>        g_optimizer.step()</span>
<span id="cb52-179"><a href="#cb52-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-180"><a href="#cb52-180" aria-hidden="true" tabindex="-1"></a>        g_losses.append(g_loss.detach())</span>
<span id="cb52-181"><a href="#cb52-181" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-182"><a href="#cb52-182" aria-hidden="true" tabindex="-1"></a>        EMA(g_running, g)</span>
<span id="cb52-183"><a href="#cb52-183" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-184"><a href="#cb52-184" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb52-185"><a href="#cb52-185" aria-hidden="true" tabindex="-1"></a>        sample_z <span class="op">=</span> torch.randn(<span class="dv">8</span>, <span class="dv">256</span>, <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb52-186"><a href="#cb52-186" aria-hidden="true" tabindex="-1"></a>        sample_imgs <span class="op">=</span> g(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-187"><a href="#cb52-187" aria-hidden="true" tabindex="-1"></a>        sample_imgs_EMA <span class="op">=</span> g_running(sample_z, layer_num<span class="op">=</span>layer_num, alpha<span class="op">=</span>alpha)</span>
<span id="cb52-188"><a href="#cb52-188" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Images after stabilising layer: </span><span class="sc">{</span>layer_num<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb52-189"><a href="#cb52-189" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G images'</span>)</span>
<span id="cb52-190"><a href="#cb52-190" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs)</span>
<span id="cb52-191"><a href="#cb52-191" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'G_running images'</span>)</span>
<span id="cb52-192"><a href="#cb52-192" aria-hidden="true" tabindex="-1"></a>        show_images(sample_imgs_EMA)</span>
<span id="cb52-193"><a href="#cb52-193" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-194"><a href="#cb52-194" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 4x4</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ff449e6a8e0441d58e35a9ec943789b0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after introducing layer: 1
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"eebbb0ae5a8840b7b38a89066037c3aa","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after stabilising layer: 1
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-11.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 8x8</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"37847e34683a4403bee5659972706bca","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after introducing layer: 2
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-15.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-17.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ecb0e8374c0f44c0842346a0918e46b9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after stabilising layer: 2
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-20.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-22.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 16x16</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"585b08a915ac48baba1922c56ad4d420","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after introducing layer: 3
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-26.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-28.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10f78991ae9f4b64a235378fe1055315","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after stabilising layer: 3
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-31.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-33.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 32x32</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f8415aad2b7549fd8bd4bb7892e78640","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after introducing layer: 4
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-37.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-39.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7bb0094b79a441c6bab423d2753c9fe8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after stabilising layer: 4
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-42.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-44.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 64x64</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"409d870dcf4e448496b5c5614f93da8f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after introducing layer: 5
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-48.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-50.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ca3f4b16430741b48e4c4bd1a1d2f96a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Images after stabilising layer: 5
G images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-53.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>G_running images</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-27-output-55.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training resolution: 128x128</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb3f2312dd274d7c86f56321a36ea656","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<p>There we have it, you’ve implemented the PGGAN let’s give ourselves a pat on the back!</p>
<p>Look at those beautiful generated faces xD. I’m sure you see some artifacting or issues but they look pretty good dont they? Comparing them to the Gulrajani case, I hope you can see that the progressive growing has it’s benefits (look at the loss plots below for hard proof), the backgrounds are much better handled and the faces look alot more realistic (to me at least). Also, we have seemingly dealt with the low variance of outputs issue. If you want to dig deeper on this, remove the MiniBatch StdDev layer and see how it affects the full case PGGAN this is one way to check if it actually does increase the variance of outputs.</p>
<p><b>VERIFY THIS FIRST BEFORE PUBLISH&lt; Before moving on, let me point out that the g_running images are exactly identical to the g images. This highlights an important factor of GANs, they are deterministic in that if you if provide the same input you will always get the same output. This fact leads me to believe either my implementation of EMA is incorrect or it has little to no effect.</b></p><b>
<p>Firstly, in the paper they use differing batch sizes depending on the resolution being generated due to memory constrains, I throw this out in favour of a small batch size. The poinf of throwing it out is for simplicity.</p>
<p>Secondly, the training process for PGGAN is quite alot quicker than the Gulrajani case and is much more stable. This is an inherent benefit of the PGGAN, the stability comes from the growing. In the early stages there is less information for the network to learn and as such it does a better job of learning the information necessary to create low resolution images. This makes the overall task simpler, we are learning the features in steps rather than asking the network to discover a mapping from 4x4 -&gt; 256x256 in one step. Regarding the speed, the improvement comes from the fact that alot of computation happens at lower resolutions, simply less numbers = faster computation (you can observe this in the progress bar, the it/s decreases as we add more layers and increase the resolution).</p>
<p>The fact that the full case learns better is due to this introduction of steps, without the growing each layer in the Gulrajani GAN is tasked with simultaneously finding successive representations for both large scale (at low resolutions) and small scale (at high resolutions) details. Growing allows earlier layers to converge early on and reach an optimal point, i.e.&nbsp;a good foundation for successive layers to build upon.</p>
<div id="573ce59a" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming d_losses and g_losses are lists of GPU tensors</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>d_losses_cpu <span class="op">=</span> [loss.cpu().detach().numpy() <span class="cf">for</span> loss <span class="kw">in</span> d_losses]</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>g_losses_cpu <span class="op">=</span> [loss.cpu().detach().numpy() <span class="cf">for</span> loss <span class="kw">in</span> g_losses]</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>plt.plot(d_losses_cpu, label<span class="op">=</span><span class="st">'Discriminator Loss'</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>plt.plot(g_losses_cpu, label<span class="op">=</span><span class="st">'Generator Loss'</span>)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iterations'</span>)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Generator and Discriminator Loss Over Time in Full Case'</span>)</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Progressive_GAN_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now then, we’ve implemented two versions of a PGGAN and explored how the techniques in the full case improve the training process and the outputs themselves! I hope you can see we get some pretty good looking outputs, perhaps if you train the models for longer you can improve the quality even further. Another thing you may want to try, is to increase the resolution we grow to (e.g.&nbsp;512x512 images). The PGGAN was a big thing in it’s time, one of the first GANs to generate somewhat high resolution images.</p>
<hr>
<p><a id="1" style="text-decoration: none; color: inherit;" href=""><sup>1</sup></a> Add image here from goodfellow GAN</p>
<p><a id="2" style="text-decoration: none; color: inherit;" href=""><sup>2</sup></a> I abbreviate Generative Adversarial Network to GAN and this refers to the one proposed by <a href="https://arxiv.org/abs/1406.2661">Goodfellow, et al</a></p>
<p><a id="3" style="text-decoration: none; color: inherit;" href=""><sup>3</sup></a><a href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf"> Learning Multiple Layers of Features from Tiny Images</a></p>
<p><a id="4" style="text-decoration: none; color: inherit;" href=""><sup>4</sup></a> This name comes from the fact the training regime follows the paper by <a href="https://arxiv.org/abs/1704.00028">Gulrajani et al.&nbsp;(2017) </a></p>
<p><a id="5" style="text-decoration: none; color: inherit;" href=""><sup>5</sup></a> I found that when updating the D model more frequently than the G model (this parameter is called <span class="math inline">\(n_{critic}\)</span>, the training was a lot less stable as the D model became too strong in the game.</p>
<p><a id="6" style="text-decoration: none; color: inherit;" href=""><sup>6</sup></a> Here’s a useful resource to build your understanding of PyTorch and what I’ve done here and other useful tricks: <a href="https://github.com/FrancescoSaverioZuppichini/Pytorch-how-and-when-to-use-Module-Sequential-ModuleList-and-ModuleDict">https://github.com/FrancescoSaverioZuppichini/Pytorch-how-and-when-to-use-Module-Sequential-ModuleList-and-ModuleDict</a></p>
<p><a id="7" style="text-decoration: none; color: inherit;" href=""><sup>7</sup></a> I want to give credit to the repo I used to build out my training loop, I admit I had a lot of trouble setting this up but this is okay. Remeber to never give up and don’t be afraid to ask for help :) <a href="https://github.com/odegeasslbc/Progressive-GAN-pytorch/tree/master">https://github.com/odegeasslbc/Progressive-GAN-pytorch/tree/master</a></p>
<p><a id="8" style="text-decoration: none; color: inherit;" href=""><sup>8</sup> </a><a href="https://arxiv.org/pdf/1701.07875">Wasserstein GAN Paper, Martin Arjovsky, et al.</a> Note, in this paper and in other WGAN related materials the discriminator model is called the critic but they mean the same thing.</p>
<p><a id="9" style="text-decoration: none; color: inherit;" href=""><sup>9</sup> </a>If there is anything unclear here, or you think I made a mistake please feel free to reach out to me. I’d be happy to discuss WGAN or any apsects of the paper! @ <a href="mailto:y%75sufmohamma%64@l%69ve.com">yusufmohammad@live.com</a></p>
<p><a id="10" style="text-decoration: none; color: inherit;" href=""><sup>10</sup></a> A k-Lipschitz constraint requires that the norms of the gradients of a function F (in our case the D model, remember a neural network is just a fancy function) have value 1 almost everywhere.</p>
<p><a id="11" style="text-decoration: none; color: inherit;" href=""><sup>11</sup></a> The WGAN-GP paper states layer norm is a good drop in for BN which is exactly what we did in the Gulrajani case.</p>
<p><a id="12" style="text-decoration: none; color: inherit;" href=""><sup>12</sup></a> You can find the authors implemenation here: <a href="https://github.com/tkarras/progressive_growing_of_gans/blob/master/networks.py">https://github.com/tkarras/progressive_growing_of_gans/blob/master/networks.py</a></p>
<p><a id="13" style="text-decoration: none; color: inherit;" href=""><sup>13</sup></a> This is kind of a cheat on my part, but I was stumped for about 3 weeks trying to implement my PGGAN until I found that repo. I think this sort of thing is okay in the journey to learning and it’s okay to get stuck on things which are hard. We are taking this journey of learning together and we cannot make it the whole way alone. To that end, here’s my email <a href="mailto:y%75sufmohamma%64@l%69ve.com">yusufmohammad@live.com</a>. Feel free to reach out!</p>
<p><a id="14" style="text-decoration: none; color: inherit;" href=""><sup>14</sup></a> So I actually observed this in practise, I made an error in my PixelNorm and had switched the / for a *. This resulted in the norms of the network exploding, the weights dynamic range exploded too and training failed.</p>
<p><a id="15" style="text-decoration: none; color: inherit;" href=""><sup>15</sup></a> This is to the best of my knowledge, feel free to correct me here. Another reason for the use of Leaky ReLU maybe to reduce sparsity as mentioned in hack 5 @ <a href="https://github.com/soumith/ganhacks">https://github.com/soumith/ganhacks</a></p>
<p><a id="16" style="text-decoration: none; color: inherit;" href=""><sup>16</sup></a> <a href="https://leimao.github.io/blog/Exponential-Moving-Average/">https://leimao.github.io/blog/Exponential-Moving-Average/</a></p>
</b></section><b>
</b></section><b>

</b></main><b>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</b></div><b> <!-- /content -->




</b></body></html>