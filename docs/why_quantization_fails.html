<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yusuf Mohammad">
<meta name="dcterms.date" content="2026-02-11">

<title>EyesOff: Why Some Models Quantize Better Than Others</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="why_quantization_fails_files/libs/clipboard/clipboard.min.js"></script>
<script src="why_quantization_fails_files/libs/quarto-html/quarto.js"></script>
<script src="why_quantization_fails_files/libs/quarto-html/popper.min.js"></script>
<script src="why_quantization_fails_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="why_quantization_fails_files/libs/quarto-html/anchor.min.js"></script>
<link href="why_quantization_fails_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="why_quantization_fails_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="why_quantization_fails_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="why_quantization_fails_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="why_quantization_fails_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#a-case-study-on-quantizing-efficientnetb0-and-resnet18" id="toc-a-case-study-on-quantizing-efficientnetb0-and-resnet18" class="nav-link active" data-scroll-target="#a-case-study-on-quantizing-efficientnetb0-and-resnet18">A case study on Quantizing EfficientNetB0 and ResNet18</a>
  <ul>
  <li><a href="#benchmarking-the-efficientnetb0-quantization" id="toc-benchmarking-the-efficientnetb0-quantization" class="nav-link" data-scroll-target="#benchmarking-the-efficientnetb0-quantization">Benchmarking the EfficientNetB0 Quantization</a>
  <ul class="collapse">
  <li><a href="#quantizing-the-pytorch-model" id="toc-quantizing-the-pytorch-model" class="nav-link" data-scroll-target="#quantizing-the-pytorch-model">Quantizing the PyTorch Model</a></li>
  <li><a href="#benchmarking-speed-accuracy" id="toc-benchmarking-speed-accuracy" class="nav-link" data-scroll-target="#benchmarking-speed-accuracy">Benchmarking Speed + Accuracy</a></li>
  </ul></li>
  <li><a href="#is-it-me-or-the-model---testing-resnet18" id="toc-is-it-me-or-the-model---testing-resnet18" class="nav-link" data-scroll-target="#is-it-me-or-the-model---testing-resnet18">Is it Me or the Model - Testing ResNet18</a>
  <ul class="collapse">
  <li><a href="#inspecting-the-weight-and-activation-values-of-resnet18-and-efficientnetb0-pre-quantization" id="toc-inspecting-the-weight-and-activation-values-of-resnet18-and-efficientnetb0-pre-quantization" class="nav-link" data-scroll-target="#inspecting-the-weight-and-activation-values-of-resnet18-and-efficientnetb0-pre-quantization">Inspecting the Weight and Activation Values of ResNet18 and EfficientNetB0 Pre-Quantization</a></li>
  <li><a href="#why-does-a-larger-range-make-it-harder-for-int8" id="toc-why-does-a-larger-range-make-it-harder-for-int8" class="nav-link" data-scroll-target="#why-does-a-larger-range-make-it-harder-for-int8">Why Does a Larger Range Make it Harder for INT8?</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#why-resnet18-quantizes-well-and-efficientnetb0-doesnt---a-component-by-component-analysis" id="toc-why-resnet18-quantizes-well-and-efficientnetb0-doesnt---a-component-by-component-analysis" class="nav-link" data-scroll-target="#why-resnet18-quantizes-well-and-efficientnetb0-doesnt---a-component-by-component-analysis">Why ResNet18 Quantizes Well and EfficientNetB0 Doesn’t - A Component by Component Analysis</a>
  <ul>
  <li><a href="#the-investigation---studying-the-layers" id="toc-the-investigation---studying-the-layers" class="nav-link" data-scroll-target="#the-investigation---studying-the-layers">The Investigation - Studying the Layers</a>
  <ul class="collapse">
  <li><a href="#building-the-models" id="toc-building-the-models" class="nav-link" data-scroll-target="#building-the-models">Building the models</a></li>
  </ul></li>
  <li><a href="#exploring-training-time-dynamics" id="toc-exploring-training-time-dynamics" class="nav-link" data-scroll-target="#exploring-training-time-dynamics">Exploring Training Time Dynamics</a>
  <ul class="collapse">
  <li><a href="#going-back-to-the-eyesoff-models" id="toc-going-back-to-the-eyesoff-models" class="nav-link" data-scroll-target="#going-back-to-the-eyesoff-models">Going Back to the EyesOff Models</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="https://ym2132.github.io/" target="_blank"><i class="bi bi-link-45deg"></i>Yusuf's Deep Learning Blog</a></li><li><a href="https://github.com/YM2132?tab=repositories" target="_blank"><i class="bi bi-link-45deg"></i>Yusuf's GitHub</a></li><li><a href="https://www.eyesoff.app" target="_blank"><i class="bi bi-link-45deg"></i>EyesOff.app</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">EyesOff: Why Some Models Quantize Better Than Others</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yusuf Mohammad </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 11, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TLDR
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Some models quantize better than others, in this case it was EfficientNetB0 and ResNet18 (the latter quantized better).</p>
<p>The issue is that the range of activation values of the EfficientNetB0 network is quite large, this is caused by the architecture, so when they are cast to INT8 values the error is large.</p>
<p>Therefore, when training your own models then if quantization is in the pipeline, check the ranges of activation values <b>post training</b> if the range is large you might see issues with quantization.</p>
<p><b>NOTE</b>: You must check the values post training as at init time the model might not display the same activation behaviour.</p>
</div>
</div>
</div>
<div class="glossary">
<p>Glossary</p>
<dl>
<dt>ENB0</dt>
<dd>
EfficientNetB0
</dd>
<dt>RN18</dt>
<dd>
ResNet18
</dd>
</dl>
</div>
<hr>
<section id="a-case-study-on-quantizing-efficientnetb0-and-resnet18" class="level2">
<h2 class="anchored" data-anchor-id="a-case-study-on-quantizing-efficientnetb0-and-resnet18">A case study on Quantizing EfficientNetB0 and ResNet18</h2>
<p>Quantization was employed in an effort to speedup and reduce the battery usage<a href="#5"><sup>5</sup></a> of the model used in EyesOff (EfficientNet_B0). However, when testing the quantized model on the benchmark the accuracy dropped massively (from <b>~90% to ~34%</b>). This sparked an investigation to understand why ENB0 quantizes poorly and why another model (RN18) quantizes well.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quantization Theory Overview
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>It’s useful to look into some of the theory of quantization before diving deep into experiments, it will become especially useful later.</p>
<p>The goal of quantization is to convert a FloatingPoint32 (FP32) model into an 8-bit integer (INT8) model. I.e. the weights and activations of the model are cast to INT8, however it is not a simple cast. By doing this we gain speed, efficiency and a reduction in memory usage - at the cost of some accuracy (depending on the model…).</p>
<p>So for a given model, we will have a range of FP32 values <span class="math inline">\([a, b]\)</span> and the goal is to convert this range into the INT8 space. Now imagine a value <span class="math inline">\(x\)</span>, which belongs to the range <span class="math inline">\([a, b]\)</span>. This <span class="math inline">\(x\)</span> can be defined by the following quantization scheme:</p>
<p><span class="math display">\[
x = S * (x_{q} - Z)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(x_{q}\)</span> = INT8 Quantized <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(S\)</span> = Scale factor (a positive FP32 value)</li>
<li><span class="math inline">\(Z\)</span> = Zero point, the INT8 value corresponding to 0 in the FP32 realm.</li>
</ul>
<p>Therefore, <span class="math inline">\(x_{q}\)</span> can be defined as:</p>
<p><span class="math display">\[
x_{q} = round(\frac{x}{S} + Z)
\]</span></p>
<section id="quantization-calibration" class="level5">
<h5 class="anchored" data-anchor-id="quantization-calibration">Quantization calibration</h5>
<p>We’ve discussed <span class="math inline">\([a, b]\)</span> a bit already, but how do we actually get these values? For weights it is easy, as weights are fixed and are known ahead of time, it becomes trickier when considering activations which may vary based on the input. This is the point of calibration and there are three types of calibration:</p>
<p>• <b>Post-Training Dynamic Quantization</b> - the range for each activation is computed on the fly at inference time, this method is very accurate however it can be slower due to the overhead of on the fly computations.</p>
<p>• <b>Static Quantization</b> (what I use in this post) - range computed in advance at quantization time. By passing representative examples (training data for example) we can calculate the expected range of FP32 activation values ahead of time. This is much quicker but does come at the cost of some accuracy, as the ranges are only as good as the examples we provide - think of general issues with generalisability and OOD samples.</p>
<p>• <b>Quantization Aware Training</b> - the range for each activation is computed at training time. It’s similar to static, but it is a bit more involved.</p>
<p>Now one simple way to actually calculate the range <span class="math inline">\([a, b]\)</span> is to take the worst case of minimum value and maximum value when calibrating the model. Refer to the further reading for other approaches<a href="#1"><sup>1</sup></a>.</p>
<p>Further reading on quantization: <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">https://leimao.github.io/article/Neural-Networks-Quantization/</a></p>
<p><a href="https://arxiv.org/abs/1712.05877">https://arxiv.org/abs/1712.05877</a></p>
</section>
</div>
</div>
</div>
<section id="benchmarking-the-efficientnetb0-quantization" class="level3">
<h3 class="anchored" data-anchor-id="benchmarking-the-efficientnetb0-quantization">Benchmarking the EfficientNetB0 Quantization</h3>
<section id="quantizing-the-pytorch-model" class="level4">
<h4 class="anchored" data-anchor-id="quantizing-the-pytorch-model">Quantizing the PyTorch Model</h4>
<p>In the expandable box you will find the code to quantize the model, taking a .pth model and outputting an INT8 quantized .onnx model.</p>
<div id="347baf59-e5a8-40fb-b1ed-ff800de2fad4" class="cell" data-execution_count="171">
<details class="code-fold">
<summary>Quantize the model</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Code to quantize the model</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> models</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> onnxruntime <span class="im">as</span> ort</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> onnxruntime.quantization.preprocess <span class="im">import</span> quant_pre_process</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> onnxruntime.quantization <span class="im">import</span> (</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    quantize_static,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    QuantType,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    QuantFormat,</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    CalibrationDataReader</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>INPUT_PTH_PATH <span class="op">=</span> <span class="st">"./model.pth"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>OUTPUT_ONNX_PATH <span class="op">=</span> <span class="st">"./model.onnx"</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> <span class="dv">224</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_efficientnet_b0():</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Build EfficientNet-B0 with custom binary classification head."""</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.efficientnet_b0(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    model.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">1280</span>, <span class="dv">128</span>),</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>),</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_pth_to_onnx(pth_path, onnx_path, img_size<span class="op">=</span><span class="dv">224</span>):</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Convert PyTorch model to ONNX.</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">        pth_path: Path to .pth weights file</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co">        onnx_path: Output path for .onnx file</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">        model_name: Architecture name (must match training)</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co">        img_size: Input image size</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"PyTorch → ONNX Conversion"</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'='</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Input:  </span><span class="sc">{</span>pth_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Output: </span><span class="sc">{</span>onnx_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> build_efficientnet_b0()</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load weights</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    state_dict <span class="op">=</span> torch.load(pth_path, map_location<span class="op">=</span><span class="st">'cpu'</span>, weights_only<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(state_dict, <span class="bu">dict</span>) <span class="kw">and</span> <span class="st">'model_state_dict'</span> <span class="kw">in</span> state_dict:</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        state_dict <span class="op">=</span> state_dict[<span class="st">'model_state_dict'</span>]</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(state_dict)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create dummy input</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    dummy_input <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">3</span>, img_size, img_size)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Export to ONNX</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    torch.onnx.export(</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        model,</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        dummy_input,</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        onnx_path,</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>        export_params<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>        opset_version<span class="op">=</span><span class="dv">21</span>,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        do_constant_folding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        input_names<span class="op">=</span>[<span class="st">'input'</span>],</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        output_names<span class="op">=</span>[<span class="st">'output'</span>],</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>        dynamic_axes<span class="op">=</span>{</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>            <span class="st">'input'</span>: {<span class="dv">0</span>: <span class="st">'batch_size'</span>},</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>            <span class="st">'output'</span>: {<span class="dv">0</span>: <span class="st">'batch_size'</span>}</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>        dynamo<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> onnx</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    onnx_model <span class="op">=</span> onnx.load(onnx_path)</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    onnx.checker.check_model(onnx_model)</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>    size_mb <span class="op">=</span> Path(onnx_path).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Conversion complete"</span>)</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Size: </span><span class="sc">{</span>size_mb<span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> onnx_path</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>convert_pth_to_onnx(INPUT_PTH_PATH, OUTPUT_ONNX_PATH, IMG_SIZE)</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Preprocess the onnx model to further optimize</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>INPUT_ONNX_PATH <span class="op">=</span> <span class="st">"./model.onnx"</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>OUTPUT_PREPROCESSED_PATH <span class="op">=</span> <span class="st">"./model_preprocessed.onnx"</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_for_quantization(input_path, output_path):</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="co">    Preprocess ONNX model for better quantization results.</span></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="co">    This step performs:</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="co">    - Symbolic shape inference</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="co">    - ONNX Runtime optimization (fuses Conv+BN, etc.)</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="co">    - ONNX shape inference</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="co">        input_path: Path to input ONNX model</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="co">        output_path: Path for preprocessed output</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="co">        output_path on success</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"ONNX Preprocessing for Quantization"</span>)</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'='</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Input:  </span><span class="sc">{</span>input_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Output: </span><span class="sc">{</span>output_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>        quant_pre_process(</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>            input_model_path<span class="op">=</span>input_path,</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>            output_model_path<span class="op">=</span>output_path,</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>            skip_optimization<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>            skip_onnx_shape<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>            skip_symbolic_shape<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>            auto_merge<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>            verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>        in_size <span class="op">=</span> Path(input_path).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>        out_size <span class="op">=</span> Path(output_path).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  ✓ Preprocessing complete"</span>)</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Size: </span><span class="sc">{</span>in_size<span class="sc">:.2f}</span><span class="ss"> MB → </span><span class="sc">{</span>out_size<span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output_path</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  ⚠️ Preprocessing failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Falling back to copy of original"</span>)</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>        <span class="im">import</span> shutil</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>        shutil.copy(input_path, output_path)</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output_path</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>preprocess_for_quantization(INPUT_ONNX_PATH, OUTPUT_PREPROCESSED_PATH)</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="co"># Load calibration data</span></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="co"># Here you would have to load data in the same format which you used to train the model</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data_npz(npz_path):</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> np.load(npz_path, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">list</span>(data[<span class="st">"frames"</span>])</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>calibration_data <span class="op">=</span> load_data_npz(<span class="st">"./calibration_data.npz"</span>)</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>INPUT_PREPROCESSED_PATH <span class="op">=</span> <span class="st">"model_preprocessed.onnx"</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>OUTPUT_INT8_PATH <span class="op">=</span> <span class="st">"model_int8_static.onnx"</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_imagenet(img_bgr):</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Standard ImageNet preprocessing for calibration."""</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.resize(img_bgr, (<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.astype(np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> np.transpose(img, (<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> np.array([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], dtype<span class="op">=</span>np.float32)[:, <span class="va">None</span>, <span class="va">None</span>]</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.array([<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>], dtype<span class="op">=</span>np.float32)[:, <span class="va">None</span>, <span class="va">None</span>]</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> (img <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> img</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CalibrationReader(CalibrationDataReader):</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Reads calibration data for static quantization."""</span></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, imgs, preprocess_fn):</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.imgs <span class="op">=</span> imgs</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.preprocess_fn <span class="op">=</span> preprocess_fn</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Calibration samples: </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.imgs)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_next(<span class="va">self</span>):</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.index <span class="op">&gt;=</span> <span class="bu">len</span>(<span class="va">self</span>.imgs):</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>        frame <span class="op">=</span> <span class="va">self</span>.imgs[<span class="va">self</span>.index]</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.index <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.preprocess_fn(frame)[np.newaxis, ...].astype(np.float32)</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">'input'</span>: x}</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> rewind(<span class="va">self</span>):</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> quantize_int8_static(input_path, output_path, calibration_data, preprocess_fn):</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="co">    Static INT8 quantization with QDQ format.</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="co">        input_path: Path to preprocessed ONNX model</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="co">        output_path: Output path for INT8 model</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="co">        calibration_data: List of BGR images for calibration</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="co">        preprocess_fn: Preprocessing function</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"INT8 Static Quantization (QDQ Format)"</span>)</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'='</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Input:  </span><span class="sc">{</span>input_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Output: </span><span class="sc">{</span>output_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>    calibration_reader <span class="op">=</span> CalibrationReader(calibration_data, preprocess_fn)</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>    quantize_static(</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>        model_input<span class="op">=</span>input_path,</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>        model_output<span class="op">=</span>output_path,</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>        calibration_data_reader<span class="op">=</span>calibration_reader,</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>        quant_format<span class="op">=</span>QuantFormat.QDQ,</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>        per_channel<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>        weight_type<span class="op">=</span>QuantType.QInt8,</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>        activation_type<span class="op">=</span>QuantType.QInt8,</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>    in_size <span class="op">=</span> Path(input_path).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>    out_size <span class="op">=</span> Path(output_path).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Quantization complete"</span>)</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Size: </span><span class="sc">{</span>in_size<span class="sc">:.2f}</span><span class="ss"> MB → </span><span class="sc">{</span>out_size<span class="sc">:.2f}</span><span class="ss"> MB (</span><span class="sc">{</span>in_size<span class="op">/</span>out_size<span class="sc">:.1f}</span><span class="ss">x smaller)"</span>)</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_path</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>output_path <span class="op">=</span> quantize_int8_static(INPUT_PREPROCESSED_PATH, OUTPUT_INT8_PATH, calibration_data, preprocess_imagenet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
PyTorch → ONNX Conversion
============================================================
  Input:  ./model.pth
  Output: ./model.onnx
  ✓ Conversion complete
  Size: 15.90 MB

============================================================
ONNX Preprocessing for Quantization
============================================================
  Input:  ./model.onnx
  Output: ./model_preprocessed.onnx
  ✓ Preprocessing complete
  Size: 15.90 MB → 15.93 MB

============================================================
INT8 Static Quantization (QDQ Format)
============================================================
  Input:  model_preprocessed.onnx
  Output: model_int8_static.onnx
  Calibration samples: 1000
  ✓ Quantization complete
  Size: 15.93 MB → 4.44 MB (3.6x smaller)</code></pre>
</div>
</div>
</section>
<section id="benchmarking-speed-accuracy" class="level4">
<h4 class="anchored" data-anchor-id="benchmarking-speed-accuracy">Benchmarking Speed + Accuracy</h4>
<p>With the quantized model in hand, it’s time to benchmark - the first benchmark is speed (as increased inference speed was one of initial goals).</p>
<div id="17f00a7e-68f7-49f0-adf2-8f59088e57dc" class="cell" data-scrolled="true" data-execution_count="2">
<details class="code-fold">
<summary>Benchmark the quantized model</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>FP32_MODEL_PATH <span class="op">=</span> <span class="st">"./model_preprocessed.onnx"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>INT8_MODEL_PATH <span class="op">=</span> <span class="st">"model_int8_static.onnx"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>FRAMES_DIR <span class="op">=</span> <span class="st">'./frames'</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>NUM_WARMUP <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>NUM_BENCHMARK <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_onnx_model(model_path, provider<span class="op">=</span><span class="st">'cpu'</span>):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Load ONNX model with specified provider."""</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    providers <span class="op">=</span> [<span class="st">'CPUExecutionProvider'</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> provider <span class="op">==</span> <span class="st">'coreml'</span>:</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        providers <span class="op">=</span> [<span class="st">'CoreMLExecutionProvider'</span>, <span class="st">'CPUExecutionProvider'</span>]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    sess_options <span class="op">=</span> ort.SessionOptions()</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    sess_options.graph_optimization_level <span class="op">=</span> ort.GraphOptimizationLevel.ORT_ENABLE_ALL</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ort.InferenceSession(model_path, sess_options, providers<span class="op">=</span>providers)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> warmup_onnx(session, dummy_input, n<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Warmup ONNX session."""</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    input_name <span class="op">=</span> session.get_inputs()[<span class="dv">0</span>].name</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> dummy_input[np.newaxis, ...].astype(np.float32)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        session.run(<span class="va">None</span>, {input_name: x})</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> benchmark_onnx(session, frames, preprocess_fn, num_runs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Benchmark ONNX model inference.</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co">        List of inference times (seconds per frame)</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    input_name <span class="op">=</span> session.get_inputs()[<span class="dv">0</span>].name</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    times <span class="op">=</span> []</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_runs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        num_runs <span class="op">=</span> <span class="bu">len</span>(frames)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(num_runs, <span class="bu">len</span>(frames))):</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> preprocess_fn(frames[i])[np.newaxis, ...].astype(np.float32)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.perf_counter()</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        session.run(<span class="va">None</span>, {input_name: x})</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        t1 <span class="op">=</span> time.perf_counter()</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>        times.append(t1 <span class="op">-</span> t0)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> times</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_benchmark_results(results):</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Print benchmark results table."""</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">80</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"BENCHMARK RESULTS"</span>)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'='</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Model'</span><span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Size (MB)'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'ms/frame'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'FPS'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Speedup'</span><span class="sc">:&lt;10}</span><span class="ss">"</span>)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>    baseline_ms <span class="op">=</span> results[<span class="dv">0</span>][<span class="st">'ms'</span>]</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> r <span class="kw">in</span> results:</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>        speedup <span class="op">=</span> baseline_ms <span class="op">/</span> r[<span class="st">'ms'</span>]</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>r[<span class="st">'name'</span>]<span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span>r[<span class="st">'size'</span>]<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>r[<span class="st">'ms'</span>]<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>r[<span class="st">'fps'</span>]<span class="sc">:&lt;10.1f}</span><span class="ss"> </span><span class="sc">{</span>speedup<span class="sc">:&lt;10.2f}</span><span class="ss">x"</span>)</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Load test frames</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading test frames..."</span>)</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>frames_dir <span class="op">=</span> Path(FRAMES_DIR)</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>frame_files <span class="op">=</span> <span class="bu">sorted</span>(frames_dir.glob(<span class="st">'*.jpg'</span>))[:NUM_BENCHMARK]</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> [cv2.imread(<span class="bu">str</span>(f)) <span class="cf">for</span> f <span class="kw">in</span> frame_files]</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> frames <span class="cf">if</span> f <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>]</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(frames)<span class="sc">}</span><span class="ss"> frames"</span>)</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dummy input for warmup</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> preprocess_imagenet(frames[<span class="dv">0</span>])</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Load models</span></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Loading models..."</span>)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>fp32_session <span class="op">=</span> load_onnx_model(FP32_MODEL_PATH, <span class="st">'cpu'</span>)</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>int8_session <span class="op">=</span> load_onnx_model(INT8_MODEL_PATH, <span class="st">'cpu'</span>)</span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Warmup</span></span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Warming up..."</span>)</span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>warmup_onnx(fp32_session, dummy_input, NUM_WARMUP)</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>warmup_onnx(int8_session, dummy_input, NUM_WARMUP)</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Benchmark</span></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Benchmarking on </span><span class="sc">{</span><span class="bu">len</span>(frames)<span class="sc">}</span><span class="ss"> frames..."</span>)</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  FP32..."</span>)</span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>fp32_times <span class="op">=</span> benchmark_onnx(fp32_session, frames, preprocess_imagenet)</span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  INT8..."</span>)</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>int8_times <span class="op">=</span> benchmark_onnx(int8_session, frames, preprocess_imagenet)</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> [</span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a>        <span class="st">'name'</span>: <span class="st">'FP32 ONNX'</span>,</span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a>        <span class="st">'size'</span>: Path(FP32_MODEL_PATH).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>),</span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ms'</span>: np.mean(fp32_times) <span class="op">*</span> <span class="dv">1000</span>,</span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a>        <span class="st">'fps'</span>: <span class="dv">1000</span> <span class="op">/</span> (np.mean(fp32_times) <span class="op">*</span> <span class="dv">1000</span>),</span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a>        <span class="st">'name'</span>: <span class="st">'INT8 Static (QDQ)'</span>,</span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a>        <span class="st">'size'</span>: Path(INT8_MODEL_PATH).stat().st_size <span class="op">/</span> (<span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>),</span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ms'</span>: np.mean(int8_times) <span class="op">*</span> <span class="dv">1000</span>,</span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a>        <span class="st">'fps'</span>: <span class="dv">1000</span> <span class="op">/</span> (np.mean(int8_times) <span class="op">*</span> <span class="dv">1000</span>),</span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a>print_benchmark_results(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Loading test frames...
Loaded 100 frames

Loading models...
Warming up...

Benchmarking on 100 frames...
  FP32...
  INT8...

================================================================================
BENCHMARK RESULTS
================================================================================
Model                               Size (MB)    ms/frame     FPS        Speedup   
--------------------------------------------------------------------------------
FP32 ONNX                           15.93        7.88         127.0      1.00      x
INT8 Static (QDQ)                   4.44         3.68         271.7      2.14      x</code></pre>
</div>
</div>
<p>Much quicker, lovely jubbly!</p>
<p>Now, let’s run the model on the test data and check how it performs vs the unquantized model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="why_quantization_fails_files/figure-html/aa3e7d7c-0a42-4c3a-9f43-69344bd40cb5-1-1166d917-0688-4dfc-81ce-fe87bf4d88b6.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1 - EfficientNetB0 Metrics across benchmark videos</figcaption>
</figure>
</div>
<p>The accuracy drop is huge! The quantized ENB0 is unusable - time to find out why!</p>
</section>
</section>
<section id="is-it-me-or-the-model---testing-resnet18" class="level3">
<h3 class="anchored" data-anchor-id="is-it-me-or-the-model---testing-resnet18">Is it Me or the Model - Testing ResNet18</h3>
<p>Given the poor performance of the quantized ENB0, my first thought was “is this a bug in my code, or are the results truly reflective of the model?”. To ensure it wasn’t a bug I trained a much simpler model, RN18 (with the exact same quantization setup) and the benchmark results were:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="why_quantization_fails_files/figure-html/5f663b4f-6e8e-4038-b752-c925d2f75e72-1-705eb825-19bd-4895-91c1-8e566448168d.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2 - ResNet18 Metrics across benchmark videos</figcaption>
</figure>
</div>
<p>RN18 quantizes much better, indicating the issue lies with the ENB0 model itself. Note, RN18 INT8 is not immune to accuracy loss, however it’s to be expected and a ~2% accuracy loss is palatable with the inference speedup.</p>
<section id="inspecting-the-weight-and-activation-values-of-resnet18-and-efficientnetb0-pre-quantization" class="level4">
<h4 class="anchored" data-anchor-id="inspecting-the-weight-and-activation-values-of-resnet18-and-efficientnetb0-pre-quantization">Inspecting the Weight and Activation Values of ResNet18 and EfficientNetB0 Pre-Quantization</h4>
<p>To get greater insight into how and why the models respond differently to quantization, we can pass the same input through each model <b>prior to quantization</b> and observe the values of weights and activations at each layer. At this point we’re looking to see how the range of values in activations differ, the ranges and standard deviation etc. Remember that INT8 quantization can represent at most 256 values, so the wider the range of FP32 values the harder it is to fit them into the INT8 range.</p>
<div id="cba2f242-4c4e-4224-b134-a7cf5dfb6c9c" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="3">
<details class="code-fold">
<summary>Run inference on pth models for inspection</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>resnet_18_state_dict <span class="op">=</span> <span class="st">"./resnet_18.pth"</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>efficenet_b0_state_dict <span class="op">=</span> <span class="st">"./efficientnet_b0.pth"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_efficientnet_b0():</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Build EfficientNet-B0 with custom binary classification head."""</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.efficientnet_b0(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    model.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">1280</span>, <span class="dv">128</span>),</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>),</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_resnet18():</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Build ResNet18 with custom binary classification head."""</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.resnet18(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    in_features <span class="op">=</span> model.fc.in_features</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    model.fc <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        nn.Linear(in_features, <span class="dv">128</span>),</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.6</span>),</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>),</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_weights(path):</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Load weights, handling both raw state_dict and checkpoint formats."""</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    checkpoint <span class="op">=</span> torch.load(path, map_location<span class="op">=</span><span class="st">"cpu"</span>, weights_only<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(checkpoint, <span class="bu">dict</span>) <span class="kw">and</span> <span class="st">'model_state_dict'</span> <span class="kw">in</span> checkpoint:</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint[<span class="st">'model_state_dict'</span>]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> checkpoint</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="co"># ImageNet normalization</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.array([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], dtype<span class="op">=</span>np.float32)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> np.array([<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>], dtype<span class="op">=</span>np.float32)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess(face_crop: np.ndarray) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Preprocess face crop for model input."""</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.resize(face_crop, (<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.transpose(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>).astype(np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> (img <span class="op">-</span> mean[:, <span class="va">None</span>, <span class="va">None</span>]) <span class="op">/</span> std[:, <span class="va">None</span>, <span class="va">None</span>]</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.from_numpy(img).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Load model and saved weights into the model</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>resnet_model <span class="op">=</span> build_resnet18()</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>efficientnet_model <span class="op">=</span> build_efficientnet_b0()</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>resnet_model.load_state_dict(load_weights(resnet_18_state_dict))</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>efficientnet_model.load_state_dict(load_weights(efficenet_b0_state_dict))</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>resnet_model.<span class="bu">eval</span>()</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>efficientnet_model.<span class="bu">eval</span>()</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>input_frame <span class="op">=</span> calibration_data[<span class="dv">0</span>]</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>input_frame <span class="op">=</span> preprocess(input_frame)</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    resnet_output <span class="op">=</span> torch.sigmoid(resnet_model(input_frame))</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    efficientnet_output <span class="op">=</span> torch.sigmoid(efficientnet_model(input_frame))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Having loaded the models, and having ran a single input through both allows us to inspect the activation values at each layer.</p>
<div id="3e729e29-c53d-4f55-adcd-58be3b62094a" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-scrolled="true">
<details class="code-fold">
<summary>Print raw statistics for each layer</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_activation_stats(model, input_tensor, model_name<span class="op">=</span><span class="st">"Model"</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Capture activation statistics at ALL layers."""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    activations <span class="op">=</span> {}</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    hooks <span class="op">=</span> []</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> make_hook(name):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> hook(module, <span class="bu">input</span>, output):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(output, torch.Tensor):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>                activations[name] <span class="op">=</span> {</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'shape'</span>: output.shape,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'min'</span>: output.<span class="bu">min</span>().item(),</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'max'</span>: output.<span class="bu">max</span>().item(),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'mean'</span>: output.mean().item(),</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'std'</span>: output.std().item() <span class="cf">if</span> output.numel() <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="fl">0.0</span>,</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'zeros_pct'</span>: (output <span class="op">==</span> <span class="dv">0</span>).<span class="bu">float</span>().mean().item() <span class="op">*</span> <span class="dv">100</span>,</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'layer_type'</span>: module.__class__.<span class="va">__name__</span>,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> hook</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Register hooks on ALL modules (no filtering)</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, module <span class="kw">in</span> model.named_modules():</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> name:  <span class="co"># Skip the root module (empty name)</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>            hooks.append(module.register_forward_hook(make_hook(name)))</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        model(input_tensor)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove hooks</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> h <span class="kw">in</span> hooks:</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        h.remove()</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print results</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">100</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> Activation Statistics (ALL </span><span class="sc">{</span><span class="bu">len</span>(activations)<span class="sc">}</span><span class="ss"> layers)"</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">100</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Layer'</span><span class="sc">:&lt;40}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Type'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Min'</span><span class="sc">:&gt;9}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Max'</span><span class="sc">:&gt;9}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Range'</span><span class="sc">:&gt;9}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Std'</span><span class="sc">:&gt;9}</span><span class="ss">"</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, stats <span class="kw">in</span> activations.items():</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        dyn_range <span class="op">=</span> stats[<span class="st">'max'</span>] <span class="op">-</span> stats[<span class="st">'min'</span>]</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">:&lt;40}</span><span class="ss"> </span><span class="sc">{</span>stats[<span class="st">'layer_type'</span>]<span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span>stats[<span class="st">'min'</span>]<span class="sc">:&gt;9.2f}</span><span class="ss"> </span><span class="sc">{</span>stats[<span class="st">'max'</span>]<span class="sc">:&gt;9.2f}</span><span class="ss"> </span><span class="sc">{</span>dyn_range<span class="sc">:&gt;9.2f}</span><span class="ss"> </span><span class="sc">{</span>stats[<span class="st">'std'</span>]<span class="sc">:&gt;9.2f}</span><span class="ss">"</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> activations</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run with ALL layers</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>input_tensor <span class="op">=</span> preprocess(calibration_data[<span class="dv">0</span>])</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>resnet_acts <span class="op">=</span> get_activation_stats(resnet_model, input_tensor, <span class="st">"ResNet18"</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>effnet_acts <span class="op">=</span> get_activation_stats(efficientnet_model, input_tensor, <span class="st">"EfficientNet-B0"</span>)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total ResNet layers captured: </span><span class="sc">{</span><span class="bu">len</span>(resnet_acts)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total EfficientNet layers captured: </span><span class="sc">{</span><span class="bu">len</span>(effnet_acts)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="3428be70-bcd4-470c-b8f9-ddb78a178771" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="5">
<details class="code-fold">
<summary>Visualise output of above code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the key metrics from your data</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyze_for_quantization(activations):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract quantization-relevant metrics."""</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> []</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, stats <span class="kw">in</span> activations.items():</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        dynamic_range <span class="op">=</span> stats[<span class="st">'max'</span>] <span class="op">-</span> stats[<span class="st">'min'</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        outlier_ratio <span class="op">=</span> <span class="bu">max</span>(<span class="bu">abs</span>(stats[<span class="st">'max'</span>]), <span class="bu">abs</span>(stats[<span class="st">'min'</span>])) <span class="op">/</span> (stats[<span class="st">'std'</span>] <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        metrics.append({</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">'name'</span>: name,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">'dynamic_range'</span>: dynamic_range,</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">'outlier_ratio'</span>: outlier_ratio,</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">'std'</span>: stats[<span class="st">'std'</span>],</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max'</span>: stats[<span class="st">'max'</span>],</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min'</span>: stats[<span class="st">'min'</span>],</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">'mean'</span>: stats[<span class="st">'mean'</span>],</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metrics</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>resnet_metrics <span class="op">=</span> analyze_for_quantization(resnet_acts)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>effnet_metrics <span class="op">=</span> analyze_for_quantization(effnet_acts)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># VISUALIZATION 1: Dynamic Range Comparison (Side-by-side bars)</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ResNet</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>resnet_ranges <span class="op">=</span> [m[<span class="st">'dynamic_range'</span>] <span class="cf">for</span> m <span class="kw">in</span> resnet_metrics]</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].barh(<span class="bu">range</span>(<span class="bu">len</span>(resnet_ranges)), resnet_ranges, color<span class="op">=</span><span class="st">'steelblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Dynamic Range (max - min)'</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'ResNet18: Activation Dynamic Range'</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlim(<span class="dv">0</span>, <span class="dv">250</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a><span class="co"># EfficientNet</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>effnet_ranges <span class="op">=</span> [m[<span class="st">'dynamic_range'</span>] <span class="cf">for</span> m <span class="kw">in</span> effnet_metrics]</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].barh(<span class="bu">range</span>(<span class="bu">len</span>(effnet_ranges)), effnet_ranges, color<span class="op">=</span><span class="st">'coral'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Dynamic Range (max - min)'</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'EfficientNet-B0: Activation Dynamic Range'</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlim(<span class="dv">0</span>, <span class="dv">250</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'dynamic_range_comparison.png'</span>, dpi<span class="op">=</span><span class="dv">150</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="co"># TOP 5 WORST LAYERS COMPARISON</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate dynamic range for each layer</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>resnet_layers <span class="op">=</span> []</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, stats <span class="kw">in</span> resnet_acts.items():</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    resnet_layers.append({</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'name'</span>: name,</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min'</span>: stats[<span class="st">'min'</span>],</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max'</span>: stats[<span class="st">'max'</span>],</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">'dynamic_range'</span>: stats[<span class="st">'max'</span>] <span class="op">-</span> stats[<span class="st">'min'</span>],</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">'std'</span>: stats[<span class="st">'std'</span>]</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>effnet_layers <span class="op">=</span> []</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, stats <span class="kw">in</span> effnet_acts.items():</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    effnet_layers.append({</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">'name'</span>: name,</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min'</span>: stats[<span class="st">'min'</span>],</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max'</span>: stats[<span class="st">'max'</span>],</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">'dynamic_range'</span>: stats[<span class="st">'max'</span>] <span class="op">-</span> stats[<span class="st">'min'</span>],</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">'std'</span>: stats[<span class="st">'std'</span>]</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by dynamic range (worst first)</span></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>resnet_sorted <span class="op">=</span> <span class="bu">sorted</span>(resnet_layers, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'dynamic_range'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>effnet_sorted <span class="op">=</span> <span class="bu">sorted</span>(effnet_layers, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'dynamic_range'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Print comparison</span></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TOP 5 WORST LAYERS BY DYNAMIC RANGE"</span>)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">RESNET18"</span>)</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Rank'</span><span class="sc">:&lt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Layer'</span><span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Min'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Max'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Range'</span><span class="sc">:&gt;10}</span><span class="ss">"</span>)</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, m <span class="kw">in</span> <span class="bu">enumerate</span>(resnet_sorted[:<span class="dv">5</span>], <span class="dv">1</span>):</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> m[<span class="st">'dynamic_range'</span>] <span class="op">/</span> <span class="dv">256</span></span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">:&lt;6}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'name'</span>]<span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'min'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'max'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'dynamic_range'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss">"</span>)</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">EFFICIENTNET-B0"</span>)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Rank'</span><span class="sc">:&lt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Layer'</span><span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Min'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Max'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Range'</span><span class="sc">:&gt;10}</span><span class="ss">"</span>)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, m <span class="kw">in</span> <span class="bu">enumerate</span>(effnet_sorted[:<span class="dv">5</span>], <span class="dv">1</span>):</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> m[<span class="st">'dynamic_range'</span>] <span class="op">/</span> <span class="dv">256</span></span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">:&lt;6}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'name'</span>]<span class="sc">:&lt;35}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'min'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'max'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss"> </span><span class="sc">{</span>m[<span class="st">'dynamic_range'</span>]<span class="sc">:&gt;10.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="why_quantization_fails_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==========================================================================================
TOP 5 WORST LAYERS BY DYNAMIC RANGE

RESNET18
------------------------------------------------------------------------------------------
Rank   Layer                                      Min        Max      Range
------------------------------------------------------------------------------------------
1      conv1                                   -17.45      13.38      30.84
2      layer4.1.bn2                            -11.48      11.88      23.36
3      layer1.0.conv1                           -9.84       4.13      13.97
4      layer4.1.relu                             0.00      12.31      12.31
5      layer4.1                                  0.00      12.31      12.31

EFFICIENTNET-B0
------------------------------------------------------------------------------------------
Rank   Layer                                      Min        Max      Range
------------------------------------------------------------------------------------------
1      features.2.0.block.0.0                 -169.51     158.38     327.90
2      features.2.0.block.1.1                 -163.37     117.90     281.27
3      features.2.1.block.0.0                 -180.45      76.43     256.88
4      features.2.0.block.3.0                 -136.70     111.38     248.08
5      features.2.0.block.0.1                 -101.67     104.81     206.48</code></pre>
</div>
</div>
<p>Wow, would you look at the difference! For now let’s leave the actual layer differences aside and focus attention on the numbers. The big picture here is that <b>ResNet activations values are “nicer”</b> and more uniform layer to layer. The ranges don’t vary wildly, the numbers themselves are much smaller and the standard deviation is much more reasonable. EfficientNet is lacking in all of these aspects and it is this which causes the poor quantization performance.</p>
<p>Let’s dig a little deeper now, first understanding why the range matters and then go on to look at understanding which layer in the ENB0 causes the issues.</p>
</section>
<section id="why-does-a-larger-range-make-it-harder-for-int8" class="level4">
<h4 class="anchored" data-anchor-id="why-does-a-larger-range-make-it-harder-for-int8">Why Does a Larger Range Make it Harder for INT8?</h4>
<p>The greater range makes it harder to bin all the FP32 values into INT8 values. This can be understood further by going back to the formula for quantization:</p>
<p><span class="math display">\[
x_{q} = round(\frac{x}{S} + Z)
\]</span></p>
<p>We can use ONNX to get the <span class="math inline">\(S\)</span> and <span class="math inline">\(Z\)</span> values and manually run through some examples to see how quantization works:</p>
<div id="d4909453-82cd-496d-a664-44a22c2e96c4" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="34">
<details class="code-fold">
<summary>Code to get the S and Z given an ONNX layer name</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> onnx</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> onnx <span class="im">import</span> numpy_helper</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># LOAD QUANTIZATION PARAMETERS FROM ONNX MODELS</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_quant_params(onnx_path):</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract scale and zero_point for each quantized layer."""</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> onnx.load(onnx_path)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    initializers <span class="op">=</span> {init.name: numpy_helper.to_array(init) <span class="cf">for</span> init <span class="kw">in</span> model.graph.initializer}</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    quant_params <span class="op">=</span> {}</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, value <span class="kw">in</span> initializers.items():</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'_scale'</span> <span class="kw">in</span> name:</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            base_name <span class="op">=</span> name.replace(<span class="st">'_scale'</span>, <span class="st">''</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> base_name <span class="kw">not</span> <span class="kw">in</span> quant_params:</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                quant_params[base_name] <span class="op">=</span> {}</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>            quant_params[base_name][<span class="st">'scale'</span>] <span class="op">=</span> <span class="bu">float</span>(value) <span class="cf">if</span> value.size <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> value</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">'_zero_point'</span> <span class="kw">in</span> name:</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>            base_name <span class="op">=</span> name.replace(<span class="st">'_zero_point'</span>, <span class="st">''</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> base_name <span class="kw">not</span> <span class="kw">in</span> quant_params:</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>                quant_params[base_name] <span class="op">=</span> {}</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>            quant_params[base_name][<span class="st">'zero_point'</span>] <span class="op">=</span> <span class="bu">int</span>(value) <span class="cf">if</span> value.size <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> value</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> quant_params</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Load from ONNX models</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>resnet_params <span class="op">=</span> extract_quant_params(<span class="st">'./resnet18_int8.onnx'</span>)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>effnet_params <span class="op">=</span> extract_quant_params(<span class="st">'./model_int8_static.onnx'</span>)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co"># GET SCALE AND ZERO POINT FOR WORST LAYERS</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="co"># ResNet worst layer (conv1 -&gt; bn1 -&gt; relu output)</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>resnet_layer <span class="op">=</span> <span class="st">'/relu/Relu_output_0'</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>resnet_scale <span class="op">=</span> resnet_params[resnet_layer][<span class="st">'scale'</span>]</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>resnet_zp <span class="op">=</span> resnet_params[resnet_layer][<span class="st">'zero_point'</span>]</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="co"># EfficientNet worst layer (features.2.0.block.0.0)</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>effnet_layer <span class="op">=</span> <span class="st">'/features/features.2/features.2.0/block/block.0/block.0.0/Conv_output_0'</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>effnet_scale <span class="op">=</span> effnet_params[effnet_layer][<span class="st">'scale'</span>]</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>effnet_zp <span class="op">=</span> effnet_params[effnet_layer][<span class="st">'zero_point'</span>]</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="co"># PRINT COMPARISON</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"WORST LAYER QUANTIZATION PARAMETERS (from ONNX)"</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'Model'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Layer'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Scale'</span><span class="sc">:&gt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Zero Point'</span><span class="sc">:&gt;12}</span><span class="ss">"</span>)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'ResNet18'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'conv1'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>resnet_scale<span class="sc">:&gt;12.6f}</span><span class="ss"> </span><span class="sc">{</span>resnet_zp<span class="sc">:&gt;12}</span><span class="ss">"</span>)</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'EfficientNet-B0'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'features.2.0.block.0.0'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>effnet_scale<span class="sc">:&gt;12.6f}</span><span class="ss"> </span><span class="sc">{</span>effnet_zp<span class="sc">:&gt;12}</span><span class="ss">"</span>)</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
WORST LAYER QUANTIZATION PARAMETERS (from ONNX)
======================================================================

Model                Layer                                 Scale   Zero Point
----------------------------------------------------------------------
ResNet18             conv1                              0.041440         -128
EfficientNet-B0      features.2.0.block.0.0             2.531122           24
----------------------------------------------------------------------</code></pre>
</div>
</div>
<p>Now given this why is it harder to represent the larger range? As mentioned, when converting to INT8 values we are binning and the larger our range is the larger our bins must be, this is why the scale is larger. Let’s take a look at a concrete example:</p>
<div id="026b67fb-b152-4b02-aaed-ecd535bcd4c6" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>val_a <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>val_b <span class="op">=</span> <span class="fl">7.5</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;First we quantize with the RN18 S and Z</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>val_a_INT8_resnet <span class="op">=</span> <span class="bu">round</span>((val_a <span class="op">/</span> resnet_scale) <span class="op">+</span> resnet_zp)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>val_b_INT8_resnet <span class="op">=</span> <span class="bu">round</span>((val_b <span class="op">/</span> resnet_scale) <span class="op">+</span> resnet_zp)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RN18 INT8 Representation: val_a: </span><span class="sc">{</span>val_a_INT8_resnet<span class="sc">}</span><span class="ss"> | val_b: </span><span class="sc">{</span>val_b_INT8_resnet<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;Quantize with the ENB0 S and Z</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>val_a_INT8_effnet <span class="op">=</span> <span class="bu">round</span>((val_a <span class="op">/</span> effnet_scale) <span class="op">+</span> effnet_zp)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>val_b_INT8_effnet <span class="op">=</span> <span class="bu">round</span>((val_b <span class="op">/</span> effnet_scale) <span class="op">+</span> effnet_zp)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ENB0 INT8 Representation: val_a: </span><span class="sc">{</span>val_a_INT8_effnet<span class="sc">}</span><span class="ss"> | val_b: </span><span class="sc">{</span>val_b_INT8_effnet<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ResNet18 INT8 Representation: val_a: 41 | val_b: 53

EfficientNetB0 INT8 Representation: val_a: 27 | val_b: 27</code></pre>
</div>
</div>
<p><b>The INT8 value for 7 and 7.5, with ENB0 scale and zero, is the same for both values!</b> To get a different value you would have to set the number &gt; 7 + 2.531122 whereas for RN18 it only need be &gt; 7 + 0.041440. This really highlights why the wild ranges cause the loss in performance, it’s very difficult to maintain values as they were in the original network.</p>
</section>
</section>
</section>
<section id="why-resnet18-quantizes-well-and-efficientnetb0-doesnt---a-component-by-component-analysis" class="level2">
<h2 class="anchored" data-anchor-id="why-resnet18-quantizes-well-and-efficientnetb0-doesnt---a-component-by-component-analysis">Why ResNet18 Quantizes Well and EfficientNetB0 Doesn’t - A Component by Component Analysis</h2>
<p>So, ENB0 quantizes poorly because its activations are all over the place. The model still works well overall, it just isn’t cut out for quantization. But, what causes the erratic behaviour?</p>
<p>I think it’s to do with the actual architecture itself, RN18 is a pretty vanilla network - its blocks are made up of Convolution, BatchNorm and ReLU<a href="#2"><sup>2</sup></a>. ENB0, on the other hand has a more complicated setup - the core block is the MBConv which consists of a SiLU, convolution, depthwise convolution and a squeeze and excite operator<a href="#3"><sup>3</sup></a>. There is something in this architecture causing the poorly conditioned activations and we will find it.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The New Layers of EfficientNetB0
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><a href="https://arxiv.org/pdf/1801.04381">DepthwiseSeparableConvolution</a> - A more efficient version of convolution, they work by splitting a single convolution into 2 layers.</p>
<p><a href="https://arxiv.org/pdf/1801.04381">SiLU</a> - Similar to ReLU but it allows small negative gradients to flow through, its aim is to result in fewer dead neurons.</p>
</div>
</div>
</div>
<p>I’ll start the investigation with a simple case, 2 small networks. One will have convolution layers and the other will be with MBConv layers.</p>
<section id="the-investigation---studying-the-layers" class="level3">
<h3 class="anchored" data-anchor-id="the-investigation---studying-the-layers">The Investigation - Studying the Layers</h3>
<p>The idea here is to see if passing a dummy input through an untrained model reveals anything about the differences in RN18 and ENB0 and where the wild ranges of the latter model arise from.</p>
<section id="building-the-models" class="level4">
<h4 class="anchored" data-anchor-id="building-the-models">Building the models</h4>
<p>In the expandable box you will find the code for the RN18 blocks and ENB0 blocks, we are taking 2 blocks from each model here. Then in the next box a dummy input is passed into the randomly initialised models.</p>
<div id="69d8d063-e965-4207-ac61-463aac87bac4" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="120">
<details class="code-fold">
<summary>Code to build blocks of ResNet and EfficientNet</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNetStackedModel(nn.Module):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Block 1: 3 → 64</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn1_b1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu1_b1 <span class="op">=</span> nn.ReLU()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn2_b1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Block 2: 64 → 64</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn1_b2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu1_b2 <span class="op">=</span> nn.ReLU()</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn2_b2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1_b1(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.bn1_b1(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.relu1_b1(x)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2_b1(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.bn2_b1(x)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1_b2(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.bn1_b2(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.relu1_b2(x)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2_b2(x)<span class="op">;</span> x <span class="op">=</span> <span class="va">self</span>.bn2_b2(x)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EfficientNetStackedModel(nn.Module):</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Block 1: 16 → 24 (expand to 96, squeeze to 4)</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_expand_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">96</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn1_expand_b1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">96</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu1_expand_b1 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_dw_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">96</span>, <span class="dv">96</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, groups<span class="op">=</span><span class="dv">96</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn2_dw_b1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">96</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu2_dw_b1 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.avg_pool_b1 <span class="op">=</span> nn.AdaptiveAvgPool2d(<span class="dv">1</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3_se_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">96</span>, <span class="dv">4</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu3_se_b1 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv4_se_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">4</span>, <span class="dv">96</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigmoid_b1 <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv5_proj_b1 <span class="op">=</span> nn.Conv2d(<span class="dv">96</span>, <span class="dv">24</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn3_proj_b1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">24</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Block 2: 24 → 24 (expand to 144, squeeze to 6)</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_expand_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">24</span>, <span class="dv">144</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn1_expand_b2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">144</span>)</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu1_expand_b2 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_dw_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">144</span>, <span class="dv">144</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, groups<span class="op">=</span><span class="dv">144</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn2_dw_b2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">144</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu2_dw_b2 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.avg_pool_b2 <span class="op">=</span> nn.AdaptiveAvgPool2d(<span class="dv">1</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3_se_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">144</span>, <span class="dv">6</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.silu3_se_b2 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv4_se_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">6</span>, <span class="dv">144</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigmoid_b2 <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv5_proj_b2 <span class="op">=</span> nn.Conv2d(<span class="dv">144</span>, <span class="dv">24</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn3_proj_b2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">24</span>)</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _mbconv_forward(<span class="va">self</span>, x, suffix):</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'conv1_expand_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'bn1_expand_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'silu1_expand_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'conv2_dw_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'bn2_dw_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'silu2_dw_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>        x_in <span class="op">=</span> x</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'avg_pool_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'conv3_se_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(scale)</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'silu3_se_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(scale)</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'conv4_se_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(scale)</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'sigmoid_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(scale)</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> scale <span class="op">*</span> x_in</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'conv5_proj_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">getattr</span>(<span class="va">self</span>, <span class="ss">f'bn3_proj_</span><span class="sc">{</span>suffix<span class="sc">}</span><span class="ss">'</span>)(x)</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>._mbconv_forward(x, <span class="st">'b1'</span>)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>._mbconv_forward(x, <span class="st">'b2'</span>)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="94e5f2bf-1400-404e-9406-9a1d988fc776" class="cell" data-execution_count="125">
<details class="code-fold">
<summary>Passing dummy inputs into the models</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>resnet_stack <span class="op">=</span> ResNetStackedModel()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>resnet_stack_acts <span class="op">=</span> get_activation_stats(resnet_stack, dummy_input, <span class="st">"resnet18_block"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>dummy_input <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>efficientnetb0_stack <span class="op">=</span> EfficientNetStackedModel()</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>efficientnetb0_stack_acts <span class="op">=</span> get_activation_stats(efficientnetb0_stack, dummy_input, <span class="st">"efficientnetb0_block"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
====================================================================================================
resnet18_block Activation Statistics (ALL 10 layers)
====================================================================================================
Layer                                    Type                  Min       Max     Range       Std
----------------------------------------------------------------------------------------------------
conv1_b1                                 Conv2d              -1.26      2.02      3.28      0.34
bn1_b1                                   BatchNorm2d         -4.98      4.45      9.43      1.00
relu1_b1                                 ReLU                 0.00      4.45      4.45      0.58
conv2_b1                                 Conv2d              -2.17      2.09      4.26      0.43
bn2_b1                                   BatchNorm2d         -5.12      4.94     10.05      1.00
conv1_b2                                 Conv2d              -2.83      2.88      5.71      0.57
bn1_b2                                   BatchNorm2d         -4.69      5.08      9.77      1.00
relu1_b2                                 ReLU                 0.00      5.08      5.08      0.58
conv2_b2                                 Conv2d              -2.18      2.22      4.40      0.41
bn2_b2                                   BatchNorm2d         -5.47      5.19     10.65      1.00

====================================================================================================
efficientnetb0_block Activation Statistics (ALL 26 layers)
====================================================================================================
Layer                                    Type                  Min       Max     Range       Std
----------------------------------------------------------------------------------------------------
conv1_expand_b1                          Conv2d              -1.42      1.39      2.81      0.33
bn1_expand_b1                            BatchNorm2d         -4.70      4.32      9.02      1.00
silu1_expand_b1                          SiLU                -0.28      4.27      4.54      0.56
conv2_dw_b1                              Conv2d              -2.60      2.86      5.46      0.34
bn2_dw_b1                                BatchNorm2d         -6.25      6.39     12.64      1.00
silu2_dw_b1                              SiLU                -0.28      6.38      6.66      0.57
avg_pool_b1                              AdaptiveAvgPool2d      0.20      0.20      0.01      0.00
conv3_se_b1                              Conv2d              -0.07      0.21      0.27      0.12
silu3_se_b1                              SiLU                -0.03      0.11      0.15      0.07
conv4_se_b1                              Conv2d              -0.55      0.49      1.04      0.30
sigmoid_b1                               Sigmoid              0.37      0.62      0.25      0.07
conv5_proj_b1                            Conv2d              -1.02      0.86      1.88      0.18
bn3_proj_b1                              BatchNorm2d         -4.69      4.80      9.49      1.00
conv1_expand_b2                          Conv2d              -3.89      4.04      7.94      0.57
bn1_expand_b2                            BatchNorm2d         -5.75      5.78     11.53      1.00
silu1_expand_b2                          SiLU                -0.28      5.76      6.04      0.56
conv2_dw_b2                              Conv2d              -3.06      3.02      6.08      0.34
bn2_dw_b2                                BatchNorm2d         -7.45      7.62     15.07      1.00
silu2_dw_b2                              SiLU                -0.28      7.62      7.90      0.57
avg_pool_b2                              AdaptiveAvgPool2d      0.20      0.20      0.01      0.00
conv3_se_b2                              Conv2d              -0.20      0.06      0.26      0.10
silu3_se_b2                              SiLU                -0.09      0.03      0.12      0.05
conv4_se_b2                              Conv2d              -0.44      0.40      0.84      0.23
sigmoid_b2                               Sigmoid              0.39      0.60      0.21      0.06
conv5_proj_b2                            Conv2d              -1.01      0.90      1.92      0.17
bn3_proj_b2                              BatchNorm2d         -5.56      5.14     10.70      1.00</code></pre>
</div>
</div>
<p>Interesting, the activation statistics show that <b>at initialisation time both models exhibit very similar behaviour</b> - the values are well behaved and exhibit “nice” values. The outcome here doesn’t fit my hypothesis. This is surprising, but it highlights that at init time there is nothing inherently bad or good about either network. Nonetheless, the issues leading to the poor quantization must appear somewhere and my next best guess is training time dynamics.</p>
<p>However, note that the large activation ranges appear at BatchNorm layers, and from this the next experiment will draw out exactly where and when the instability begins.</p>
</section>
</section>
<section id="exploring-training-time-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="exploring-training-time-dynamics">Exploring Training Time Dynamics</h3>
<p>To see where the instability begins, we will train both RN18 and the ENB0 models from scratch on ImageWoof<a href="#4"><sup>4</sup></a>, a 10 class classification task to determine which breed a dog is. Every 5 epochs the code will log the activation min, max and std deviation values for first 2 layers in each network. This will reveal to us where and when the issue arises.</p>
<div id="848f24a3-084f-4a65-aedd-40c5c199d0e5" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-scrolled="true">
<details class="code-fold">
<summary>Training loop code for ImageWoof with ResNet18 and EfficientNetB0</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">Train ResNet18 and EfficientNet-B0 from scratch on ImageWoof (10 classes).</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">Log activation statistics for specific blocks every N epochs.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">Save results to JSON for later analysis.</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">Designed to run in a Jupyter notebook on MPS.</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms, models</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co"># CONFIG — edit these as needed</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>DATA_DIR <span class="op">=</span> <span class="st">"./data/imagewoof2-320"</span>  <span class="co"># &lt;-- UPDATE THIS</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>NUM_EPOCHS <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>LOG_EVERY <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>LR <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>MOMENTUM <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>WEIGHT_DECAY <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>OUTPUT_DIR <span class="op">=</span> <span class="st">"./experiment_results"</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>NUM_WORKERS <span class="op">=</span> <span class="dv">0</span>  <span class="co"># 0 is safest on MPS, increase if stable</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="co"># DEVICE SETUP</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(SEED)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(SEED)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.mps.is_available():</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. MODEL BUILDERS</span></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_resnet18(num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ResNet18 from scratch with simple classification head."""</span></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.resnet18(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>    model.fc <span class="op">=</span> nn.Linear(<span class="dv">512</span>, num_classes)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_efficientnet_b0(num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""EfficientNet-B0 from scratch with simple classification head."""</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> models.efficientnet_b0(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>    model.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">1280</span>, num_classes),</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. DATA SETUP</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloaders(data_dir, batch_size<span class="op">=</span><span class="dv">64</span>, num_workers<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>    train_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>        transforms.RandomResizedCrop(<span class="dv">224</span>),</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>        transforms.RandomHorizontalFlip(),</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>            mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>],</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>            std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>],</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>    val_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>        transforms.Resize(<span class="dv">256</span>),</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>        transforms.CenterCrop(<span class="dv">224</span>),</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(</span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>            mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>],</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>            std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>],</span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> datasets.ImageFolder(</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>        os.path.join(data_dir, <span class="st">"train"</span>),</span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>        transform<span class="op">=</span>train_transform,</span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="op">=</span> datasets.ImageFolder(</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a>        os.path.join(data_dir, <span class="st">"val"</span>),</span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a>        transform<span class="op">=</span>val_transform,</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>        train_dataset,</span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a>        num_workers<span class="op">=</span>num_workers,</span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>        pin_memory<span class="op">=</span><span class="va">False</span>,  <span class="co"># pin_memory=False for MPS</span></span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>        val_dataset,</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>        num_workers<span class="op">=</span>num_workers,</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a>        pin_memory<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, val_loader</span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. ACTIVATION LOGGING</span></span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_activation_stats_for_blocks(model, input_tensor, block_prefixes):</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a><span class="co">    Capture activation statistics for layers within specified blocks.</span></span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a>    activations <span class="op">=</span> {}</span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a>    hooks <span class="op">=</span> []</span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> make_hook(name):</span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> hook(module, <span class="bu">input</span>, output):</span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(output, torch.Tensor):</span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a>                activations[name] <span class="op">=</span> {</span>
<span id="cb16-135"><a href="#cb16-135" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"shape"</span>: <span class="bu">list</span>(output.shape),</span>
<span id="cb16-136"><a href="#cb16-136" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"min"</span>: output.<span class="bu">min</span>().item(),</span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"max"</span>: output.<span class="bu">max</span>().item(),</span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"mean"</span>: output.mean().item(),</span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"std"</span>: output.std().item() <span class="cf">if</span> output.numel() <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="fl">0.0</span>,</span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"range"</span>: (output.<span class="bu">max</span>() <span class="op">-</span> output.<span class="bu">min</span>()).item(),</span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"layer_type"</span>: module.__class__.<span class="va">__name__</span>,</span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> hook</span>
<span id="cb16-144"><a href="#cb16-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-145"><a href="#cb16-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, module <span class="kw">in</span> model.named_modules():</span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> name <span class="kw">and</span> <span class="bu">any</span>(name.startswith(prefix) <span class="cf">for</span> prefix <span class="kw">in</span> block_prefixes):</span>
<span id="cb16-147"><a href="#cb16-147" aria-hidden="true" tabindex="-1"></a>            hooks.append(module.register_forward_hook(make_hook(name)))</span>
<span id="cb16-148"><a href="#cb16-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a>        model(input_tensor)</span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> h <span class="kw">in</span> hooks:</span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a>        h.remove()</span>
<span id="cb16-154"><a href="#cb16-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-155"><a href="#cb16-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> activations</span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. TRAINING LOOP</span></span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_one_epoch(model, train_loader, criterion, optimizer, device):</span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb16-164"><a href="#cb16-164" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb16-165"><a href="#cb16-165" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> inputs, targets <span class="kw">in</span> train_loader:</span>
<span id="cb16-169"><a href="#cb16-169" aria-hidden="true" tabindex="-1"></a>        inputs, targets <span class="op">=</span> inputs.to(device), targets.to(device)</span>
<span id="cb16-170"><a href="#cb16-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs)</span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb16-178"><a href="#cb16-178" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb16-179"><a href="#cb16-179" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> targets.size(<span class="dv">0</span>)</span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> predicted.eq(targets).<span class="bu">sum</span>().item()</span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> running_loss <span class="op">/</span> total, <span class="fl">100.0</span> <span class="op">*</span> correct <span class="op">/</span> total</span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-185"><a href="#cb16-185" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(model, val_loader, criterion, device):</span>
<span id="cb16-186"><a href="#cb16-186" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-191"><a href="#cb16-191" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-192"><a href="#cb16-192" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, targets <span class="kw">in</span> val_loader:</span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a>            inputs, targets <span class="op">=</span> inputs.to(device), targets.to(device)</span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb16-198"><a href="#cb16-198" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb16-199"><a href="#cb16-199" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> targets.size(<span class="dv">0</span>)</span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> predicted.eq(targets).<span class="bu">sum</span>().item()</span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> running_loss <span class="op">/</span> total, <span class="fl">100.0</span> <span class="op">*</span> correct <span class="op">/</span> total</span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-204"><a href="#cb16-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-205"><a href="#cb16-205" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_experiment(</span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a>    model_name,</span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a>    block_prefixes,</span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a>    train_loader,</span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a>    val_loader,</span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a>    fixed_batch,</span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a>    device,</span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a>    num_epochs<span class="op">=</span><span class="dv">25</span>,</span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a>    log_every<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a>    momentum<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model.to(device)</span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.SGD(</span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a>        model.parameters(),</span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span>lr,</span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a>        momentum<span class="op">=</span>momentum,</span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a>        weight_decay<span class="op">=</span>weight_decay,</span>
<span id="cb16-226"><a href="#cb16-226" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-227"><a href="#cb16-227" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max<span class="op">=</span>num_epochs)</span>
<span id="cb16-228"><a href="#cb16-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-229"><a href="#cb16-229" aria-hidden="true" tabindex="-1"></a>    fixed_input <span class="op">=</span> fixed_batch[<span class="dv">0</span>].to(device)</span>
<span id="cb16-230"><a href="#cb16-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-231"><a href="#cb16-231" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {</span>
<span id="cb16-232"><a href="#cb16-232" aria-hidden="true" tabindex="-1"></a>        <span class="st">"model_name"</span>: model_name,</span>
<span id="cb16-233"><a href="#cb16-233" aria-hidden="true" tabindex="-1"></a>        <span class="st">"block_prefixes"</span>: block_prefixes,</span>
<span id="cb16-234"><a href="#cb16-234" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hyperparameters"</span>: {</span>
<span id="cb16-235"><a href="#cb16-235" aria-hidden="true" tabindex="-1"></a>            <span class="st">"lr"</span>: lr,</span>
<span id="cb16-236"><a href="#cb16-236" aria-hidden="true" tabindex="-1"></a>            <span class="st">"momentum"</span>: momentum,</span>
<span id="cb16-237"><a href="#cb16-237" aria-hidden="true" tabindex="-1"></a>            <span class="st">"weight_decay"</span>: weight_decay,</span>
<span id="cb16-238"><a href="#cb16-238" aria-hidden="true" tabindex="-1"></a>            <span class="st">"num_epochs"</span>: num_epochs,</span>
<span id="cb16-239"><a href="#cb16-239" aria-hidden="true" tabindex="-1"></a>            <span class="st">"scheduler"</span>: <span class="st">"CosineAnnealingLR"</span>,</span>
<span id="cb16-240"><a href="#cb16-240" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb16-241"><a href="#cb16-241" aria-hidden="true" tabindex="-1"></a>        <span class="st">"training_history"</span>: [],</span>
<span id="cb16-242"><a href="#cb16-242" aria-hidden="true" tabindex="-1"></a>        <span class="st">"activation_logs"</span>: {},</span>
<span id="cb16-243"><a href="#cb16-243" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-244"><a href="#cb16-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-245"><a href="#cb16-245" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log at epoch 0 (before any training)</span></span>
<span id="cb16-246"><a href="#cb16-246" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-247"><a href="#cb16-247" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> — Logging activations at epoch 0 (init)"</span>)</span>
<span id="cb16-248"><a href="#cb16-248" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-249"><a href="#cb16-249" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb16-250"><a href="#cb16-250" aria-hidden="true" tabindex="-1"></a>    init_stats <span class="op">=</span> get_activation_stats_for_blocks(model, fixed_input, block_prefixes)</span>
<span id="cb16-251"><a href="#cb16-251" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">"activation_logs"</span>][<span class="st">"epoch_0"</span>] <span class="op">=</span> init_stats</span>
<span id="cb16-252"><a href="#cb16-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-253"><a href="#cb16-253" aria-hidden="true" tabindex="-1"></a>    val_loss, val_acc <span class="op">=</span> validate(model, val_loader, criterion, device)</span>
<span id="cb16-254"><a href="#cb16-254" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">"training_history"</span>].append({</span>
<span id="cb16-255"><a href="#cb16-255" aria-hidden="true" tabindex="-1"></a>        <span class="st">"epoch"</span>: <span class="dv">0</span>,</span>
<span id="cb16-256"><a href="#cb16-256" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_loss"</span>: <span class="va">None</span>,</span>
<span id="cb16-257"><a href="#cb16-257" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_acc"</span>: <span class="va">None</span>,</span>
<span id="cb16-258"><a href="#cb16-258" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_loss"</span>: val_loss,</span>
<span id="cb16-259"><a href="#cb16-259" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_acc"</span>: val_acc,</span>
<span id="cb16-260"><a href="#cb16-260" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb16-261"><a href="#cb16-261" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Epoch 0 | Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss"> | Val Acc: </span><span class="sc">{</span>val_acc<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb16-262"><a href="#cb16-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-263"><a href="#cb16-263" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb16-264"><a href="#cb16-264" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb16-265"><a href="#cb16-265" aria-hidden="true" tabindex="-1"></a>        train_loss, train_acc <span class="op">=</span> train_one_epoch(</span>
<span id="cb16-266"><a href="#cb16-266" aria-hidden="true" tabindex="-1"></a>            model, train_loader, criterion, optimizer, device</span>
<span id="cb16-267"><a href="#cb16-267" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-268"><a href="#cb16-268" aria-hidden="true" tabindex="-1"></a>        val_loss, val_acc <span class="op">=</span> validate(model, val_loader, criterion, device)</span>
<span id="cb16-269"><a href="#cb16-269" aria-hidden="true" tabindex="-1"></a>        scheduler.step()</span>
<span id="cb16-270"><a href="#cb16-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-271"><a href="#cb16-271" aria-hidden="true" tabindex="-1"></a>        current_lr <span class="op">=</span> optimizer.param_groups[<span class="dv">0</span>][<span class="st">"lr"</span>]</span>
<span id="cb16-272"><a href="#cb16-272" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb16-273"><a href="#cb16-273" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"  Epoch </span><span class="sc">{</span>epoch<span class="sc">:&gt;3d}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss"> | "</span></span>
<span id="cb16-274"><a href="#cb16-274" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> | Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.2f}</span><span class="ss">% | "</span></span>
<span id="cb16-275"><a href="#cb16-275" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss"> | Val Acc: </span><span class="sc">{</span>val_acc<span class="sc">:.2f}</span><span class="ss">% | "</span></span>
<span id="cb16-276"><a href="#cb16-276" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"LR: </span><span class="sc">{</span>current_lr<span class="sc">:.6f}</span><span class="ss">"</span></span>
<span id="cb16-277"><a href="#cb16-277" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-278"><a href="#cb16-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-279"><a href="#cb16-279" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">"training_history"</span>].append({</span>
<span id="cb16-280"><a href="#cb16-280" aria-hidden="true" tabindex="-1"></a>            <span class="st">"epoch"</span>: epoch,</span>
<span id="cb16-281"><a href="#cb16-281" aria-hidden="true" tabindex="-1"></a>            <span class="st">"train_loss"</span>: train_loss,</span>
<span id="cb16-282"><a href="#cb16-282" aria-hidden="true" tabindex="-1"></a>            <span class="st">"train_acc"</span>: train_acc,</span>
<span id="cb16-283"><a href="#cb16-283" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: val_loss,</span>
<span id="cb16-284"><a href="#cb16-284" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_acc"</span>: val_acc,</span>
<span id="cb16-285"><a href="#cb16-285" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb16-286"><a href="#cb16-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-287"><a href="#cb16-287" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log activations every N epochs</span></span>
<span id="cb16-288"><a href="#cb16-288" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> log_every <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> epoch <span class="op">==</span> num_epochs:</span>
<span id="cb16-289"><a href="#cb16-289" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  → Logging activations at epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-290"><a href="#cb16-290" aria-hidden="true" tabindex="-1"></a>            model.<span class="bu">eval</span>()</span>
<span id="cb16-291"><a href="#cb16-291" aria-hidden="true" tabindex="-1"></a>            stats <span class="op">=</span> get_activation_stats_for_blocks(</span>
<span id="cb16-292"><a href="#cb16-292" aria-hidden="true" tabindex="-1"></a>                model, fixed_input, block_prefixes</span>
<span id="cb16-293"><a href="#cb16-293" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb16-294"><a href="#cb16-294" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">"activation_logs"</span>][<span class="ss">f"epoch_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> stats</span>
<span id="cb16-295"><a href="#cb16-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-296"><a href="#cb16-296" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results, model</span>
<span id="cb16-297"><a href="#cb16-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-298"><a href="#cb16-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-299"><a href="#cb16-299" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-300"><a href="#cb16-300" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. RUN EXPERIMENT</span></span>
<span id="cb16-301"><a href="#cb16-301" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb16-302"><a href="#cb16-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-303"><a href="#cb16-303" aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb16-304"><a href="#cb16-304" aria-hidden="true" tabindex="-1"></a>train_loader, val_loader <span class="op">=</span> get_dataloaders(</span>
<span id="cb16-305"><a href="#cb16-305" aria-hidden="true" tabindex="-1"></a>    DATA_DIR,</span>
<span id="cb16-306"><a href="#cb16-306" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb16-307"><a href="#cb16-307" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span>NUM_WORKERS,</span>
<span id="cb16-308"><a href="#cb16-308" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-309"><a href="#cb16-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train samples: </span><span class="sc">{</span><span class="bu">len</span>(train_loader.dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-310"><a href="#cb16-310" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Val samples: </span><span class="sc">{</span><span class="bu">len</span>(val_loader.dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-311"><a href="#cb16-311" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Classes: </span><span class="sc">{</span>train_loader<span class="sc">.</span>dataset<span class="sc">.</span>classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-312"><a href="#cb16-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-313"><a href="#cb16-313" aria-hidden="true" tabindex="-1"></a><span class="co"># Fixed batch for consistent activation logging</span></span>
<span id="cb16-314"><a href="#cb16-314" aria-hidden="true" tabindex="-1"></a>fixed_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(val_loader))</span>
<span id="cb16-315"><a href="#cb16-315" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Fixed batch shape: </span><span class="sc">{</span>fixed_batch[<span class="dv">0</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-316"><a href="#cb16-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-317"><a href="#cb16-317" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared training config</span></span>
<span id="cb16-318"><a href="#cb16-318" aria-hidden="true" tabindex="-1"></a>train_kwargs <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb16-319"><a href="#cb16-319" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb16-320"><a href="#cb16-320" aria-hidden="true" tabindex="-1"></a>    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb16-321"><a href="#cb16-321" aria-hidden="true" tabindex="-1"></a>    fixed_batch<span class="op">=</span>fixed_batch,</span>
<span id="cb16-322"><a href="#cb16-322" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb16-323"><a href="#cb16-323" aria-hidden="true" tabindex="-1"></a>    num_epochs<span class="op">=</span>NUM_EPOCHS,</span>
<span id="cb16-324"><a href="#cb16-324" aria-hidden="true" tabindex="-1"></a>    log_every<span class="op">=</span>LOG_EVERY,</span>
<span id="cb16-325"><a href="#cb16-325" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>LR,</span>
<span id="cb16-326"><a href="#cb16-326" aria-hidden="true" tabindex="-1"></a>    momentum<span class="op">=</span>MOMENTUM,</span>
<span id="cb16-327"><a href="#cb16-327" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>WEIGHT_DECAY,</span>
<span id="cb16-328"><a href="#cb16-328" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-329"><a href="#cb16-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-330"><a href="#cb16-330" aria-hidden="true" tabindex="-1"></a>os.makedirs(OUTPUT_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-331"><a href="#cb16-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-332"><a href="#cb16-332" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- ResNet18 ----</span></span>
<span id="cb16-333"><a href="#cb16-333" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-334"><a href="#cb16-334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  TRAINING RESNET18"</span>)</span>
<span id="cb16-335"><a href="#cb16-335" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-336"><a href="#cb16-336" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> build_resnet18(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb16-337"><a href="#cb16-337" aria-hidden="true" tabindex="-1"></a>resnet_results, resnet_trained <span class="op">=</span> run_experiment(</span>
<span id="cb16-338"><a href="#cb16-338" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>resnet,</span>
<span id="cb16-339"><a href="#cb16-339" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span><span class="st">"ResNet18"</span>,</span>
<span id="cb16-340"><a href="#cb16-340" aria-hidden="true" tabindex="-1"></a>    block_prefixes<span class="op">=</span>[<span class="st">"layer1.0"</span>, <span class="st">"layer1.1"</span>],</span>
<span id="cb16-341"><a href="#cb16-341" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>train_kwargs,</span>
<span id="cb16-342"><a href="#cb16-342" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-343"><a href="#cb16-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-344"><a href="#cb16-344" aria-hidden="true" tabindex="-1"></a>resnet_path <span class="op">=</span> os.path.join(OUTPUT_DIR, <span class="st">"resnet18_results.json"</span>)</span>
<span id="cb16-345"><a href="#cb16-345" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(resnet_path, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb16-346"><a href="#cb16-346" aria-hidden="true" tabindex="-1"></a>    json.dump(resnet_results, f, indent<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-347"><a href="#cb16-347" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ResNet18 results saved to </span><span class="sc">{</span>resnet_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-348"><a href="#cb16-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-349"><a href="#cb16-349" aria-hidden="true" tabindex="-1"></a>torch.save(</span>
<span id="cb16-350"><a href="#cb16-350" aria-hidden="true" tabindex="-1"></a>    resnet_trained.state_dict(),</span>
<span id="cb16-351"><a href="#cb16-351" aria-hidden="true" tabindex="-1"></a>    os.path.join(OUTPUT_DIR, <span class="st">"resnet18_imagewoof.pth"</span>),</span>
<span id="cb16-352"><a href="#cb16-352" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-353"><a href="#cb16-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-354"><a href="#cb16-354" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- EfficientNet-B0 ----</span></span>
<span id="cb16-355"><a href="#cb16-355" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-356"><a href="#cb16-356" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  TRAINING EFFICIENTNET-B0"</span>)</span>
<span id="cb16-357"><a href="#cb16-357" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-358"><a href="#cb16-358" aria-hidden="true" tabindex="-1"></a>efficientnet <span class="op">=</span> build_efficientnet_b0(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb16-359"><a href="#cb16-359" aria-hidden="true" tabindex="-1"></a>effnet_results, effnet_trained <span class="op">=</span> run_experiment(</span>
<span id="cb16-360"><a href="#cb16-360" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>efficientnet,</span>
<span id="cb16-361"><a href="#cb16-361" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span><span class="st">"EfficientNet-B0"</span>,</span>
<span id="cb16-362"><a href="#cb16-362" aria-hidden="true" tabindex="-1"></a>    block_prefixes<span class="op">=</span>[<span class="st">"features.1.0"</span>, <span class="st">"features.2.0"</span>],</span>
<span id="cb16-363"><a href="#cb16-363" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>train_kwargs,</span>
<span id="cb16-364"><a href="#cb16-364" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-365"><a href="#cb16-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-366"><a href="#cb16-366" aria-hidden="true" tabindex="-1"></a>effnet_path <span class="op">=</span> os.path.join(OUTPUT_DIR, <span class="st">"efficientnet_b0_results.json"</span>)</span>
<span id="cb16-367"><a href="#cb16-367" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(effnet_path, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb16-368"><a href="#cb16-368" aria-hidden="true" tabindex="-1"></a>    json.dump(effnet_results, f, indent<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-369"><a href="#cb16-369" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">EfficientNet-B0 results saved to </span><span class="sc">{</span>effnet_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-370"><a href="#cb16-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-371"><a href="#cb16-371" aria-hidden="true" tabindex="-1"></a>torch.save(</span>
<span id="cb16-372"><a href="#cb16-372" aria-hidden="true" tabindex="-1"></a>    effnet_trained.state_dict(),</span>
<span id="cb16-373"><a href="#cb16-373" aria-hidden="true" tabindex="-1"></a>    os.path.join(OUTPUT_DIR, <span class="st">"efficientnet_b0_imagewoof.pth"</span>),</span>
<span id="cb16-374"><a href="#cb16-374" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-375"><a href="#cb16-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-376"><a href="#cb16-376" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-377"><a href="#cb16-377" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  EXPERIMENT COMPLETE"</span>)</span>
<span id="cb16-378"><a href="#cb16-378" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb16-379"><a href="#cb16-379" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"All results saved to </span><span class="sc">{</span>OUTPUT_DIR<span class="sc">}</span><span class="ss">/"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now with the output and upon further inspection, we see issues arise at the Depthwise Convs, look at the activation value after the Depthwise Conv and the subsequent BatchNorm.</p>
<div id="9510e0da-2066-4893-b3c3-f9654dc5cc06" class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="173">
<details class="code-fold">
<summary>Load and show the training json</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'experiment_results/resnet18_results.json'</span>) <span class="im">as</span> f:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    rdata <span class="op">=</span> json.load(f)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'experiment_results/efficientnet_b0_results.json'</span>) <span class="im">as</span> f:</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    edata <span class="op">=</span> json.load(f)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> [<span class="st">"epoch_0"</span>, <span class="st">"epoch_5"</span>, <span class="st">"epoch_10"</span>, <span class="st">"epoch_15"</span>, <span class="st">"epoch_20"</span>, <span class="st">"epoch_25"</span>]</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>ep_labels <span class="op">=</span> [<span class="st">"Ep0"</span>, <span class="st">"Ep5"</span>, <span class="st">"Ep10"</span>, <span class="st">"Ep15"</span>, <span class="st">"Ep20"</span>, <span class="st">"Ep25"</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_range(data, epoch, layer):</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data[<span class="st">"activation_logs"</span>][epoch].get(layer, {}).get(<span class="st">"range"</span>, <span class="dv">0</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_std(data, epoch, layer):</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data[<span class="st">"activation_logs"</span>][epoch].get(layer, {}).get(<span class="st">"std"</span>, <span class="dv">0</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ratio(data, epoch, conv, bn):</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> get_range(data, epoch, conv)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> get_range(data, epoch, bn)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> b <span class="op">/</span> c <span class="cf">if</span> c <span class="op">&gt;</span> <span class="fl">0.001</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fmt(v, decimals<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span>v<span class="sc">:.</span>{decimals}f<span class="sc">}</span><span class="ss">"</span> <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"N/A"</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Table 2: Raw ranges</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Raw Activation Ranges (Conv → BN)"</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Layer'</span><span class="sc">:&lt;32}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep0'</span><span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep5'</span><span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep10'</span><span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep15'</span><span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep20'</span><span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ep25'</span><span class="sc">:&gt;6}</span><span class="ss">"</span>)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>detail_rows <span class="op">=</span> [</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"ResNet Conv1"</span>,               rdata, <span class="st">"layer1.0.conv1"</span>),</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"ResNet BN1"</span>,                 rdata, <span class="st">"layer1.0.bn1"</span>),</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>    <span class="va">None</span>,</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"EffNet Depthwise Conv"</span>,      edata, <span class="st">"features.2.0.block.1.0"</span>),</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"EffNet Depthwise BN"</span>,        edata, <span class="st">"features.2.0.block.1.1"</span>),</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    <span class="va">None</span>,</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"EffNet Expand Conv"</span>,         edata, <span class="st">"features.2.0.block.0.0"</span>),</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"EffNet Expand BN"</span>,           edata, <span class="st">"features.2.0.block.0.1"</span>),</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> detail_rows:</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>()</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    label, data, layer <span class="op">=</span> row</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    vals <span class="op">=</span> [fmt(get_range(data, ep, layer), <span class="dv">1</span>) <span class="cf">for</span> ep <span class="kw">in</span> epochs]</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">:&lt;32}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">0</span>]<span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">1</span>]<span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">2</span>]<span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">3</span>]<span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">4</span>]<span class="sc">:&gt;6}</span><span class="ss"> </span><span class="sc">{</span>vals[<span class="dv">5</span>]<span class="sc">:&gt;6}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>

Raw Activation Ranges (Conv → BN)
Layer                               Ep0    Ep5   Ep10   Ep15   Ep20   Ep25
----------------------------------------------------------------------
ResNet Conv1                        5.7   22.7   31.1   33.7   34.7   34.7
ResNet BN1                          5.7   15.5   19.2   17.6   19.4   19.6

EffNet Depthwise Conv               0.0    6.4    6.1    6.9    6.8    7.1
EffNet Depthwise BN                 0.0   31.6   28.8   33.2   30.2   30.5

EffNet Expand Conv                  0.3   16.7   20.4   24.0   24.3   24.8
EffNet Expand BN                    0.3   30.2   28.5   29.8   29.5   30.5</code></pre>
</div>
</div>
<p>As noted, at init time both models exhibit similar behaviours. But, by epoch 5 their behaviours have diverged. In ENB0, BatchNorm is expanding the activation ranges. The range of values outputted by DepthWise conv is pretty reasonable, but after the BatchNorm they get crazy.</p>
<p>There is a <a href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/papers/Yun_Do_All_MobileNets_Quantize_Poorly_Gaining_Insights_Into_the_Effect_CVPRW_2021_paper.pdf">paper</a> discussing this phenomenon in more detail, check it out for more coverage. But, we can get an insight into it by going back to the original EyesOff Models I trained.</p>
<section id="going-back-to-the-eyesoff-models" class="level4">
<h4 class="anchored" data-anchor-id="going-back-to-the-eyesoff-models">Going Back to the EyesOff Models</h4>
<p>To understand the output, we first need to better understand the DepthWise convolution. In the DepthWise conv the number of filters = number of input channels as such each filter only operates on a single input channel. Bear in mind in a regular conv each filter operates across all input channels - meaning they see much more values. Due to this, the filters of DepthWise convs can have different scales/their values can differ quite a bit across filters. This can be seen below:</p>
<div id="156dc367-eade-43f1-abe6-973ad2b89938" class="cell" data-execution_count="170">
<details class="code-fold">
<summary>Compare per-channel activation mismatch and BN gamma: Depthwise Conv vs Regular Conv</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_per_channel_stats(model, input_tensor, layer_name):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Get per-channel std from activations."""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> {}</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    hooks <span class="op">=</span> []</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> make_hook(name):</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> hook(module, <span class="bu">input</span>, output):</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(output, torch.Tensor):</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>                per_channel_std <span class="op">=</span> output.std(dim<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>])  <span class="co"># [C]</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                per_channel_range <span class="op">=</span> output.flatten(start_dim<span class="op">=</span><span class="dv">2</span>).<span class="bu">max</span>(dim<span class="op">=</span><span class="dv">2</span>).values.squeeze(<span class="dv">0</span>) <span class="op">-</span> <span class="op">\</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                                    output.flatten(start_dim<span class="op">=</span><span class="dv">2</span>).<span class="bu">min</span>(dim<span class="op">=</span><span class="dv">2</span>).values.squeeze(<span class="dv">0</span>)  <span class="co"># [C]</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>                result[<span class="st">"per_channel_std"</span>] <span class="op">=</span> per_channel_std</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                result[<span class="st">"per_channel_range"</span>] <span class="op">=</span> per_channel_range</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> hook</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, module <span class="kw">in</span> model.named_modules():</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> name <span class="op">==</span> layer_name:</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            hooks.append(module.register_forward_hook(make_hook(name)))</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        model(input_tensor)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> h <span class="kw">in</span> hooks:</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        h.remove()</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Get per-channel activation stats</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>resnet_ch <span class="op">=</span> get_per_channel_stats(resnet_model, input_frame, <span class="st">"layer1.0.conv1"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>effnet_ch <span class="op">=</span> get_per_channel_stats(efficientnet_model, input_frame, <span class="st">"features.2.0.block.1.0"</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>r_std <span class="op">=</span> resnet_ch[<span class="st">"per_channel_std"</span>]</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>e_std <span class="op">=</span> effnet_ch[<span class="st">"per_channel_std"</span>]</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>r_range <span class="op">=</span> resnet_ch[<span class="st">"per_channel_range"</span>]</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>e_range <span class="op">=</span> effnet_ch[<span class="st">"per_channel_range"</span>]</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Get BN gamma values</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>resnet_bn_gamma <span class="op">=</span> resnet_model.layer1[<span class="dv">0</span>].bn1.weight.data</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>effnet_dw_bn_gamma <span class="op">=</span> efficientnet_model.features[<span class="dv">2</span>][<span class="dv">0</span>].block[<span class="dv">1</span>][<span class="dv">1</span>].weight.data</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  PER-CHANNEL ACTIVATION STD (output of conv layers)"</span>)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Metric'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'ResNet Conv'</span><span class="sc">:&gt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'EffNet DW Conv'</span><span class="sc">:&gt;15}</span><span class="ss">"</span>)</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Num channels'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>r_std<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:&gt;15}</span><span class="ss"> </span><span class="sc">{</span>e_std<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:&gt;15}</span><span class="ss">"</span>)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Mean of ch stds'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>r_std<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>e_std<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Std of ch stds'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>r_std<span class="sc">.</span>std()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>e_std<span class="sc">.</span>std()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Min ch std'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>r_std<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>e_std<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Max ch std'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>r_std<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>e_std<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  BATCHNORM GAMMA"</span>)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Metric'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'ResNet BN1'</span><span class="sc">:&gt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'EffNet DW BN'</span><span class="sc">:&gt;15}</span><span class="ss">"</span>)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Mean gamma'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>resnet_bn_gamma<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>effnet_dw_bn_gamma<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Std of gamma'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>resnet_bn_gamma<span class="sc">.</span>std()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>effnet_dw_bn_gamma<span class="sc">.</span>std()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Min gamma'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>resnet_bn_gamma<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>effnet_dw_bn_gamma<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">'Max gamma'</span><span class="sc">:&lt;30}</span><span class="ss"> </span><span class="sc">{</span>resnet_bn_gamma<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss"> </span><span class="sc">{</span>effnet_dw_bn_gamma<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">:&gt;15.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
  PER-CHANNEL ACTIVATION STD (output of conv layers)
======================================================================
  Metric                             ResNet Conv  EffNet DW Conv
  ------------------------------------------------------------
  Num channels                                64              96
  Mean of ch stds                         0.4786          1.9116
  Std of ch stds                          0.2081          1.8563
  Min ch std                              0.1341          0.0118
  Max ch std                              1.0941          8.9032

======================================================================
  BATCHNORM GAMMA
======================================================================
  Metric                              ResNet BN1    EffNet DW BN
  ------------------------------------------------------------
  Mean gamma                              0.3396          5.5246
  Std of gamma                            0.1248          2.1555
  Min gamma                               0.1683          2.0408
  Max gamma                               0.6440         12.0095</code></pre>
</div>
</div>
<p>Look at the difference in the mean and std deviation of the channel stats of the RN18 filters vs the ENB0 ones! Looking at the difference in min and max std deviation is even more telling - the activations of ENB0 are just bigger, this goes back to the DepthWise conv’s filters, as each only operates on a single input channel they have a tendency to drift whereas the RN18 convs don’t.</p>
<p>Next look at that BatchNorm, the range of gamma values for ENB0 is massive in comparison to RN18. In ENB0’s filters the max std deviation of a channel is 8.9 whereas RN18 is much better behaved with a max std deviation across its channels of 1.08. This phenomenon is a direct outcome of the activation values ranges, the gammas need to work harder when the range is wilder.</p>
<p>This then exacerbates the issues we see with INT8 quantization as gamma is a linear multiplier in the BatchNorm calculation, so with a larger gamma outliers are amplified further - thus increasing the range of values which need to be quantized.</p>
<p>See below for a quick example of this, I take an example layer which just has 10 values and two of them are outliers (5 and 10) then we can see the effect of the RN18 gamma vs ENB0 gamma:</p>
<div id="4d552a47-a6ac-42d2-b493-54311a95d881" class="cell" data-execution_count="218">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simple_batch_norm(values, gamma, beta):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> np.mean(values)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> np.var(values)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> gamma <span class="op">*</span> ((values <span class="op">-</span> mean) <span class="op">/</span> np.sqrt((variance <span class="op">+</span> <span class="fl">1e-5</span>))) <span class="op">+</span> beta</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>example_activations <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="fl">2.5</span>, <span class="dv">1</span>, <span class="fl">1.25</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.33</span>, <span class="dv">10</span>])</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>idx_max_gamma_enb0 <span class="op">=</span> np.argmax(efficientnet_model.features[<span class="dv">2</span>][<span class="dv">0</span>].block[<span class="dv">1</span>][<span class="dv">1</span>].weight.data)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>g_enb0 <span class="op">=</span> efficientnet_model.features[<span class="dv">2</span>][<span class="dv">0</span>].block[<span class="dv">1</span>][<span class="dv">1</span>].weight.data[idx_max_gamma_enb0]</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>b_enb0 <span class="op">=</span> efficientnet_model.features[<span class="dv">2</span>][<span class="dv">0</span>].block[<span class="dv">1</span>][<span class="dv">1</span>].bias.data[idx_max_gamma_enb0]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>idx_max_gamma_rn18 <span class="op">=</span> np.argmax(resnet_model.layer1[<span class="dv">0</span>].bn1.weight.data)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>g_rn18 <span class="op">=</span> resnet_model.layer1[<span class="dv">0</span>].bn1.weight.data[idx_max_gamma_rn18]</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>b_rn18 <span class="op">=</span> resnet_model.layer1[<span class="dv">0</span>].bn1.bias.data[idx_max_gamma_rn18]</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>enb0_gamma_beta <span class="op">=</span> simple_batch_norm(example_activations, g_enb0, b_enb0)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>rn18_gamma_beta <span class="op">=</span> simple_batch_norm(example_activations, g_rn18, b_rn18)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Range pre BatchNorm: </span><span class="sc">{</span>np<span class="sc">.</span>ptp(example_activations)<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Raw activation values post BatchNorm:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ENB0: </span><span class="sc">{</span>enb0_gamma_beta<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RN18: </span><span class="sc">{</span>rn18_gamma_beta<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Range post BatchNorm:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ENB0: </span><span class="sc">{</span>np<span class="sc">.</span>ptp(enb0_gamma_beta)<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RN18: </span><span class="sc">{</span>np<span class="sc">.</span>ptp(rn18_gamma_beta)<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">90</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Range pre BatchNorm: 12.0

------------------------------------------------------------------------------------------
Raw actvation values post BatchNorm:

ENB0: tensor([  7.2638, -20.2524, -12.3906,  -2.5634,  -8.4597,  -7.4770,  -4.5288,
         -0.5980,  -3.2317,  26.9182], dtype=torch.float64)

RN18: tensor([ 0.1996, -1.2760, -0.8544, -0.3274, -0.6436, -0.5909, -0.4328, -0.2220,
        -0.3632,  1.2536], dtype=torch.float64)

------------------------------------------------------------------------------------------
Range post BatchNorm:

ENB0: 47.17061443435465

RN18: 2.529558665151854

------------------------------------------------------------------------------------------</code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The root cause of ENB0’s poor quantization is a chain reaction: it begins with DepthWiseSeparableConvs learning 1 filter per input channel. Then without the averaging effect of operating across all channels, filters drift to different scales. Next, BatchNorm learns large gamma values due to the different scales, amplifying outliers and widening the activation range even further. Finally, when this large activation range is quantized the error is too large, causing massive degradation in performance.</p>
<p>If you ever face issues in quantization performance, it’s worth checking the activation range of your model prior to quantizing.</p>
<p>As for EyesOff I am going with the RN18 model for now. I have tried QAT, but have not yet had a chance to fully test it out, also there exists other quantization methods for handling large ranges which would be worth a try. For now, RN18 is fast and accurate… what more can one ask from an ML model.</p>
<hr>
<p><a id="1" style="text-decoration: none; color: inherit;" href=""><sup>1</sup></a><a href="https://huggingface.co/docs/optimum/en/concept_guides/quantization">https://huggingface.co/docs/optimum/en/concept_guides/quantization</a></p>
<p><a id="2" style="text-decoration: none; color: inherit;" href=""><sup>2</sup></a><a href="https://docs.pytorch.org/vision/main/_modules/torchvision/models/resnet.html#ResNet18_Weights">https://docs.pytorch.org/vision/main/_modules/torchvision/models/resnet.html#ResNet18_Weights</a></p>
<p><a id="3" style="text-decoration: none; color: inherit;" href=""><sup>3</sup></a><a href="https://docs.pytorch.org/vision/main/_modules/torchvision/models/efficientnet.html#EfficientNet_B0_Weights">https://docs.pytorch.org/vision/main/_modules/torchvision/models/efficientnet.html#EfficientNet_B0_Weights</a></p>
<p><a id="4" style="text-decoration: none; color: inherit;" href=""><sup>4</sup></a><a href="https://github.com/fastai/imagenette">https://github.com/fastai/imagenette</a></p>
<p><a id="5" style="text-decoration: none; color: inherit;" href=""><sup>5</sup></a> I benchmarked the power usage of the FP32 vs INT8 models and got:</p>
<pre class="text"><code>=====================================================================================
  ENERGY BENCHMARK RESULTS
=====================================================================================
  Model                       Time (s)    Energy (Wh)      Wh/frame
  ---------------------------------------------------------------
  EfficientNet FP32               4.54         0.0612      0.000306
  EfficientNet INT8               1.15         0.0155      0.000077

  EfficientNet uses 74.7% less energy</code></pre>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>